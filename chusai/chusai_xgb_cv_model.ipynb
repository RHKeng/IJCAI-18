{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import csv\n",
    "import matplotlib.dates\n",
    "from datetime import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from xgboost.sklearn import XGBClassifier  \n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score  \n",
    "import matplotlib.pylab as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Index(['shop_review_positive_rate', 'shop_score_service',\n",
      "       'shop_score_delivery', 'shop_score_description', 'context_page_id_1',\n",
      "       'context_page_id_2', 'context_page_id_3', 'context_page_id_4',\n",
      "       'item_pv_level_low', 'shop_star_level_loss',\n",
      "       'isHigh_shop_review_positive_rate', 'shop_review_positive_rate_diff',\n",
      "       'isHigh_shop_score_service', 'shop_score_service_diff',\n",
      "       'isHigh_shop_score_delivery', 'shop_score_delivery_diff',\n",
      "       'isHigh_shop_score_description', 'shop_score_description_diff', 'hour',\n",
      "       'user_gender_id', 'user_occupation_id', 'user_star_level',\n",
      "       'user_age_level', 'item_sales_level', 'item_brand_id', 'item_city_id',\n",
      "       'item_collected_level', 'item_price_level', 'item_pv_level',\n",
      "       'context_page_id', 'shop_review_num_level', 'shop_star_level',\n",
      "       'match_category_proportion', 'match_property_proportion',\n",
      "       'predict_category_number', 'predict_property_number',\n",
      "       'isFirstCategoryIn', 'isLastCategoryIn', 'day_hour', 'weekday',\n",
      "       'lastOneHour_sameItem_count', 'lastOneHour_sameFirstCategory_count',\n",
      "       'lastOneHour_sameLastCategory_count', 'is_history_sameItem',\n",
      "       'is_history_sameFirstCategory', 'is_history_sameLastCategory',\n",
      "       'is_highProportion_brand', 'is_highSale_brand', 'category_number',\n",
      "       'property_number', 'lastOneHour_sameBrand_count',\n",
      "       'lastOneHour_sameShop_count', 'is_history_sameBrand',\n",
      "       'is_history_sameShop', 'isLastOneHour_firstClickItem',\n",
      "       'userItem_lastClickDeltaTime', 'userBrand_lastClickDeltaTime',\n",
      "       'userShop_lastClickDeltaTime', 'userFirstCategory_lastClickDeltaTime',\n",
      "       'userLastCategory_lastClickDeltaTime', 'shop_item_classNumber',\n",
      "       'brand_item_classNumber', 'city_item_classNumber',\n",
      "       'shop_user_classNumber', 'brand_user_classNumber',\n",
      "       'city_user_classNumber'],\n",
      "      dtype='object')\n",
      "66\n",
      "Index(['shop_review_positive_rate', 'shop_score_service',\n",
      "       'shop_score_delivery', 'shop_score_description', 'context_page_id_1',\n",
      "       'context_page_id_2', 'context_page_id_3', 'context_page_id_4',\n",
      "       'item_pv_level_low', 'shop_star_level_loss',\n",
      "       'shop_review_positive_rate_diff', 'isHigh_shop_review_positive_rate',\n",
      "       'shop_score_service_diff', 'isHigh_shop_score_service',\n",
      "       'shop_score_delivery_diff', 'isHigh_shop_score_delivery',\n",
      "       'shop_score_description_diff', 'isHigh_shop_score_description', 'hour',\n",
      "       'user_gender_id', 'user_occupation_id', 'user_star_level',\n",
      "       'user_age_level', 'item_sales_level', 'item_brand_id', 'item_city_id',\n",
      "       'item_collected_level', 'item_price_level', 'item_pv_level',\n",
      "       'context_page_id', 'shop_review_num_level', 'shop_star_level',\n",
      "       'match_category_proportion', 'match_property_proportion',\n",
      "       'predict_category_number', 'predict_property_number',\n",
      "       'isFirstCategoryIn', 'isLastCategoryIn', 'day_hour', 'weekday',\n",
      "       'lastOneHour_sameItem_count', 'lastOneHour_sameFirstCategory_count',\n",
      "       'lastOneHour_sameLastCategory_count', 'is_history_sameItem',\n",
      "       'is_history_sameFirstCategory', 'is_history_sameLastCategory',\n",
      "       'is_highProportion_brand', 'is_highSale_brand', 'category_number',\n",
      "       'property_number', 'lastOneHour_sameBrand_count',\n",
      "       'lastOneHour_sameShop_count', 'is_history_sameBrand',\n",
      "       'is_history_sameShop', 'isLastOneHour_firstClickItem',\n",
      "       'userItem_lastClickDeltaTime', 'userBrand_lastClickDeltaTime',\n",
      "       'userShop_lastClickDeltaTime', 'userFirstCategory_lastClickDeltaTime',\n",
      "       'userLastCategory_lastClickDeltaTime', 'shop_item_classNumber',\n",
      "       'brand_item_classNumber', 'city_item_classNumber',\n",
      "       'shop_user_classNumber', 'brand_user_classNumber',\n",
      "       'city_user_classNumber'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#首先导入训练集数据进行线下数据集划分\n",
    "train_df = pd.read_csv('chusai_train_df.csv')\n",
    "\n",
    "regex_string = ('item_price_level_.*|item_pv_level_.*' + \n",
    "               '|shop_review_num_level_.*|shop_star_level_.*' + \n",
    "               '|context_page_id_.*' + \n",
    "               '|shop_review_positive_rate|shop_score_service|shop_score_delivery|shop_score_description')\n",
    "fea = ['hour', 'user_gender_id', 'user_occupation_id', 'user_star_level', 'user_age_level', 'item_sales_level', \n",
    "       'item_brand_id', 'item_city_id', 'item_collected_level','item_price_level', 'item_pv_level', \n",
    "       'context_page_id', 'shop_review_num_level', 'shop_star_level',\n",
    "      'match_category_proportion', 'match_property_proportion', \n",
    "       'predict_category_number', 'predict_property_number', \n",
    "      'isFirstCategoryIn', 'isLastCategoryIn',\n",
    "       'day_hour', 'weekday',\n",
    "       'lastOneHour_sameItem_count', 'lastOneHour_sameFirstCategory_count', 'lastOneHour_sameLastCategory_count',\n",
    "#        'history_sameItem_count', 'history_sameFirstCategory_count', 'history_sameLastCategory_count',\n",
    "       'is_history_sameItem', 'is_history_sameFirstCategory', 'is_history_sameLastCategory',\n",
    "       'is_highProportion_brand', 'is_highSale_brand', 'category_number', 'property_number',\n",
    "       'lastOneHour_sameBrand_count', 'lastOneHour_sameShop_count',\n",
    "#        'history_sameBrand_count', 'history_sameShop_count',\n",
    "       'is_history_sameBrand', 'is_history_sameShop',\n",
    "#        'is_history_firstClickItem', \n",
    "       'isLastOneHour_firstClickItem',\n",
    "#        'item_sales_price', 'item_sales_collected', 'item_sales_pv',\n",
    "#        'item_price_collected', 'item_price_pv', 'item_collected_pv',\n",
    "#        'user_gender_age', 'user_gender_occupation', 'user_gender_star', 'user_age_occupation', 'user_age_star', 'user_occupation_star',\n",
    "#        'shop_review_star'\n",
    "       'userItem_lastClickDeltaTime', 'userBrand_lastClickDeltaTime', 'userShop_lastClickDeltaTime', 'userFirstCategory_lastClickDeltaTime', 'userLastCategory_lastClickDeltaTime',\n",
    "       'shop_item_classNumber', 'brand_item_classNumber', 'city_item_classNumber', \n",
    "       'shop_user_classNumber', 'brand_user_classNumber', 'city_user_classNumber'\n",
    "      ]\n",
    "\n",
    "drop_fea = ['item_price_level_0', 'item_price_level_1', 'shop_star_level_lowHigh', #'is_history_sameItem', \n",
    "            'shop_star_level_middle', 'shop_review_num_level_lowHigh']\n",
    "def dropFeture(drop_fea, df):\n",
    "    for fea in drop_fea:\n",
    "        df = df.drop(fea, 1)\n",
    "    return df\n",
    "train_df = dropFeture(drop_fea, train_df)\n",
    "\n",
    "train_dataset = train_df.filter(regex = regex_string)\n",
    "train_dataset = pd.concat([train_dataset, train_df[fea]], axis = 1)\n",
    "train_dataset_label = train_df['is_trade']\n",
    "print(len(train_dataset.columns))\n",
    "print(train_dataset.columns)\n",
    "\n",
    "test_df = pd.read_csv('chusai_test_df.csv')\n",
    "test_dataset = test_df.filter(regex = regex_string)\n",
    "test_dataset = pd.concat([test_dataset, test_df[fea]], axis = 1)\n",
    "test_dataset = dropFeture(drop_fea, test_dataset)\n",
    "print(len(test_dataset.columns))\n",
    "print(test_dataset.columns)\n",
    "\n",
    "#初步先用前6天数据作为线下训练集，用第七天数据作为线下测试集\n",
    "train_dataset1 = train_df[train_df.day <= 22]\n",
    "train_dataset1_x = train_dataset1.filter(regex = regex_string)\n",
    "train_dataset1_x = pd.concat([train_dataset1_x, train_dataset1[fea]], axis = 1)\n",
    "train_dataset1_y = train_dataset1['is_trade']\n",
    "test_dataset1 = train_df[train_df.day == 23]\n",
    "test_dataset1_x = test_dataset1.filter(regex = regex_string)\n",
    "test_dataset1_x = pd.concat([test_dataset1_x, test_dataset1[fea]], axis = 1)\n",
    "test_dataset1_y = test_dataset1['is_trade']\n",
    "\n",
    "train_df['context_timestamp'] = train_df.context_timestamp.map(lambda x: datetime.fromtimestamp(x))\n",
    "test_df['context_timestamp'] = test_df.context_timestamp.map(lambda x: datetime.fromtimestamp(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XgbModel:\n",
    "    def __init__(self, feaNames=None, params={}):\n",
    "        self.feaNames = feaNames\n",
    "        self.params = {\n",
    "            'booster':'gbtree',\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric':'logloss',\n",
    "            'silent': True,\n",
    "            'lambda':11,\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 3,\n",
    "            'gamma': 0.3,\n",
    "            'subsample':0.9,\n",
    "            'colsample_bytree': 0.65,\n",
    "            'min_child_weight': 9,\n",
    "            'max_delta_step': 2,\n",
    "            # 'alpha':1600\n",
    "        }\n",
    "        for k,v in params.items():\n",
    "            self.params[k] = v\n",
    "        self.clf = None\n",
    "\n",
    "    def train(self, X, y, train_size=1, test_size=0.1, verbose=True, num_boost_round=1000, early_stopping_rounds=3):\n",
    "        if train_size==1:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "            X_train, y_train = X, y\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size)\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=self.feaNames)\n",
    "        dval = xgb.DMatrix(X_test, label=y_test, feature_names=self.feaNames)\n",
    "        watchlist = [(dtrain,'train'),(dval,'val')]\n",
    "        clf = xgb.train(\n",
    "            self.params, dtrain, \n",
    "            num_boost_round = num_boost_round, \n",
    "            evals = watchlist, \n",
    "            early_stopping_rounds = early_stopping_rounds,\n",
    "            verbose_eval=verbose\n",
    "        )\n",
    "        self.clf = clf\n",
    "\n",
    "    def trainCV(self, X, y, nFold=3, verbose=True, num_boost_round=1500, early_stopping_rounds=10):\n",
    "        dtrain = xgb.DMatrix(X, label=y, feature_names=self.feaNames)\n",
    "        cvResult = xgb.cv(\n",
    "            self.params, dtrain, \n",
    "            num_boost_round = num_boost_round, \n",
    "            nfold = nFold,\n",
    "            early_stopping_rounds = early_stopping_rounds,\n",
    "            verbose_eval=verbose\n",
    "        )\n",
    "        clf = xgb.train(\n",
    "            self.params, dtrain, \n",
    "            num_boost_round = cvResult.shape[0], \n",
    "        )\n",
    "        self.clf = clf\n",
    "\n",
    "    def gridSearch(self, X, y, nFold=3, verbose=1, num_boost_round=330):\n",
    "        paramsGrids = {\n",
    "            # 'n_estimators': [50+5*i for i in range(0,30)],\n",
    "            'gamma': [i/10 for i in range(0,10)],\n",
    "#             'max_depth': list(range(3,10))\n",
    "#             'min_child_weight': list(range(1,10))\n",
    "#              'subsample': [1-0.05*i for i in range(0,10)]\n",
    "#             'colsample_bytree': [1-0.05*i for i in range(0,10)]\n",
    "#             'lambda': list(range(5,15))\n",
    "            # 'reg_alpha':[1000+100*i for i in range(0,20)]\n",
    "            # 'max_delta_step': [0+1*i for i in range(0,8)]\n",
    "        }\n",
    "        gsearch = GridSearchCV(\n",
    "            estimator = xgb.XGBClassifier(\n",
    "                max_depth = self.params['max_depth'], \n",
    "                # gamma = self.params['gamma'],\n",
    "                learning_rate = self.params['eta'],\n",
    "                max_delta_step = self.params['max_delta_step'],\n",
    "                min_child_weight = self.params['min_child_weight'],\n",
    "                # subsample = self.params['subsample'],\n",
    "                colsample_bytree = self.params['colsample_bytree'],\n",
    "                silent = self.params['silent'],\n",
    "                # reg_alpha = self.params['alpha'],\n",
    "                n_estimators = num_boost_round\n",
    "            ),\n",
    "            param_grid = paramsGrids,\n",
    "            scoring = 'neg_log_loss',\n",
    "            cv = nFold,\n",
    "            verbose = verbose,\n",
    "            n_jobs = 4\n",
    "        )\n",
    "        gsearch.fit(X, y)\n",
    "        print(pd.DataFrame(gsearch.cv_results_))\n",
    "        print(gsearch.best_params_)\n",
    "        exit()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(xgb.DMatrix(X, feature_names=self.feaNames))\n",
    "\n",
    "    def getFeaScore(self, show=False):\n",
    "        fscore = self.clf.get_score()\n",
    "        feaNames = fscore.keys()\n",
    "        scoreDf = pd.DataFrame(index=feaNames, columns=['importance'])\n",
    "        for k,v in fscore.items():\n",
    "            scoreDf.loc[k, 'importance'] = v\n",
    "        if show:\n",
    "            print(scoreDf.sort_index(by=['importance'], ascending=False))\n",
    "        return scoreDf\n",
    "\n",
    "# 划分训练集和测试集\n",
    "def trainTestSplit(df, splitDate=pd.to_datetime('2018-09-23'), trainPeriod=3, testPeriod=1):\n",
    "    trainDf = df[(df.context_timestamp<splitDate)&(df.context_timestamp>=splitDate-timedelta(days=trainPeriod))]\n",
    "    testDf = df[(df.context_timestamp>=splitDate)&(df.context_timestamp<splitDate+timedelta(days=testPeriod))]\n",
    "    return (trainDf, testDf)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fea = train_df.columns\n",
    "\n",
    "# 测试模型效果\n",
    "costDf = pd.DataFrame(index=fea+['cost'])\n",
    "xgbModel = XgbModel(feaNames=fea)\n",
    "trainDf, testDf = trainTestSplit(train_df, pd.to_datetime('2018-09-23'), trainPeriod=7)\n",
    "# xgbModel.trainCV(trainDf[fea].values, trainDf['is_trade'].values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "0      67.372550         1.147380        -0.090962         -0.087461   \n",
      "1      66.497854         1.222886        -0.090968         -0.087467   \n",
      "2      67.568267         1.111672        -0.090987         -0.087504   \n",
      "3      68.353757         1.132333        -0.090953         -0.087514   \n",
      "4      67.603970         1.159069        -0.090946         -0.087503   \n",
      "5      67.386241         1.132262        -0.090964         -0.087475   \n",
      "6      66.471396         1.182733        -0.091022         -0.087499   \n",
      "7      64.647568         1.133347        -0.091038         -0.087470   \n",
      "8      64.011982         1.125286        -0.091037         -0.087420   \n",
      "9      49.575414         1.054277        -0.091030         -0.087444   \n",
      "\n",
      "  param_gamma          params  rank_test_score  split0_test_score  \\\n",
      "0           0  {'gamma': 0.0}                3          -0.090853   \n",
      "1         0.1  {'gamma': 0.1}                5          -0.090870   \n",
      "2         0.2  {'gamma': 0.2}                6          -0.090870   \n",
      "3         0.3  {'gamma': 0.3}                2          -0.090895   \n",
      "4         0.4  {'gamma': 0.4}                1          -0.090895   \n",
      "5         0.5  {'gamma': 0.5}                4          -0.090895   \n",
      "6         0.6  {'gamma': 0.6}                7          -0.090821   \n",
      "7         0.7  {'gamma': 0.7}               10          -0.090863   \n",
      "8         0.8  {'gamma': 0.8}                9          -0.090863   \n",
      "9         0.9  {'gamma': 0.9}                8          -0.090864   \n",
      "\n",
      "   split0_train_score  split1_test_score  split1_train_score  \\\n",
      "0           -0.087441          -0.091266           -0.087252   \n",
      "1           -0.087461          -0.091266           -0.087252   \n",
      "2           -0.087461          -0.091270           -0.087348   \n",
      "3           -0.087489          -0.091270           -0.087348   \n",
      "4           -0.087489          -0.091250           -0.087315   \n",
      "5           -0.087489          -0.091316           -0.087297   \n",
      "6           -0.087395          -0.091263           -0.087313   \n",
      "7           -0.087357          -0.091291           -0.087318   \n",
      "8           -0.087357          -0.091307           -0.087294   \n",
      "9           -0.087357          -0.091307           -0.087294   \n",
      "\n",
      "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
      "0          -0.090767           -0.087689      1.502783        0.066394   \n",
      "1          -0.090767           -0.087689      0.707133        0.017164   \n",
      "2          -0.090821           -0.087702      1.040352        0.026514   \n",
      "3          -0.090694           -0.087705      0.856071        0.061488   \n",
      "4          -0.090694           -0.087705      1.376811        0.062194   \n",
      "5          -0.090681           -0.087640      0.288406        0.021142   \n",
      "6          -0.090982           -0.087791      1.607890        0.047994   \n",
      "7          -0.090958           -0.087735      1.021916        0.041528   \n",
      "8          -0.090939           -0.087610      0.758031        0.020201   \n",
      "9          -0.090921           -0.087681     10.785319        0.118275   \n",
      "\n",
      "   std_test_score  std_train_score  \n",
      "0        0.000218         0.000179  \n",
      "1        0.000215         0.000178  \n",
      "2        0.000201         0.000148  \n",
      "3        0.000239         0.000147  \n",
      "4        0.000230         0.000159  \n",
      "5        0.000264         0.000140  \n",
      "6        0.000183         0.000209  \n",
      "7        0.000183         0.000188  \n",
      "8        0.000194         0.000137  \n",
      "9        0.000197         0.000170  \n",
      "{'gamma': 0.4}\n"
     ]
    }
   ],
   "source": [
    "xgbModel.gridSearch(trainDf[fea].values, trainDf['is_trade'].values)\n",
    "# for dt in pd.date_range(start='2018-09-21', end='2018-09-24', freq='D'):\n",
    "#     trainDf, testDf = trainTestSplit(train_df, dt, trainPeriod=7)\n",
    "#     xgbModel.gridSearch(trainDf[fea].values, trainDf['is_trade'].values)\n",
    "#     xgbModel.trainCV(trainDf[fea].values, trainDf['is_trade'].values)\n",
    "#     testDf.loc[:,'predict'] = xgbModel.predict(testDf[fea].values)\n",
    "#     scoreDf = xgbModel.getFeaScore()\n",
    "#     scoreDf.columns = [dt.strftime('%Y-%m-%d')]\n",
    "#     costDf = costDf.merge(scoreDf, how='left', left_index=True, right_index=True)\n",
    "#     cost = metrics.log_loss(testDf['is_trade'].values, testDf['predict'].values)\n",
    "#     costDf.loc['cost',dt.strftime('%Y-%m-%d')] = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
