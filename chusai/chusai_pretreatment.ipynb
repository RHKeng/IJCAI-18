{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import csv\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from datetime import *\n",
    "import matplotlib.pylab as pylab\n",
    "from pylab import *  \n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478138 entries, 0 to 478137\n",
      "Data columns (total 27 columns):\n",
      "instance_id                  478138 non-null int64\n",
      "item_id                      478138 non-null int64\n",
      "item_category_list           478138 non-null object\n",
      "item_property_list           478138 non-null object\n",
      "item_brand_id                478138 non-null int64\n",
      "item_city_id                 478138 non-null int64\n",
      "item_price_level             478138 non-null int64\n",
      "item_sales_level             478138 non-null int64\n",
      "item_collected_level         478138 non-null int64\n",
      "item_pv_level                478138 non-null int64\n",
      "user_id                      478138 non-null int64\n",
      "user_gender_id               478138 non-null int64\n",
      "user_age_level               478138 non-null int64\n",
      "user_occupation_id           478138 non-null int64\n",
      "user_star_level              478138 non-null int64\n",
      "context_id                   478138 non-null int64\n",
      "context_timestamp            478138 non-null int64\n",
      "context_page_id              478138 non-null int64\n",
      "predict_category_property    478138 non-null object\n",
      "shop_id                      478138 non-null int64\n",
      "shop_review_num_level        478138 non-null int64\n",
      "shop_review_positive_rate    478138 non-null float64\n",
      "shop_star_level              478138 non-null int64\n",
      "shop_score_service           478138 non-null float64\n",
      "shop_score_delivery          478138 non-null float64\n",
      "shop_score_description       478138 non-null float64\n",
      "is_trade                     478138 non-null int64\n",
      "dtypes: float64(4), int64(20), object(3)\n",
      "memory usage: 98.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#导入训练数据\n",
    "train_df = pd.read_csv('../../data/round1_ijcai_18_train_20180301.txt', sep=' ')\n",
    "print(train_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  context_timestamp  day  weekday\n",
      "0 2018-09-18 10:09:04         1537236544   18        1\n",
      "1 2018-09-18 12:00:32         1537243232   18        1\n",
      "2 2018-09-18 03:04:12         1537211052   18        1\n",
      "3 2018-09-18 06:17:50         1537222670   18        1\n",
      "4 2018-09-18 19:48:40         1537271320   18        1\n",
      "5 2018-09-18 23:00:55         1537282855   18        1\n",
      "6 2018-09-18 22:18:37         1537280317   18        1\n",
      "7 2018-09-18 16:58:40         1537261120   18        1\n",
      "8 2018-09-18 02:27:51         1537208871   18        1\n",
      "9 2018-09-18 23:43:10         1537285390   18        1\n"
     ]
    }
   ],
   "source": [
    "#尝试将时间戳转化为日期\n",
    "# train_df['date'] = train_df.context_timestamp.map(lambda x: datetime.datetime.fromtimestamp(x).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "train_df['date'] = train_df.context_timestamp.map(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "train_df['weekday'] = train_df['date'].map(lambda x: x.weekday())\n",
    "train_df['day'] = train_df['date'].map(lambda x: x.day)\n",
    "train_df['hour'] = train_df['date'].map(lambda x: x.hour)\n",
    "print(train_df[['date', 'context_timestamp', 'day', 'weekday']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           instance_id              item_id  \\\n",
      "0   108641074714126964  3412720377098676069   \n",
      "1  5754713551599725161  3412720377098676069   \n",
      "2   842679481291040981  3412720377098676069   \n",
      "3   937088850059189027  3412720377098676069   \n",
      "4  7975697065017708072  3412720377098676069   \n",
      "5  7764762765372067286  3412720377098676069   \n",
      "6  6956333474094867789   285660928590172217   \n",
      "7  8387099821892927911   285660928590172217   \n",
      "8  4021878205550012615  5202355029344881809   \n",
      "9  6499571365974135517   285660928590172217   \n",
      "\n",
      "                        item_category_list  \\\n",
      "0  7908382889764677758;5799347067982556520   \n",
      "1  7908382889764677758;5799347067982556520   \n",
      "2  7908382889764677758;5799347067982556520   \n",
      "3  7908382889764677758;5799347067982556520   \n",
      "4  7908382889764677758;5799347067982556520   \n",
      "5  7908382889764677758;5799347067982556520   \n",
      "6  7908382889764677758;8277336076276184272   \n",
      "7  7908382889764677758;8277336076276184272   \n",
      "8  7908382889764677758;5755694407684602296   \n",
      "9  7908382889764677758;8277336076276184272   \n",
      "\n",
      "                                  item_property_list        item_brand_id  \\\n",
      "0  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "1  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "2  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "3  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "4  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "5  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "6  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "7  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "8  2072967855524022579;5131280576272319091;263639...  5520678735822176314   \n",
      "9  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "\n",
      "          item_city_id  item_price_level  item_sales_level  \\\n",
      "0  3948283326616421003                 3                 3   \n",
      "1  3948283326616421003                 3                 3   \n",
      "2  3948283326616421003                 3                 3   \n",
      "3  3948283326616421003                 3                 3   \n",
      "4  3948283326616421003                 3                 3   \n",
      "5  3948283326616421003                 3                 3   \n",
      "6   548352491538518780                 8                 9   \n",
      "7   548352491538518780                 8                 9   \n",
      "8   548352491538518780                 8                 9   \n",
      "9   548352491538518780                 8                 9   \n",
      "\n",
      "   item_collected_level  item_pv_level        ...          \\\n",
      "0                     4             14        ...           \n",
      "1                     4             14        ...           \n",
      "2                     4             14        ...           \n",
      "3                     4             14        ...           \n",
      "4                     4             14        ...           \n",
      "5                     4             14        ...           \n",
      "6                     8             13        ...           \n",
      "7                     8             13        ...           \n",
      "8                    10             16        ...           \n",
      "9                     8             13        ...           \n",
      "\n",
      "   shop_score_description  is_trade                date  weekday  day  hour  \\\n",
      "0                1.000000         0 2018-09-18 10:09:04        1   18    10   \n",
      "1                1.000000         0 2018-09-18 12:00:32        1   18    12   \n",
      "2                1.000000         0 2018-09-18 03:04:12        1   18     3   \n",
      "3                1.000000         0 2018-09-18 06:17:50        1   18     6   \n",
      "4                1.000000         0 2018-09-18 19:48:40        1   18    19   \n",
      "5                1.000000         0 2018-09-18 23:00:55        1   18    23   \n",
      "6                0.969278         0 2018-09-18 22:18:37        1   18    22   \n",
      "7                0.969278         0 2018-09-18 16:58:40        1   18    16   \n",
      "8                0.969278         0 2018-09-18 02:27:51        1   18     2   \n",
      "9                0.969278         0 2018-09-18 23:43:10        1   18    23   \n",
      "\n",
      "   context_page_id_1  context_page_id_2 context_page_id_3  context_page_id_4  \n",
      "0                  0                  0                 1                  0  \n",
      "1                  1                  0                 0                  0  \n",
      "2                  1                  0                 0                  0  \n",
      "3                  0                  0                 0                  1  \n",
      "4                  1                  0                 0                  0  \n",
      "5                  0                  1                 0                  0  \n",
      "6                  1                  0                 0                  0  \n",
      "7                  1                  0                 0                  0  \n",
      "8                  1                  0                 0                  0  \n",
      "9                  0                  1                 0                  0  \n",
      "\n",
      "[10 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#提取跟广告商品展示页面编号相关的特征\n",
    "#第1页作为一个特征，2-5页作为一个特征，6-10页作为一个特征，10-20页作为一个特征\n",
    "def getPageIdFuture(df):\n",
    "    df['context_page_id_1'] = df['context_page_id'].map(lambda x: 1 if x == 4001 else 0)\n",
    "    df['context_page_id_2'] = df['context_page_id'].map(lambda x: 1 if ((x < 4006) & (x > 4001)) else 0)\n",
    "    df['context_page_id_3'] = df['context_page_id'].map(lambda x: 1 if ((x < 4011) & (x > 4005)) else 0)\n",
    "    df['context_page_id_4'] = df['context_page_id'].map(lambda x: 1 if ((x <= 4020) & (x > 4010)) else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getPageIdFuture(train_df)\n",
    "print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           instance_id              item_id  \\\n",
      "0   108641074714126964  3412720377098676069   \n",
      "1  5754713551599725161  3412720377098676069   \n",
      "2   842679481291040981  3412720377098676069   \n",
      "3   937088850059189027  3412720377098676069   \n",
      "4  7975697065017708072  3412720377098676069   \n",
      "5  7764762765372067286  3412720377098676069   \n",
      "6  6956333474094867789   285660928590172217   \n",
      "7  8387099821892927911   285660928590172217   \n",
      "8  4021878205550012615  5202355029344881809   \n",
      "9  6499571365974135517   285660928590172217   \n",
      "\n",
      "                        item_category_list  \\\n",
      "0  7908382889764677758;5799347067982556520   \n",
      "1  7908382889764677758;5799347067982556520   \n",
      "2  7908382889764677758;5799347067982556520   \n",
      "3  7908382889764677758;5799347067982556520   \n",
      "4  7908382889764677758;5799347067982556520   \n",
      "5  7908382889764677758;5799347067982556520   \n",
      "6  7908382889764677758;8277336076276184272   \n",
      "7  7908382889764677758;8277336076276184272   \n",
      "8  7908382889764677758;5755694407684602296   \n",
      "9  7908382889764677758;8277336076276184272   \n",
      "\n",
      "                                  item_property_list        item_brand_id  \\\n",
      "0  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "1  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "2  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "3  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "4  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "5  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "6  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "7  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "8  2072967855524022579;5131280576272319091;263639...  5520678735822176314   \n",
      "9  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "\n",
      "          item_city_id  item_price_level  item_sales_level  \\\n",
      "0  3948283326616421003                 3                 3   \n",
      "1  3948283326616421003                 3                 3   \n",
      "2  3948283326616421003                 3                 3   \n",
      "3  3948283326616421003                 3                 3   \n",
      "4  3948283326616421003                 3                 3   \n",
      "5  3948283326616421003                 3                 3   \n",
      "6   548352491538518780                 8                 9   \n",
      "7   548352491538518780                 8                 9   \n",
      "8   548352491538518780                 8                 9   \n",
      "9   548352491538518780                 8                 9   \n",
      "\n",
      "   item_collected_level  item_pv_level         ...          \\\n",
      "0                     4             14         ...           \n",
      "1                     4             14         ...           \n",
      "2                     4             14         ...           \n",
      "3                     4             14         ...           \n",
      "4                     4             14         ...           \n",
      "5                     4             14         ...           \n",
      "6                     8             13         ...           \n",
      "7                     8             13         ...           \n",
      "8                    10             16         ...           \n",
      "9                     8             13         ...           \n",
      "\n",
      "                 date  weekday  day  hour  context_page_id_1  \\\n",
      "0 2018-09-18 10:09:04        1   18    10                  0   \n",
      "1 2018-09-18 12:00:32        1   18    12                  1   \n",
      "2 2018-09-18 03:04:12        1   18     3                  1   \n",
      "3 2018-09-18 06:17:50        1   18     6                  0   \n",
      "4 2018-09-18 19:48:40        1   18    19                  1   \n",
      "5 2018-09-18 23:00:55        1   18    23                  0   \n",
      "6 2018-09-18 22:18:37        1   18    22                  1   \n",
      "7 2018-09-18 16:58:40        1   18    16                  1   \n",
      "8 2018-09-18 02:27:51        1   18     2                  1   \n",
      "9 2018-09-18 23:43:10        1   18    23                  0   \n",
      "\n",
      "   context_page_id_2  context_page_id_3  context_page_id_4 item_price_level_0  \\\n",
      "0                  0                  1                  0                  0   \n",
      "1                  0                  0                  0                  0   \n",
      "2                  0                  0                  0                  0   \n",
      "3                  0                  0                  1                  0   \n",
      "4                  0                  0                  0                  0   \n",
      "5                  1                  0                  0                  0   \n",
      "6                  0                  0                  0                  1   \n",
      "7                  0                  0                  0                  1   \n",
      "8                  0                  0                  0                  1   \n",
      "9                  1                  0                  0                  1   \n",
      "\n",
      "   item_price_level_1  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "5                   1  \n",
      "6                   0  \n",
      "7                   0  \n",
      "8                   0  \n",
      "9                   0  \n",
      "\n",
      "[10 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "#构造跟广告商品价格等级item_price_level相关的特征\n",
    "#对于0-3或者9以上的作为一个特征，4-8作为一个特征\n",
    "def getItemPriceLevelFuture(df):\n",
    "    df['item_price_level_0'] = df['item_price_level'].map(lambda x: 1 if ((x >= 4) & (x <= 8)) else 0)\n",
    "    df['item_price_level_1'] = df['item_price_level'].map(lambda x: 1 if ((x < 4) | (x > 8)) else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getItemPriceLevelFuture(train_df)\n",
    "print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                instance_id              item_id  \\\n",
      "478128  3006683903772995202  7876305779987282497   \n",
      "478129   810107468384208582   642074399208226630   \n",
      "478130   440724230912710850  8714352873114629036   \n",
      "478131  5307935891681475459  5040834653196495196   \n",
      "478132   477737900698382237  5040834653196495196   \n",
      "478133  5940763769799191887  5040834653196495196   \n",
      "478134  3387284546470665526  5040834653196495196   \n",
      "478135  5693770660150212848  5040834653196495196   \n",
      "478136  4623253188146764341  5040834653196495196   \n",
      "478137  8013124750038806831  3762437480819554366   \n",
      "\n",
      "                             item_category_list  \\\n",
      "478128  7908382889764677758;5799347067982556520   \n",
      "478129  7908382889764677758;2011981573061447208   \n",
      "478130  7908382889764677758;8277336076276184272   \n",
      "478131  7908382889764677758;5755694407684602296   \n",
      "478132  7908382889764677758;5755694407684602296   \n",
      "478133  7908382889764677758;5755694407684602296   \n",
      "478134  7908382889764677758;5755694407684602296   \n",
      "478135  7908382889764677758;5755694407684602296   \n",
      "478136  7908382889764677758;5755694407684602296   \n",
      "478137  7908382889764677758;5755694407684602296   \n",
      "\n",
      "                                       item_property_list  \\\n",
      "478128  2636395404473730413;3163265386149801264;734498...   \n",
      "478129  2636395404473730413;7344985833148694227;885142...   \n",
      "478130  2636395404473730413;2488701964620097331;124376...   \n",
      "478131  5131280576272319091;2636395404473730413;121077...   \n",
      "478132  5131280576272319091;2636395404473730413;121077...   \n",
      "478133  5131280576272319091;2636395404473730413;121077...   \n",
      "478134  5131280576272319091;2636395404473730413;121077...   \n",
      "478135  5131280576272319091;2636395404473730413;121077...   \n",
      "478136  5131280576272319091;2636395404473730413;121077...   \n",
      "478137  5131280576272319091;2636395404473730413;625945...   \n",
      "\n",
      "              item_brand_id         item_city_id  item_price_level  \\\n",
      "478128  3351806778234144687  4918413420989329604                 8   \n",
      "478129  3351806778234144687  4918413420989329604                 7   \n",
      "478130  3351806778234144687  4918413420989329604                 7   \n",
      "478131  2603815409272347112  3948283326616421003                 8   \n",
      "478132  2603815409272347112  3948283326616421003                 8   \n",
      "478133  2603815409272347112  3948283326616421003                 8   \n",
      "478134  2603815409272347112  3948283326616421003                 8   \n",
      "478135  2603815409272347112  3948283326616421003                 8   \n",
      "478136  2603815409272347112  3948283326616421003                 8   \n",
      "478137  6447766541123854191  7322157373578955368                 7   \n",
      "\n",
      "        item_sales_level  item_collected_level  item_pv_level  \\\n",
      "478128                 7                    12             13   \n",
      "478129                 8                    14             13   \n",
      "478130                10                    12             12   \n",
      "478131                10                    13             14   \n",
      "478132                10                    13             14   \n",
      "478133                10                    13             14   \n",
      "478134                10                    13             14   \n",
      "478135                10                    13             14   \n",
      "478136                10                    13             14   \n",
      "478137                 3                     4             11   \n",
      "\n",
      "              ...          weekday  day  hour  context_page_id_1  \\\n",
      "478128        ...                0   24    13                  1   \n",
      "478129        ...                0   24    14                  0   \n",
      "478130        ...                0   24    14                  1   \n",
      "478131        ...                0   24    18                  1   \n",
      "478132        ...                0   24    11                  1   \n",
      "478133        ...                0   24     7                  0   \n",
      "478134        ...                0   24    23                  0   \n",
      "478135        ...                0   24    20                  1   \n",
      "478136        ...                0   24    18                  1   \n",
      "478137        ...                0   24    19                  0   \n",
      "\n",
      "        context_page_id_2  context_page_id_3  context_page_id_4  \\\n",
      "478128                  0                  0                  0   \n",
      "478129                  1                  0                  0   \n",
      "478130                  0                  0                  0   \n",
      "478131                  0                  0                  0   \n",
      "478132                  0                  0                  0   \n",
      "478133                  0                  1                  0   \n",
      "478134                  1                  0                  0   \n",
      "478135                  0                  0                  0   \n",
      "478136                  0                  0                  0   \n",
      "478137                  0                  1                  0   \n",
      "\n",
      "        item_price_level_0 item_price_level_1  item_pv_level_low  \n",
      "478128                   1                  0                  1  \n",
      "478129                   1                  0                  1  \n",
      "478130                   1                  0                  1  \n",
      "478131                   1                  0                  1  \n",
      "478132                   1                  0                  1  \n",
      "478133                   1                  0                  1  \n",
      "478134                   1                  0                  1  \n",
      "478135                   1                  0                  1  \n",
      "478136                   1                  0                  1  \n",
      "478137                   1                  0                  1  \n",
      "\n",
      "[10 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#构造跟广告商品被展示次数等级item_pv_level相关的特征\n",
    "#对于等级小于10的样本作为一个特征，其余的采用onehot处理\n",
    "def getItemPvLevelFuture(df):\n",
    "    df['item_pv_level_low'] = df['item_pv_level'].map(lambda x: 1 if ((x <= 14) | (x == 21)) else 0)\n",
    "    df['item_pv_level_low'] = df['item_pv_level'].map(lambda x: 1 if ((x <= 20) | (x >= 15)) else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getItemPvLevelFuture(train_df)\n",
    "print(train_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           instance_id              item_id  \\\n",
      "0   108641074714126964  3412720377098676069   \n",
      "1  5754713551599725161  3412720377098676069   \n",
      "2   842679481291040981  3412720377098676069   \n",
      "3   937088850059189027  3412720377098676069   \n",
      "4  7975697065017708072  3412720377098676069   \n",
      "5  7764762765372067286  3412720377098676069   \n",
      "6  6956333474094867789   285660928590172217   \n",
      "7  8387099821892927911   285660928590172217   \n",
      "8  4021878205550012615  5202355029344881809   \n",
      "9  6499571365974135517   285660928590172217   \n",
      "\n",
      "                        item_category_list  \\\n",
      "0  7908382889764677758;5799347067982556520   \n",
      "1  7908382889764677758;5799347067982556520   \n",
      "2  7908382889764677758;5799347067982556520   \n",
      "3  7908382889764677758;5799347067982556520   \n",
      "4  7908382889764677758;5799347067982556520   \n",
      "5  7908382889764677758;5799347067982556520   \n",
      "6  7908382889764677758;8277336076276184272   \n",
      "7  7908382889764677758;8277336076276184272   \n",
      "8  7908382889764677758;5755694407684602296   \n",
      "9  7908382889764677758;8277336076276184272   \n",
      "\n",
      "                                  item_property_list        item_brand_id  \\\n",
      "0  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "1  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "2  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "3  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "4  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "5  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "6  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "7  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "8  2072967855524022579;5131280576272319091;263639...  5520678735822176314   \n",
      "9  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "\n",
      "          item_city_id  item_price_level  item_sales_level  \\\n",
      "0  3948283326616421003                 3                 3   \n",
      "1  3948283326616421003                 3                 3   \n",
      "2  3948283326616421003                 3                 3   \n",
      "3  3948283326616421003                 3                 3   \n",
      "4  3948283326616421003                 3                 3   \n",
      "5  3948283326616421003                 3                 3   \n",
      "6   548352491538518780                 8                 9   \n",
      "7   548352491538518780                 8                 9   \n",
      "8   548352491538518780                 8                 9   \n",
      "9   548352491538518780                 8                 9   \n",
      "\n",
      "   item_collected_level  item_pv_level              ...                day  \\\n",
      "0                     4             14              ...                 18   \n",
      "1                     4             14              ...                 18   \n",
      "2                     4             14              ...                 18   \n",
      "3                     4             14              ...                 18   \n",
      "4                     4             14              ...                 18   \n",
      "5                     4             14              ...                 18   \n",
      "6                     8             13              ...                 18   \n",
      "7                     8             13              ...                 18   \n",
      "8                    10             16              ...                 18   \n",
      "9                     8             13              ...                 18   \n",
      "\n",
      "   hour  context_page_id_1  context_page_id_2  context_page_id_3  \\\n",
      "0    10                  0                  0                  1   \n",
      "1    12                  1                  0                  0   \n",
      "2     3                  1                  0                  0   \n",
      "3     6                  0                  0                  0   \n",
      "4    19                  1                  0                  0   \n",
      "5    23                  0                  1                  0   \n",
      "6    22                  1                  0                  0   \n",
      "7    16                  1                  0                  0   \n",
      "8     2                  1                  0                  0   \n",
      "9    23                  0                  1                  0   \n",
      "\n",
      "   context_page_id_4  item_price_level_0  item_price_level_1  \\\n",
      "0                  0                   0                   1   \n",
      "1                  0                   0                   1   \n",
      "2                  0                   0                   1   \n",
      "3                  1                   0                   1   \n",
      "4                  0                   0                   1   \n",
      "5                  0                   0                   1   \n",
      "6                  0                   1                   0   \n",
      "7                  0                   1                   0   \n",
      "8                  0                   1                   0   \n",
      "9                  0                   1                   0   \n",
      "\n",
      "  item_pv_level_low  shop_review_num_level_lowHigh  \n",
      "0                 1                              1  \n",
      "1                 1                              1  \n",
      "2                 1                              1  \n",
      "3                 1                              1  \n",
      "4                 1                              1  \n",
      "5                 1                              1  \n",
      "6                 1                              0  \n",
      "7                 1                              0  \n",
      "8                 1                              0  \n",
      "9                 1                              0  \n",
      "\n",
      "[10 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "#构造跟店铺的评价数量等级相关的特征\n",
    "#对于等级小于等于5或者大于等于22的作为一个特征，其余的先采用onehot编码处理\n",
    "def getShopReviewNumLevelFuture(df):\n",
    "    df['shop_review_num_level_lowHigh'] = df['shop_review_num_level'].map(lambda x: 1 if ((x <= 5) | (x >= 22)) else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getShopReviewNumLevelFuture(train_df)\n",
    "print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           instance_id              item_id  \\\n",
      "0   108641074714126964  3412720377098676069   \n",
      "1  5754713551599725161  3412720377098676069   \n",
      "2   842679481291040981  3412720377098676069   \n",
      "3   937088850059189027  3412720377098676069   \n",
      "4  7975697065017708072  3412720377098676069   \n",
      "5  7764762765372067286  3412720377098676069   \n",
      "6  6956333474094867789   285660928590172217   \n",
      "7  8387099821892927911   285660928590172217   \n",
      "8  4021878205550012615  5202355029344881809   \n",
      "9  6499571365974135517   285660928590172217   \n",
      "\n",
      "                        item_category_list  \\\n",
      "0  7908382889764677758;5799347067982556520   \n",
      "1  7908382889764677758;5799347067982556520   \n",
      "2  7908382889764677758;5799347067982556520   \n",
      "3  7908382889764677758;5799347067982556520   \n",
      "4  7908382889764677758;5799347067982556520   \n",
      "5  7908382889764677758;5799347067982556520   \n",
      "6  7908382889764677758;8277336076276184272   \n",
      "7  7908382889764677758;8277336076276184272   \n",
      "8  7908382889764677758;5755694407684602296   \n",
      "9  7908382889764677758;8277336076276184272   \n",
      "\n",
      "                                  item_property_list        item_brand_id  \\\n",
      "0  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "1  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "2  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "3  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "4  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "5  2072967855524022579;5131280576272319091;263639...  1975590437749032870   \n",
      "6  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "7  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "8  2072967855524022579;5131280576272319091;263639...  5520678735822176314   \n",
      "9  2072967855524022579;5131280576272319091;263639...  9057103201734987852   \n",
      "\n",
      "          item_city_id  item_price_level  item_sales_level  \\\n",
      "0  3948283326616421003                 3                 3   \n",
      "1  3948283326616421003                 3                 3   \n",
      "2  3948283326616421003                 3                 3   \n",
      "3  3948283326616421003                 3                 3   \n",
      "4  3948283326616421003                 3                 3   \n",
      "5  3948283326616421003                 3                 3   \n",
      "6   548352491538518780                 8                 9   \n",
      "7   548352491538518780                 8                 9   \n",
      "8   548352491538518780                 8                 9   \n",
      "9   548352491538518780                 8                 9   \n",
      "\n",
      "   item_collected_level  item_pv_level          ...           \\\n",
      "0                     4             14          ...            \n",
      "1                     4             14          ...            \n",
      "2                     4             14          ...            \n",
      "3                     4             14          ...            \n",
      "4                     4             14          ...            \n",
      "5                     4             14          ...            \n",
      "6                     8             13          ...            \n",
      "7                     8             13          ...            \n",
      "8                    10             16          ...            \n",
      "9                     8             13          ...            \n",
      "\n",
      "   context_page_id_2  context_page_id_3  context_page_id_4  \\\n",
      "0                  0                  1                  0   \n",
      "1                  0                  0                  0   \n",
      "2                  0                  0                  0   \n",
      "3                  0                  0                  1   \n",
      "4                  0                  0                  0   \n",
      "5                  1                  0                  0   \n",
      "6                  0                  0                  0   \n",
      "7                  0                  0                  0   \n",
      "8                  0                  0                  0   \n",
      "9                  1                  0                  0   \n",
      "\n",
      "   item_price_level_0  item_price_level_1  item_pv_level_low  \\\n",
      "0                   0                   1                  1   \n",
      "1                   0                   1                  1   \n",
      "2                   0                   1                  1   \n",
      "3                   0                   1                  1   \n",
      "4                   0                   1                  1   \n",
      "5                   0                   1                  1   \n",
      "6                   1                   0                  1   \n",
      "7                   1                   0                  1   \n",
      "8                   1                   0                  1   \n",
      "9                   1                   0                  1   \n",
      "\n",
      "   shop_review_num_level_lowHigh  shop_star_level_lowHigh  \\\n",
      "0                              1                        1   \n",
      "1                              1                        1   \n",
      "2                              1                        1   \n",
      "3                              1                        1   \n",
      "4                              1                        1   \n",
      "5                              1                        1   \n",
      "6                              0                        0   \n",
      "7                              0                        0   \n",
      "8                              0                        0   \n",
      "9                              0                        0   \n",
      "\n",
      "  shop_star_level_middle  shop_star_level_loss  \n",
      "0                      0                     0  \n",
      "1                      0                     0  \n",
      "2                      0                     0  \n",
      "3                      0                     0  \n",
      "4                      0                     0  \n",
      "5                      0                     0  \n",
      "6                      1                     0  \n",
      "7                      1                     0  \n",
      "8                      1                     0  \n",
      "9                      1                     0  \n",
      "\n",
      "[10 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "#构造跟店铺星级编号相关的特征\n",
    "#由于存在缺失值，将缺失值作为一个种类，然后，将等级小于等于5008或者大于等于5019的作为一个种类，其余的作为一个种类\n",
    "def getShopStarLevelFuture(df):\n",
    "    df['shop_star_level_lowHigh'] = df['shop_star_level'].map(lambda x: 1 if (((x >= 4999) & (x <= 5008)) | (x >=5019)) else 0)\n",
    "    df['shop_star_level_middle'] = df['shop_star_level'].map(lambda x: 1 if ((x > 5008) & (x < 5019)) else 0)\n",
    "    df['shop_star_level_loss'] = df['shop_star_level'].map(lambda x: 1 if x == -1 else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getShopStarLevelFuture(train_df)\n",
    "print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hour  day_hour\n",
      "0    10         1\n",
      "1    12         1\n",
      "2     3         0\n",
      "3     6         0\n",
      "4    19         2\n",
      "5    23         3\n",
      "6    22         3\n",
      "7    16         1\n",
      "8     2         0\n",
      "9    23         3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#添加跟一天内时间点划分相关的数据，9-18,19-21,22-0,1-8\n",
    "def getDayHourFuture(df):\n",
    "    df['day_hour'] = 0\n",
    "    df['day_hour'][((df.hour <= 18) & (df.hour >= 9))] = 1\n",
    "    df['day_hour'][((df.hour <= 21) & (df.hour >= 19))] = 2\n",
    "    df['day_hour'][((df.hour == 23) | (df.hour == 22) | (df.hour == 0))] = 3\n",
    "    return df\n",
    "\n",
    "train_df = getDayHourFuture(train_df)\n",
    "print(train_df[['hour', 'day_hour']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [5799347067982556520, 509660095530134768, 5755...\n",
      "1           [5799347067982556520, 7908382889764677758]\n",
      "2    [5799347067982556520, 7258015885215914736, 790...\n",
      "3    [509660095530134768, 5799347067982556520, 7908...\n",
      "4           [5799347067982556520, 7908382889764677758]\n",
      "5    [5799347067982556520, 8710739180200009128, 575...\n",
      "6    [2011981573061447208, 8277336076276184272, 575...\n",
      "7    [2011981573061447208, 8277336076276184272, 575...\n",
      "8    [5755694407684602296, 5799347067982556520, 790...\n",
      "9    [8277336076276184272, 509660095530134768, 5799...\n",
      "Name: predict_category_list, dtype: object\n",
      "0                                {9148482949976129397}\n",
      "1    {9148482949976129397, 5195139481388729954, 917...\n",
      "2                                {5131280576272319091}\n",
      "3    {6165347051143749031, 9148482949976129397, 360...\n",
      "4                                {9172976955054793469}\n",
      "5           {9172976955054793469, 5131280576272319091}\n",
      "6                                {7199361004668592209}\n",
      "7                                {7199361004668592209}\n",
      "8                                {1354874066266948599}\n",
      "9    {820214312075361939, 9148482949976129397, 9389...\n",
      "Name: predict_property_list, dtype: object\n",
      "0    {5799347067982556520, 7908382889764677758}\n",
      "1    {5799347067982556520, 7908382889764677758}\n",
      "2    {5799347067982556520, 7908382889764677758}\n",
      "3    {5799347067982556520, 7908382889764677758}\n",
      "4    {5799347067982556520, 7908382889764677758}\n",
      "5    {5799347067982556520, 7908382889764677758}\n",
      "6    {7908382889764677758, 8277336076276184272}\n",
      "7    {7908382889764677758, 8277336076276184272}\n",
      "8    {7908382889764677758, 5755694407684602296}\n",
      "9    {7908382889764677758, 8277336076276184272}\n",
      "Name: real_item_category_list, dtype: object\n",
      "0    {720840888466250585, 7270669313837600482, 8838...\n",
      "1    {720840888466250585, 7270669313837600482, 8838...\n",
      "2    {720840888466250585, 7270669313837600482, 8838...\n",
      "3    {720840888466250585, 7270669313837600482, 8838...\n",
      "4    {720840888466250585, 7270669313837600482, 8838...\n",
      "5    {720840888466250585, 7270669313837600482, 8838...\n",
      "6    {615076485672811995, 3802510553218572927, 2559...\n",
      "7    {615076485672811995, 3802510553218572927, 2559...\n",
      "8    {1665611025031010859, 5119621442439839441, 207...\n",
      "9    {615076485672811995, 3802510553218572927, 2559...\n",
      "Name: item_property_list, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def addSet(setList):\n",
    "    allSet = []\n",
    "    for member in setList:\n",
    "        allSet = allSet + member\n",
    "    allSet = set(allSet)\n",
    "    return allSet\n",
    "\n",
    "#处理跟商品类目和属性相关的特征\n",
    "def getCategoryFuture(df):\n",
    "    df['predict_category_list'] = df['predict_category_property'].map(lambda x: [] if x == np.nan else list(kv.split(':')[0] for kv in str(x).split(';')))\n",
    "    df['predict_category_set'] = df['predict_category_list'].map(lambda x: set(x))\n",
    "    df['real_item_category_list'] = df['item_category_list'].map(lambda x: set(x.split(';')))\n",
    "    \n",
    "    df['predict_property_list'] = df['predict_category_property'].map(lambda x: [] if x == np.nan else ((kv.split(':')[1].split(',') if kv.split(':')[1]!='-1' else []) if len(kv.split(':')) >= 2 else [] for kv in str(x).split(';')))\n",
    "    df['predict_property_list'] = df['predict_property_list'].map(lambda x: addSet(x))\n",
    "    df['item_property_list'] = df['item_property_list'].map(lambda x: set(x.split(';')))\n",
    "    return df\n",
    "\n",
    "train_df = getCategoryFuture(train_df)\n",
    "print(train_df['predict_category_list'].head(10))\n",
    "print(train_df['predict_property_list'].head(10))\n",
    "print(train_df['real_item_category_list'].head(10))\n",
    "print(train_df['item_property_list'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_category_proportion  match_property_proportion\n",
      "0                   0.400000                   0.000000\n",
      "1                   1.000000                   0.200000\n",
      "2                   0.666667                   1.000000\n",
      "3                   0.400000                   0.000000\n",
      "4                   1.000000                   1.000000\n",
      "5                   0.400000                   1.000000\n",
      "6                   0.333333                   1.000000\n",
      "7                   0.333333                   1.000000\n",
      "8                   0.333333                   0.000000\n",
      "9                   0.333333                   0.666667\n"
     ]
    }
   ],
   "source": [
    "def getMatchProportion(df):\n",
    "    match_category_proportion = []\n",
    "    match_property_proportion = []\n",
    "    for x,y,m,n in df[['real_item_category_list', 'predict_category_set', 'item_property_list', 'predict_property_list']].values:\n",
    "        match_category = x & y\n",
    "        match_property = m & n\n",
    "        if len(y) > 0:\n",
    "            category_proportion = len(match_category) / len(y)\n",
    "            match_category_proportion.append(category_proportion)\n",
    "        else:\n",
    "            match_category_proportion.append(0)\n",
    "        if len(n) > 0:\n",
    "            property_proportion = len(match_property) / len(n)\n",
    "            match_property_proportion.append(property_proportion)\n",
    "        else:\n",
    "            match_property_proportion.append(0)\n",
    "    df['match_category_proportion'] = match_category_proportion\n",
    "    df['match_property_proportion'] = match_property_proportion\n",
    "    return df\n",
    "\n",
    "train_df = getMatchProportion(train_df)\n",
    "print(train_df[['match_category_proportion', 'match_property_proportion']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predict_category_number  predict_property_number  is_trade\n",
      "0                        5                        1         0\n",
      "1                        2                        5         0\n",
      "2                        3                        1         0\n",
      "3                        5                        8         0\n",
      "4                        2                        1         0\n",
      "5                        5                        2         0\n",
      "6                        6                        1         0\n",
      "7                        6                        1         0\n",
      "8                        6                        1         0\n",
      "9                        6                        3         0\n"
     ]
    }
   ],
   "source": [
    "#构造跟预测数目相关的特征\n",
    "def getPredictNumber(df):\n",
    "    df['predict_category_number'] = df['predict_category_set'].map(lambda x: len(x))\n",
    "    df['predict_property_number'] = df['predict_property_list'].map(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "train_df = getPredictNumber(train_df)\n",
    "print(train_df[['predict_category_number', 'predict_property_number', 'is_trade']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   isFirstCategoryIn  isLastCategoryIn  is_trade\n",
      "0                  1                 1         0\n",
      "1                  1                 1         0\n",
      "2                  1                 1         0\n",
      "3                  0                 0         0\n",
      "4                  1                 1         0\n",
      "5                  1                 1         0\n",
      "6                  0                 0         0\n",
      "7                  0                 0         0\n",
      "8                  1                 0         0\n",
      "9                  1                 1         0\n"
     ]
    }
   ],
   "source": [
    "#构造跟类目预测精确性相关的特征\n",
    "def getPredictAccuracy(df):\n",
    "    isFirstCategoryIn = []\n",
    "    isLastCategoryIn = []\n",
    "    for x,y in df[['real_item_category_list', 'predict_category_list']].values:\n",
    "        if y[0] in x:\n",
    "            isFirstCategoryIn.append(1)\n",
    "        else:\n",
    "            isFirstCategoryIn.append(0)\n",
    "        if y[len(y)-1] in x:\n",
    "            isLastCategoryIn.append(1)\n",
    "        else:\n",
    "            isLastCategoryIn.append(0)\n",
    "    df['isFirstCategoryIn'] = isFirstCategoryIn\n",
    "    df['isLastCategoryIn'] = isLastCategoryIn\n",
    "    return df\n",
    "\n",
    "train_df = getPredictAccuracy(train_df)\n",
    "print(train_df[['isFirstCategoryIn', 'isLastCategoryIn', 'is_trade']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df['difference'] = train_df['lastOneHour_sameItem_count'] - train_df['lastOneHour_sameShop_count']\n",
    "# print(len(train_df['instance_id'][train_df.difference != 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  item_property_list  property_number  \\\n",
      "0  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "1  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "2  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "3  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "4  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "5  {720840888466250585, 7270669313837600482, 8838...               22   \n",
      "6  {615076485672811995, 3802510553218572927, 2559...               50   \n",
      "7  {615076485672811995, 3802510553218572927, 2559...               50   \n",
      "8  {1665611025031010859, 5119621442439839441, 207...               46   \n",
      "9  {615076485672811995, 3802510553218572927, 2559...               50   \n",
      "\n",
      "   category_number  \n",
      "0                2  \n",
      "1                2  \n",
      "2                2  \n",
      "3                2  \n",
      "4                2  \n",
      "5                2  \n",
      "6                2  \n",
      "7                2  \n",
      "8                2  \n",
      "9                2  \n"
     ]
    }
   ],
   "source": [
    "#添加商品属性个数以及类目个数特征\n",
    "def getCPNumber(df):\n",
    "    df['category_number'] = df['item_category_list'].map(lambda x: len(x.split(';')))\n",
    "    df['property_number'] = df['item_property_list'].map(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "train_df = getCPNumber(train_df)\n",
    "print(train_df[['item_property_list', 'property_number', 'category_number']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "24\n",
      "            item_brand_id  is_highProportion_brand  is_highSale_brand\n",
      "14    9057103201734987852                        0                  0\n",
      "52    7066302540842412840                        0                  1\n",
      "55    7066302540842412840                        0                  1\n",
      "83    7066302540842412840                        0                  1\n",
      "129   7066302540842412840                        0                  1\n",
      "271   7066302540842412840                        0                  1\n",
      "816   7066302540842412840                        0                  1\n",
      "1068  7066302540842412840                        0                  1\n",
      "1109  7066302540842412840                        0                  1\n",
      "1576  7066302540842412840                        0                  1\n",
      "1837  7066302540842412840                        0                  1\n",
      "1980   605266119463963358                        0                  0\n",
      "1996   605266119463963358                        0                  0\n",
      "2017   605266119463963358                        0                  0\n",
      "2023   605266119463963358                        0                  0\n",
      "2038   605266119463963358                        0                  0\n",
      "2075   605266119463963358                        0                  0\n",
      "2126  1869485793196349073                        0                  0\n",
      "2174  5738287572601304102                        0                  0\n",
      "2194  5738287572601304102                        0                  0\n",
      "2195  5738287572601304102                        0                  0\n",
      "2201  5738287572601304102                        0                  0\n",
      "2367  7838285046767229711                        0                  1\n",
      "2421   448955875785543916                        0                  1\n",
      "2446   448955875785543916                        0                  1\n",
      "2473   448955875785543916                        0                  1\n",
      "2474   448955875785543916                        0                  1\n",
      "2515   448955875785543916                        0                  1\n",
      "2645   448955875785543916                        0                  1\n",
      "2671   448955875785543916                        0                  1\n"
     ]
    }
   ],
   "source": [
    "#首先获取转正率大于0.1以及转正样本数大于50的品牌集合\n",
    "train_df_positive_brand = train_df[['item_brand_id']][train_df.is_trade == 1].drop_duplicates()\n",
    "train_df_positive_brand['positive_counts'] = train_df_positive_brand['item_brand_id'].map(lambda x: len(train_df['item_brand_id'][(train_df.is_trade == 1) & (train_df.item_brand_id == x)])) \n",
    "train_df_positive_brand['all_counts'] = train_df_positive_brand['item_brand_id'].map(lambda x: len(train_df['item_brand_id'][(train_df.item_brand_id == x)])) \n",
    "train_df_positive_brand['proportion'] = train_df_positive_brand['positive_counts'] / train_df_positive_brand['all_counts']\n",
    "train_df_positive_brand['proportion_label'] = train_df_positive_brand.proportion.map(lambda x: 0 if math.isnan(x) else int(x * 10))\n",
    "proportion_brandId_set = set(train_df_positive_brand['item_brand_id'][train_df_positive_brand.proportion > 0.1])\n",
    "number_brandId_set = set(train_df_positive_brand['item_brand_id'][train_df_positive_brand.positive_counts > 50])\n",
    "print(len(proportion_brandId_set))\n",
    "print(len(number_brandId_set))\n",
    "\n",
    "#处理跟品牌相关的特征，转正率大于0.1的作为一个特征，转正样本数大于50的也作为一个特征\n",
    "def getBrandFuture(df, proportion_brandId_set, number_brandId_set):\n",
    "    df['is_highProportion_brand'] = df['item_brand_id'].map(lambda x: 1 if x in proportion_brandId_set else 0)\n",
    "    df['is_highSale_brand'] = df['item_brand_id'].map(lambda x: 1 if x in number_brandId_set else 0)\n",
    "    return df\n",
    "\n",
    "train_df = getBrandFuture(train_df, proportion_brandId_set, number_brandId_set)\n",
    "print(train_df[['item_brand_id', 'is_highProportion_brand', 'is_highSale_brand']][train_df.is_trade == 1].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       item_sales_level  item_price_level  item_sales_price\n",
      "11498                -1                 7               -17\n",
      "11559                -1                 7               -17\n",
      "11565                -1                 7               -17\n",
      "11677                -1                 5               -15\n",
      "12838                -1                 5               -15\n",
      "12842                -1                 5               -15\n",
      "12846                -1                 5               -15\n",
      "12859                -1                 5               -15\n",
      "12877                -1                 5               -15\n",
      "12887                -1                 5               -15\n"
     ]
    }
   ],
   "source": [
    "#获取组合特征函数\n",
    "def zuheFuture(df, colName1, colName2, newColName):\n",
    "    df[newColName] = df[colName1].astype(str) + df[colName2].astype(str)\n",
    "    df[newColName] = df[newColName].astype(int)\n",
    "    return df\n",
    "\n",
    "#尝试获取跟广告商品相关的组合特征\n",
    "def getItemZuheFuture(df):\n",
    "    df = zuheFuture(df, 'item_sales_level', 'item_price_level', 'item_sales_price')\n",
    "    df = zuheFuture(df, 'item_sales_level', 'item_collected_level', 'item_sales_collected')\n",
    "    df = zuheFuture(df, 'item_sales_level', 'item_pv_level', 'item_sales_pv')\n",
    "    df = zuheFuture(df, 'item_price_level', 'item_collected_level', 'item_price_collected')\n",
    "    df = zuheFuture(df, 'item_price_level', 'item_pv_level', 'item_price_pv')\n",
    "    df = zuheFuture(df, 'item_collected_level', 'item_pv_level', 'item_collected_pv')\n",
    "    return df\n",
    "\n",
    "train_df = getItemZuheFuture(train_df)\n",
    "print(train_df[['item_sales_level', 'item_price_level', 'item_sales_price']][train_df.item_sales_price < 0].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_gender_id  user_age_level  user_gender_age\n",
      "0               1            1003            11003\n",
      "1               0            1002             1002\n",
      "2               0            1003             1003\n",
      "3               1            1004            11004\n",
      "4               0            1002             1002\n",
      "5               1            1004            11004\n",
      "6               1            1006            11006\n",
      "7               0            1002             1002\n",
      "8               0            1003             1003\n",
      "9               0            1003             1003\n"
     ]
    }
   ],
   "source": [
    "#尝试获取跟用户相关的组合特征\n",
    "def getUserZuheFuture(df):\n",
    "    temp = df.copy()\n",
    "    for col in ['user_age_level', 'user_occupation_id', 'user_star_level']:\n",
    "        temp[col] = temp[col].map(lambda x: 0 if x == -1 else x)\n",
    "    \n",
    "    temp = zuheFuture(temp, 'user_gender_id', 'user_age_level', 'user_gender_age')\n",
    "    temp = zuheFuture(temp, 'user_gender_id', 'user_occupation_id', 'user_gender_occupation')\n",
    "    temp = zuheFuture(temp, 'user_gender_id', 'user_star_level', 'user_gender_star')\n",
    "    temp = zuheFuture(temp, 'user_age_level', 'user_occupation_id', 'user_age_occupation')\n",
    "    temp = zuheFuture(temp, 'user_age_level', 'user_star_level', 'user_age_star')\n",
    "    temp = zuheFuture(temp, 'user_occupation_id', 'user_star_level', 'user_occupation_star')\n",
    "    \n",
    "    for col in ['user_gender_age', 'user_gender_occupation', 'user_gender_star', 'user_age_occupation', 'user_age_star', 'user_occupation_star']:\n",
    "        df[col] = temp[col]\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = getUserZuheFuture(train_df)\n",
    "print(train_df[['user_gender_id', 'user_age_level', 'user_gender_age']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shop_review_num_level  shop_star_level  shop_review_star\n",
      "0                      4             5002             45002\n",
      "1                      4             5002             45002\n",
      "2                      4             5002             45002\n",
      "3                      4             5002             45002\n",
      "4                      4             5002             45002\n",
      "5                      4             5002             45002\n",
      "6                     15             5012            155012\n",
      "7                     15             5012            155012\n",
      "8                     15             5012            155012\n",
      "9                     15             5012            155012\n"
     ]
    }
   ],
   "source": [
    "#尝试获取跟店铺相关的组合特征\n",
    "def getShopZuheFuture(df):\n",
    "    df = zuheFuture(df, 'shop_review_num_level', 'shop_star_level', 'shop_review_star')\n",
    "    return df\n",
    "\n",
    "train_df = getShopZuheFuture(train_df)\n",
    "print(train_df[['shop_review_num_level', 'shop_star_level', 'shop_review_star']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61259 entries, 0 to 61258\n",
      "Data columns (total 26 columns):\n",
      "instance_id                  61259 non-null int64\n",
      "item_id                      61259 non-null int64\n",
      "item_category_list           61259 non-null object\n",
      "item_property_list           61259 non-null object\n",
      "item_brand_id                61259 non-null int64\n",
      "item_city_id                 61259 non-null int64\n",
      "item_price_level             61259 non-null int64\n",
      "item_sales_level             61259 non-null int64\n",
      "item_collected_level         61259 non-null int64\n",
      "item_pv_level                61259 non-null int64\n",
      "user_id                      61259 non-null int64\n",
      "user_gender_id               61259 non-null int64\n",
      "user_age_level               61259 non-null int64\n",
      "user_occupation_id           61259 non-null int64\n",
      "user_star_level              61259 non-null int64\n",
      "context_id                   61259 non-null int64\n",
      "context_timestamp            61259 non-null int64\n",
      "context_page_id              61259 non-null int64\n",
      "predict_category_property    61259 non-null object\n",
      "shop_id                      61259 non-null int64\n",
      "shop_review_num_level        61259 non-null int64\n",
      "shop_review_positive_rate    61259 non-null float64\n",
      "shop_star_level              61259 non-null int64\n",
      "shop_score_service           61259 non-null float64\n",
      "shop_score_delivery          61259 non-null float64\n",
      "shop_score_description       61259 non-null float64\n",
      "dtypes: float64(4), int64(19), object(3)\n",
      "memory usage: 12.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#导入初赛测试集数据\n",
    "test_df_a = pd.read_csv('../../data/round1_ijcai_18_test_a_20180301.txt', sep=' ')\n",
    "test_df_b = pd.read_csv('../../data/round1_ijcai_18_test_b_20180418.txt', sep=' ')\n",
    "\n",
    "test_df = pd.concat([test_df_a, test_df_b], ignore_index=True)\n",
    "\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           instance_id              item_id  \\\n",
      "0  2475218615076601065  2275895163219263378   \n",
      "1   398316874173557226  7096238490711246967   \n",
      "2  6586402638209028583  7096238490711246967   \n",
      "3  1040996105851528465  7096238490711246967   \n",
      "4  6316278569655873454  7096238490711246967   \n",
      "5   868158305045921978  7096238490711246967   \n",
      "6  5713520501786699854  1171140458228333440   \n",
      "7   932945015407923184  7020520887593189887   \n",
      "8  1919197847086752313  8143258757857432437   \n",
      "9   304887065966615346  8143258757857432437   \n",
      "\n",
      "                        item_category_list  \\\n",
      "0  7908382889764677758;8277336076276184272   \n",
      "1  7908382889764677758;5755694407684602296   \n",
      "2  7908382889764677758;5755694407684602296   \n",
      "3  7908382889764677758;5755694407684602296   \n",
      "4  7908382889764677758;5755694407684602296   \n",
      "5  7908382889764677758;5755694407684602296   \n",
      "6  7908382889764677758;4879721024980945592   \n",
      "7  7908382889764677758;2011981573061447208   \n",
      "8  7908382889764677758;2011981573061447208   \n",
      "9  7908382889764677758;2011981573061447208   \n",
      "\n",
      "                                  item_property_list        item_brand_id  \\\n",
      "0  {6971134363351686861, 3965165427527476577, 409...  7838285046767229711   \n",
      "1  {5706520677554380710, 3625609447173810282, 159...  8126195666233054089   \n",
      "2  {5706520677554380710, 3625609447173810282, 159...  8126195666233054089   \n",
      "3  {5706520677554380710, 3625609447173810282, 159...  8126195666233054089   \n",
      "4  {5706520677554380710, 3625609447173810282, 159...  8126195666233054089   \n",
      "5  {5706520677554380710, 3625609447173810282, 159...  8126195666233054089   \n",
      "6  {720840888466250585, 4696616841982410243, 3163...  1547983184598012595   \n",
      "7  {207612925929709000, 8198562711061878538, 3667...  8324857885829459863   \n",
      "8  {9144923089074240656, 4088043395214833908, 819...  8324857885829459863   \n",
      "9  {9144923089074240656, 4088043395214833908, 819...  8324857885829459863   \n",
      "\n",
      "          item_city_id  item_price_level  item_sales_level  \\\n",
      "0  7534238860363577544                 7                 6   \n",
      "1  3948283326616421003                 6                 9   \n",
      "2  3948283326616421003                 6                 9   \n",
      "3  3948283326616421003                 6                 9   \n",
      "4  3948283326616421003                 6                 9   \n",
      "5  3948283326616421003                 6                 9   \n",
      "6  8072963182326625214                 5                 6   \n",
      "7  1019055478500227370                 7                10   \n",
      "8  1019055478500227370                 8                10   \n",
      "9  1019055478500227370                 8                10   \n",
      "\n",
      "   item_collected_level  item_pv_level        ...         \\\n",
      "0                     8             14        ...          \n",
      "1                     8             16        ...          \n",
      "2                     8             16        ...          \n",
      "3                     8             16        ...          \n",
      "4                     8             16        ...          \n",
      "5                     8             16        ...          \n",
      "6                     6             15        ...          \n",
      "7                    11             14        ...          \n",
      "8                    13             15        ...          \n",
      "9                    13             15        ...          \n",
      "\n",
      "   item_price_collected  item_price_pv  item_collected_pv  user_gender_age  \\\n",
      "0                    78            714                814             1002   \n",
      "1                    68            616                816            11004   \n",
      "2                    68            616                816             1004   \n",
      "3                    68            616                816            11003   \n",
      "4                    68            616                816             1002   \n",
      "5                    68            616                816             1003   \n",
      "6                    56            515                615             1004   \n",
      "7                   711            714               1114            11001   \n",
      "8                   813            815               1315             1002   \n",
      "9                   813            815               1315             1004   \n",
      "\n",
      "   user_gender_occupation  user_gender_star  user_age_occupation  \\\n",
      "0                    2005              3001             10022005   \n",
      "1                   12002             13006             10042002   \n",
      "2                    2002              3004             10042002   \n",
      "3                   12002             13007             10032002   \n",
      "4                    2003              3002             10022003   \n",
      "5                    2005              3006             10032005   \n",
      "6                    2002              3006             10042002   \n",
      "7                   12005             13002             10012005   \n",
      "8                    2002              3007             10022002   \n",
      "9                    2002              3007             10042002   \n",
      "\n",
      "   user_age_star user_occupation_star  shop_review_star  \n",
      "0       10023001             20053001            135011  \n",
      "1       10043006             20023006            145012  \n",
      "2       10043004             20023004            145012  \n",
      "3       10033007             20023007            145012  \n",
      "4       10023002             20033002            145012  \n",
      "5       10033006             20053006            145012  \n",
      "6       10043006             20023006            165013  \n",
      "7       10013002             20053002            155012  \n",
      "8       10023007             20023007            155012  \n",
      "9       10043007             20023007            155012  \n",
      "\n",
      "[10 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "#对测试集和训练集采取相同的处理\n",
    "test_df['date'] = test_df.context_timestamp.map(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "test_df['weekday'] = test_df['date'].map(lambda x: x.weekday())\n",
    "test_df['day'] = test_df['date'].map(lambda x: x.day)\n",
    "test_df['hour'] = test_df['date'].map(lambda x: x.hour)\n",
    "test_df = getDayHourFuture(test_df)\n",
    "\n",
    "test_df = getPageIdFuture(test_df)\n",
    "\n",
    "test_df = getItemPriceLevelFuture(test_df)\n",
    "\n",
    "test_df = getItemPvLevelFuture(test_df)\n",
    "\n",
    "test_df = getShopReviewNumLevelFuture(test_df)\n",
    "\n",
    "test_df = getShopStarLevelFuture(test_df)\n",
    "\n",
    "test_df = getCategoryFuture(test_df)\n",
    "test_df = getMatchProportion(test_df)\n",
    "test_df = getPredictNumber(test_df)\n",
    "test_df = getPredictAccuracy(test_df)\n",
    "\n",
    "test_df['real_first_category'] = test_df['item_category_list'].map(lambda x: np.nan if len(x.split(';')) < 1 else x.split(';')[0])\n",
    "test_df['real_last_category'] = test_df['item_category_list'].map(lambda x: np.nan if len(x.split(';')) < 1 else x[len(x.split(';')) -1])\n",
    "\n",
    "test_df = getBrandFuture(test_df, proportion_brandId_set, number_brandId_set)\n",
    "\n",
    "test_df = getCPNumber(test_df)\n",
    "\n",
    "test_df = getItemZuheFuture(test_df)\n",
    "test_df = getUserZuheFuture(test_df)\n",
    "test_df = getShopZuheFuture(test_df)\n",
    "\n",
    "print(test_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneHour_sameItem_count\n",
      "0 2018-09-18 10:09:04                         0.0\n",
      "1 2018-09-18 12:00:32                         0.0\n",
      "2 2018-09-18 03:04:12                         0.0\n",
      "3 2018-09-18 06:17:50                         0.0\n",
      "4 2018-09-18 19:48:40                         0.0\n",
      "5 2018-09-18 23:00:55                         0.0\n",
      "6 2018-09-18 22:18:37                         0.0\n",
      "7 2018-09-18 16:58:40                         0.0\n",
      "8 2018-09-18 02:27:51                         0.0\n",
      "9 2018-09-18 23:43:10                         0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击某个相同商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneHourSameItemCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item'] = tempDf['user_item'].shift(1)\n",
    "    tempDf['last_user_item'] = tempDf['last_user_item']==tempDf['user_item']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameItem_count'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_item', 'date']], tempDf[['user_item', 'date', 'lastOneHour_sameItem_count']], on = ['user_item', 'date'], how = 'left')\n",
    "#     print(temp_df[['user_item', 'date']].head())\n",
    "#     print(tempDf[['user_item', 'date', 'lastOneHour_sameItem_count']][tempDf.user_item == '15383240786656120175586531724608162781'].head())\n",
    "#     print(temp[temp.lastOneHour_sameItem_count > 0].head())\n",
    "    train_df['lastOneHour_sameItem_count'] = temp['lastOneHour_sameItem_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneHour_sameItem_count'] = temp['lastOneHour_sameItem_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneHourSameItemCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneHour_sameItem_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneHour_sameFirstCategory_count\n",
      "0 2018-09-18 10:09:04                                  0.0\n",
      "1 2018-09-18 12:00:32                                  1.0\n",
      "2 2018-09-18 03:04:12                                  0.0\n",
      "3 2018-09-18 06:17:50                                  0.0\n",
      "4 2018-09-18 19:48:40                                  0.0\n",
      "5 2018-09-18 23:00:55                                  1.0\n",
      "6 2018-09-18 22:18:37                                  7.0\n",
      "7 2018-09-18 16:58:40                                  0.0\n",
      "8 2018-09-18 02:27:51                                  0.0\n",
      "9 2018-09-18 23:43:10                                  3.0\n"
     ]
    }
   ],
   "source": [
    "#构造跟商品实际的根类目和叶子类目特征\n",
    "train_df['real_first_category'] = train_df['item_category_list'].map(lambda x: np.nan if len(x.split(';')) < 1 else x.split(';')[0])\n",
    "train_df['real_last_category'] = train_df['item_category_list'].map(lambda x: np.nan if len(x.split(';')) < 1 else x[len(x.split(';')) -1])\n",
    "\n",
    "# 统计过去一个小时某用户点击同种根类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneHourSameFirstCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_first_category', 'date', 'instance_id']], test_df[['user_id', 'real_first_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_first_category_str'] = temp_df['real_first_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_first_category'] = temp_df['user_id_str'] + temp_df['real_first_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_first_category','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameFirstCategory_count'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_real_first_category', 'date']], tempDf[['user_real_first_category', 'date', 'lastOneHour_sameFirstCategory_count']], on = ['user_real_first_category', 'date'], how = 'left')\n",
    "    train_df['lastOneHour_sameFirstCategory_count'] = temp['lastOneHour_sameFirstCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneHour_sameFirstCategory_count'] = temp['lastOneHour_sameFirstCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneHourSameFirstCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneHour_sameFirstCategory_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneHour_sameLastCategory_count\n",
      "0 2018-09-18 10:09:04                                 0.0\n",
      "1 2018-09-18 12:00:32                                 1.0\n",
      "2 2018-09-18 03:04:12                                 0.0\n",
      "3 2018-09-18 06:17:50                                 0.0\n",
      "4 2018-09-18 19:48:40                                 0.0\n",
      "5 2018-09-18 23:00:55                                 1.0\n",
      "6 2018-09-18 22:18:37                                 7.0\n",
      "7 2018-09-18 16:58:40                                 0.0\n",
      "8 2018-09-18 02:27:51                                 0.0\n",
      "9 2018-09-18 23:43:10                                 3.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种叶子类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneHourSameLastCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_last_category', 'date', 'instance_id']], test_df[['user_id', 'real_last_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_last_category_str'] = temp_df['real_last_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_last_category'] = temp_df['user_id_str'] + temp_df['real_last_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_last_category','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameLastCategory_count'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_real_last_category', 'date']], tempDf[['user_real_last_category', 'date', 'lastOneHour_sameLastCategory_count']], on = ['user_real_last_category', 'date'], how = 'left')\n",
    "    train_df['lastOneHour_sameLastCategory_count'] = temp['lastOneHour_sameLastCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneHour_sameLastCategory_count'] = temp['lastOneHour_sameLastCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneHourSameLastCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneHour_sameLastCategory_count']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneHour_sameBrand_count\n",
      "0 2018-09-18 10:09:04                          0.0\n",
      "1 2018-09-18 12:00:32                          0.0\n",
      "2 2018-09-18 03:04:12                          0.0\n",
      "3 2018-09-18 06:17:50                          0.0\n",
      "4 2018-09-18 19:48:40                          0.0\n",
      "5 2018-09-18 23:00:55                          0.0\n",
      "6 2018-09-18 22:18:37                          0.0\n",
      "7 2018-09-18 16:58:40                          0.0\n",
      "8 2018-09-18 02:27:51                          0.0\n",
      "9 2018-09-18 23:43:10                          0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种品牌商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneHourSameBrandCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_brand_id', 'date', 'instance_id']], test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['brand_id_str'] = temp_df['item_brand_id'].map(lambda x: str(x))\n",
    "    temp_df['user_brand_id'] = temp_df['user_id_str'] + temp_df['brand_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_brand_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_brand_id'] = tempDf['user_brand_id'].shift(1)\n",
    "    tempDf['last_user_brand_id'] = tempDf['last_user_brand_id']==tempDf['user_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_brand_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_brand_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameBrand_count'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_brand_id', 'date']], tempDf[['user_brand_id', 'date', 'lastOneHour_sameBrand_count']], on = ['user_brand_id', 'date'], how = 'left')\n",
    "    train_df['lastOneHour_sameBrand_count'] = temp['lastOneHour_sameBrand_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneHour_sameBrand_count'] = temp['lastOneHour_sameBrand_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneHourSameBrandCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneHour_sameBrand_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneHour_sameShop_count\n",
      "0 2018-09-18 10:09:04                         0.0\n",
      "1 2018-09-18 12:00:32                         0.0\n",
      "2 2018-09-18 03:04:12                         0.0\n",
      "3 2018-09-18 06:17:50                         0.0\n",
      "4 2018-09-18 19:48:40                         0.0\n",
      "5 2018-09-18 23:00:55                         0.0\n",
      "6 2018-09-18 22:18:37                         0.0\n",
      "7 2018-09-18 16:58:40                         0.0\n",
      "8 2018-09-18 02:27:51                         0.0\n",
      "9 2018-09-18 23:43:10                         0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种店铺商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneHourSameShopCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'shop_id', 'date', 'instance_id']], test_df[['user_id', 'shop_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_shop_id_str'] = temp_df['shop_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_shop_id'] = temp_df['user_id_str'] + temp_df['item_shop_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_shop_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['user_item_shop_id'].shift(1)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['last_user_item_shop_id']==tempDf['user_item_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_shop_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_shop_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameShop_count'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_item_shop_id', 'date']], tempDf[['user_item_shop_id', 'date', 'lastOneHour_sameShop_count']], on = ['user_item_shop_id', 'date'], how = 'left')\n",
    "    train_df['lastOneHour_sameShop_count'] = temp['lastOneHour_sameShop_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneHour_sameShop_count'] = temp['lastOneHour_sameShop_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneHourSameShopCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneHour_sameShop_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  isLastOneHour_firstClickItem\n",
      "0 2018-09-18 10:09:04                             1\n",
      "1 2018-09-18 12:00:32                             1\n",
      "2 2018-09-18 03:04:12                             1\n",
      "3 2018-09-18 06:17:50                             1\n",
      "4 2018-09-18 19:48:40                             1\n",
      "5 2018-09-18 23:00:55                             1\n",
      "6 2018-09-18 22:18:37                             1\n",
      "7 2018-09-18 16:58:40                             1\n",
      "8 2018-09-18 02:27:51                             1\n",
      "9 2018-09-18 23:43:10                             1\n"
     ]
    }
   ],
   "source": [
    "# 获取是否是该用户在这1个小时内第一次点击这个商品的特征，同时对训练集和测试集进行处理\n",
    "def getIsOneHourFirstClickItem(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_id'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            if len(hourShowTemp) > 0:\n",
    "                hourShowList.append(0)\n",
    "            else:\n",
    "                hourShowList.append(1)\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(1)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['isLastOneHour_firstClickItem'] = hourShowList\n",
    "    temp = pd.merge(temp_df[['user_item_id', 'date']], tempDf[['user_item_id', 'date', 'isLastOneHour_firstClickItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "#     print(temp[['user_item_id', 'date', 'isLastOneHour_firstClickItem']].head(10))\n",
    "#     print(temp[['user_item_id', 'date', 'isLastOneHour_firstClickItem', 'is_trade']][temp.user_item_id == '62033080084805934235202355029344881809'].head(10))\n",
    "#     print(len(temp[temp.isLastOneHour_firstClickItem == 0]))\n",
    "#     print(len(temp[(temp.isLastOneHour_firstClickItem == 0) & (temp.is_trade == 1)]))\n",
    "#     print(len(temp[temp.isLastOneHour_firstClickItem == 1]))\n",
    "#     print(len(temp[(temp.isLastOneHour_firstClickItem == 1) & (temp.is_trade == 1)]))\n",
    "    train_df['isLastOneHour_firstClickItem'] = temp['isLastOneHour_firstClickItem'][:len(train_df['user_id'])]\n",
    "    test_df['isLastOneHour_firstClickItem'] = temp['isLastOneHour_firstClickItem'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsOneHourFirstClickItem(train_df, test_df)\n",
    "print(train_df[['date', 'isLastOneHour_firstClickItem']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneDay_sameItem_count\n",
      "0 2018-09-18 10:09:04                        0.0\n",
      "1 2018-09-18 12:00:32                        0.0\n",
      "2 2018-09-18 03:04:12                        0.0\n",
      "3 2018-09-18 06:17:50                        0.0\n",
      "4 2018-09-18 19:48:40                        0.0\n",
      "5 2018-09-18 23:00:55                        0.0\n",
      "6 2018-09-18 22:18:37                        0.0\n",
      "7 2018-09-18 16:58:40                        0.0\n",
      "8 2018-09-18 02:27:51                        0.0\n",
      "9 2018-09-18 23:43:10                        0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一天某用户点击某个相同商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneDaySameItemCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item'] = tempDf['user_item'].shift(1)\n",
    "    tempDf['last_user_item'] = tempDf['last_user_item']==tempDf['user_item']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    dayShowList = []\n",
    "    dayShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item','date','show']].values:\n",
    "        if same:\n",
    "            [dayShowTemp.pop(k) for k in list(dayShowTemp) if k<dt-timedelta(days=1)]\n",
    "            dayShowList.append(np.sum(list(dayShowTemp.values())))\n",
    "            dayShowTemp[dt] = show\n",
    "        else:\n",
    "            dayShowList.append(0)\n",
    "            dayShowTemp = {dt:show}\n",
    "    tempDf['lastOneDay_sameItem_count'] = dayShowList\n",
    "    temp = pd.merge(temp_df[['user_item', 'date']], tempDf[['user_item', 'date', 'lastOneDay_sameItem_count']], on = ['user_item', 'date'], how = 'left')\n",
    "    train_df['lastOneDay_sameItem_count'] = temp['lastOneDay_sameItem_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneDay_sameItem_count'] = temp['lastOneDay_sameItem_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneDaySameItemCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneDay_sameItem_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneDay_sameFirstCategory_count\n",
      "0 2018-09-18 10:09:04                                 0.0\n",
      "1 2018-09-18 12:00:32                                 1.0\n",
      "2 2018-09-18 03:04:12                                 0.0\n",
      "3 2018-09-18 06:17:50                                 0.0\n",
      "4 2018-09-18 19:48:40                                 0.0\n",
      "5 2018-09-18 23:00:55                                 1.0\n",
      "6 2018-09-18 22:18:37                                19.0\n",
      "7 2018-09-18 16:58:40                                 0.0\n",
      "8 2018-09-18 02:27:51                                 0.0\n",
      "9 2018-09-18 23:43:10                                 3.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一天某用户点击同种根类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneDaySameFirstCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_first_category', 'date', 'instance_id']], test_df[['user_id', 'real_first_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_first_category_str'] = temp_df['real_first_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_first_category'] = temp_df['user_id_str'] + temp_df['real_first_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    dayShowList = []\n",
    "    dayShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_first_category','date','show']].values:\n",
    "        if same:\n",
    "            [dayShowTemp.pop(k) for k in list(dayShowTemp) if k<dt-timedelta(days=1)]\n",
    "            dayShowList.append(np.sum(list(dayShowTemp.values())))\n",
    "            dayShowTemp[dt] = show\n",
    "        else:\n",
    "            dayShowList.append(0)\n",
    "            dayShowTemp = {dt:show}\n",
    "    tempDf['lastOneDay_sameFirstCategory_count'] = dayShowList\n",
    "    temp = pd.merge(temp_df[['user_real_first_category', 'date']], tempDf[['user_real_first_category', 'date', 'lastOneDay_sameFirstCategory_count']], on = ['user_real_first_category', 'date'], how = 'left')\n",
    "    train_df['lastOneDay_sameFirstCategory_count'] = temp['lastOneDay_sameFirstCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneDay_sameFirstCategory_count'] = temp['lastOneDay_sameFirstCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneDaySameFirstCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneDay_sameFirstCategory_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneDay_sameLastCategory_count\n",
      "0 2018-09-18 10:09:04                                0.0\n",
      "1 2018-09-18 12:00:32                                1.0\n",
      "2 2018-09-18 03:04:12                                0.0\n",
      "3 2018-09-18 06:17:50                                0.0\n",
      "4 2018-09-18 19:48:40                                0.0\n",
      "5 2018-09-18 23:00:55                                1.0\n",
      "6 2018-09-18 22:18:37                               19.0\n",
      "7 2018-09-18 16:58:40                                0.0\n",
      "8 2018-09-18 02:27:51                                0.0\n",
      "9 2018-09-18 23:43:10                                3.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个天某用户点击同种叶子类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneDaySameLastCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_last_category', 'date', 'instance_id']], test_df[['user_id', 'real_last_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_last_category_str'] = temp_df['real_last_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_last_category'] = temp_df['user_id_str'] + temp_df['real_last_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    dayShowList = []\n",
    "    dayShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_last_category','date','show']].values:\n",
    "        if same:\n",
    "            [dayShowTemp.pop(k) for k in list(dayShowTemp) if k<dt-timedelta(days=1)]\n",
    "            dayShowList.append(np.sum(list(dayShowTemp.values())))\n",
    "            dayShowTemp[dt] = show\n",
    "        else:\n",
    "            dayShowList.append(0)\n",
    "            dayShowTemp = {dt:show}\n",
    "    tempDf['lastOneDay_sameLastCategory_count'] = dayShowList\n",
    "    temp = pd.merge(temp_df[['user_real_last_category', 'date']], tempDf[['user_real_last_category', 'date', 'lastOneDay_sameLastCategory_count']], on = ['user_real_last_category', 'date'], how = 'left')\n",
    "    train_df['lastOneDay_sameLastCategory_count'] = temp['lastOneDay_sameLastCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneDay_sameLastCategory_count'] = temp['lastOneDay_sameLastCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneDaySameLastCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneDay_sameLastCategory_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneDay_sameBrand_count\n",
      "0 2018-09-18 10:09:04                         0.0\n",
      "1 2018-09-18 12:00:32                         0.0\n",
      "2 2018-09-18 03:04:12                         0.0\n",
      "3 2018-09-18 06:17:50                         0.0\n",
      "4 2018-09-18 19:48:40                         0.0\n",
      "5 2018-09-18 23:00:55                         0.0\n",
      "6 2018-09-18 22:18:37                         0.0\n",
      "7 2018-09-18 16:58:40                         0.0\n",
      "8 2018-09-18 02:27:51                         0.0\n",
      "9 2018-09-18 23:43:10                         0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个天某用户点击同种品牌商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneDaySameBrandCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_brand_id', 'date', 'instance_id']], test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['brand_id_str'] = temp_df['item_brand_id'].map(lambda x: str(x))\n",
    "    temp_df['user_brand_id'] = temp_df['user_id_str'] + temp_df['brand_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_brand_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_brand_id'] = tempDf['user_brand_id'].shift(1)\n",
    "    tempDf['last_user_brand_id'] = tempDf['last_user_brand_id']==tempDf['user_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_brand_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    dayShowList = []\n",
    "    dayShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_brand_id','date','show']].values:\n",
    "        if same:\n",
    "            [dayShowTemp.pop(k) for k in list(dayShowTemp) if k<dt-timedelta(days=1)]\n",
    "            dayShowList.append(np.sum(list(dayShowTemp.values())))\n",
    "            dayShowTemp[dt] = show\n",
    "        else:\n",
    "            dayShowList.append(0)\n",
    "            dayShowTemp = {dt:show}\n",
    "    tempDf['lastOneDay_sameBrand_count'] = dayShowList\n",
    "    temp = pd.merge(temp_df[['user_brand_id', 'date']], tempDf[['user_brand_id', 'date', 'lastOneDay_sameBrand_count']], on = ['user_brand_id', 'date'], how = 'left')\n",
    "    train_df['lastOneDay_sameBrand_count'] = temp['lastOneDay_sameBrand_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneDay_sameBrand_count'] = temp['lastOneDay_sameBrand_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneDaySameBrandCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneDay_sameBrand_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  lastOneDay_sameShop_count\n",
      "0 2018-09-18 10:09:04                        0.0\n",
      "1 2018-09-18 12:00:32                        0.0\n",
      "2 2018-09-18 03:04:12                        0.0\n",
      "3 2018-09-18 06:17:50                        0.0\n",
      "4 2018-09-18 19:48:40                        0.0\n",
      "5 2018-09-18 23:00:55                        0.0\n",
      "6 2018-09-18 22:18:37                        0.0\n",
      "7 2018-09-18 16:58:40                        0.0\n",
      "8 2018-09-18 02:27:51                        0.0\n",
      "9 2018-09-18 23:43:10                        0.0\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个天某用户点击同种店铺商品的次数，同时对训练集和测试集进行处理\n",
    "def getOneDaySameShopCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'shop_id', 'date', 'instance_id']], test_df[['user_id', 'shop_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_shop_id_str'] = temp_df['shop_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_shop_id'] = temp_df['user_id_str'] + temp_df['item_shop_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_shop_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['user_item_shop_id'].shift(1)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['last_user_item_shop_id']==tempDf['user_item_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_shop_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    dayShowList = []\n",
    "    dayShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_shop_id','date','show']].values:\n",
    "        if same:\n",
    "            [dayShowTemp.pop(k) for k in list(dayShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            dayShowList.append(np.sum(list(dayShowTemp.values())))\n",
    "            dayShowTemp[dt] = show\n",
    "        else:\n",
    "            dayShowList.append(0)\n",
    "            dayShowTemp = {dt:show}\n",
    "    tempDf['lastOneDay_sameShop_count'] = dayShowList\n",
    "    temp = pd.merge(temp_df[['user_item_shop_id', 'date']], tempDf[['user_item_shop_id', 'date', 'lastOneDay_sameShop_count']], on = ['user_item_shop_id', 'date'], how = 'left')\n",
    "    train_df['lastOneDay_sameShop_count'] = temp['lastOneDay_sameShop_count'][:len(train_df['user_id'])]\n",
    "    test_df['lastOneDay_sameShop_count'] = temp['lastOneDay_sameShop_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getOneDaySameShopCount(train_df, test_df)\n",
    "print(train_df[['date', 'lastOneDay_sameShop_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   date  history_sameItem_count  lastOneHour_sameItem_count\n",
      "60  2018-09-18 19:48:23                       1                         1.0\n",
      "103 2018-09-18 14:35:06                       1                         1.0\n",
      "129 2018-09-18 13:13:32                       1                         1.0\n",
      "146 2018-09-18 09:28:18                       1                         1.0\n",
      "156 2018-09-18 12:18:04                       1                         1.0\n",
      "284 2018-09-18 14:32:35                       1                         1.0\n",
      "293 2018-09-18 21:03:05                       3                         2.0\n",
      "306 2018-09-18 16:22:59                       1                         1.0\n",
      "436 2018-09-18 20:40:27                       1                         1.0\n",
      "525 2018-09-18 11:09:58                       1                         1.0\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户点击某个相同商品的次数，同时对训练集和测试集进行处理\n",
    "def getHistorySameItemCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item'] = tempDf['user_item'].shift(1)\n",
    "    tempDf['last_user_item'] = tempDf['last_user_item']==tempDf['user_item']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item','date','show']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            historyShowList.append(np.sum(list(historyShowTemp.values())))\n",
    "            historyShowTemp[dt] = show\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:show}\n",
    "    tempDf['history_sameItem_count'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_item', 'date']], tempDf[['user_item', 'date', 'history_sameItem_count']], on = ['user_item', 'date'], how = 'left')\n",
    "#     print(temp_df[['user_item', 'date']].head())\n",
    "#     print(tempDf[['user_item', 'date', 'lastOneHour_sameItem_count']][tempDf.user_item == '15383240786656120175586531724608162781'].head())\n",
    "#     print(temp[temp.lastOneHour_sameItem_count > 0].head())\n",
    "    train_df['history_sameItem_count'] = temp['history_sameItem_count'][:len(train_df['user_id'])]\n",
    "    test_df['history_sameItem_count'] = temp['history_sameItem_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getHistorySameItemCount(train_df, test_df)\n",
    "print(train_df[['date', 'history_sameItem_count', 'lastOneHour_sameItem_count']][train_df.lastOneHour_sameItem_count > 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date  history_sameFirstCategory_count  \\\n",
      "478113 2018-09-24 15:40:13                                2   \n",
      "478114 2018-09-24 01:33:20                                8   \n",
      "478117 2018-09-24 09:07:38                                2   \n",
      "478119 2018-09-24 22:47:56                                2   \n",
      "478120 2018-09-24 22:44:11                                1   \n",
      "478126 2018-09-24 14:20:07                                1   \n",
      "478129 2018-09-24 14:25:29                                3   \n",
      "478133 2018-09-24 07:48:39                                2   \n",
      "478134 2018-09-24 23:03:35                                6   \n",
      "478136 2018-09-24 18:08:49                                7   \n",
      "\n",
      "        lastOneHour_sameFirstCategory_count  \n",
      "478113                                  2.0  \n",
      "478114                                  5.0  \n",
      "478117                                  1.0  \n",
      "478119                                  2.0  \n",
      "478120                                  1.0  \n",
      "478126                                  1.0  \n",
      "478129                                  3.0  \n",
      "478133                                  1.0  \n",
      "478134                                  2.0  \n",
      "478136                                  7.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户点击某个相同根类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getHistorySameFirstCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_first_category', 'date', 'instance_id']], test_df[['user_id', 'real_first_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_first_category_str'] = temp_df['real_first_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_first_category'] = temp_df['user_id_str'] + temp_df['real_first_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_first_category','date','show']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            historyShowList.append(np.sum(list(historyShowTemp.values())))\n",
    "            historyShowTemp[dt] = show\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:show}\n",
    "    tempDf['history_sameFirstCategory_count'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_real_first_category', 'date']], tempDf[['user_real_first_category', 'date', 'history_sameFirstCategory_count']], on = ['user_real_first_category', 'date'], how = 'left')\n",
    "    train_df['history_sameFirstCategory_count'] = temp['history_sameFirstCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['history_sameFirstCategory_count'] = temp['history_sameFirstCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getHistorySameFirstCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'history_sameFirstCategory_count', 'lastOneHour_sameFirstCategory_count']][train_df.lastOneHour_sameFirstCategory_count > 0].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date  history_sameLastCategory_count  \\\n",
      "478113 2018-09-24 15:40:13                               2   \n",
      "478114 2018-09-24 01:33:20                               8   \n",
      "478117 2018-09-24 09:07:38                               2   \n",
      "478119 2018-09-24 22:47:56                               2   \n",
      "478120 2018-09-24 22:44:11                               1   \n",
      "478126 2018-09-24 14:20:07                               1   \n",
      "478129 2018-09-24 14:25:29                               3   \n",
      "478133 2018-09-24 07:48:39                               2   \n",
      "478134 2018-09-24 23:03:35                               6   \n",
      "478136 2018-09-24 18:08:49                               7   \n",
      "\n",
      "        lastOneHour_sameLastCategory_count  \n",
      "478113                                 2.0  \n",
      "478114                                 5.0  \n",
      "478117                                 1.0  \n",
      "478119                                 2.0  \n",
      "478120                                 1.0  \n",
      "478126                                 1.0  \n",
      "478129                                 3.0  \n",
      "478133                                 1.0  \n",
      "478134                                 2.0  \n",
      "478136                                 7.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户点击某个相同叶子类目商品的次数，同时对训练集和测试集进行处理\n",
    "def getHistorySameLastCategoryCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_last_category', 'date', 'instance_id']], test_df[['user_id', 'real_last_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_last_category_str'] = temp_df['real_last_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_last_category'] = temp_df['user_id_str'] + temp_df['real_last_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_last_category','date','show']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            historyShowList.append(np.sum(list(historyShowTemp.values())))\n",
    "            historyShowTemp[dt] = show\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:show}\n",
    "    tempDf['history_sameLastCategory_count'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_real_last_category', 'date']], tempDf[['user_real_last_category', 'date', 'history_sameLastCategory_count']], on = ['user_real_last_category', 'date'], how = 'left')\n",
    "    train_df['history_sameLastCategory_count'] = temp['history_sameLastCategory_count'][:len(train_df['user_id'])]\n",
    "    test_df['history_sameLastCategory_count'] = temp['history_sameLastCategory_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getHistorySameLastCategoryCount(train_df, test_df)\n",
    "print(train_df[['date', 'history_sameLastCategory_count', 'lastOneHour_sameLastCategory_count']][train_df.lastOneHour_sameLastCategory_count > 0].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date  history_sameBrand_count  \\\n",
      "478077 2018-09-24 16:23:00                        2   \n",
      "478089 2018-09-24 09:01:35                        1   \n",
      "478096 2018-09-24 15:41:39                        1   \n",
      "478097 2018-09-24 17:18:19                        1   \n",
      "478099 2018-09-24 23:23:22                        4   \n",
      "478100 2018-09-24 22:11:40                        2   \n",
      "478102 2018-09-24 21:55:55                        1   \n",
      "478104 2018-09-24 22:23:31                        3   \n",
      "478112 2018-09-24 16:46:49                        1   \n",
      "478129 2018-09-24 14:25:29                        1   \n",
      "\n",
      "        lastOneHour_sameBrand_count  \n",
      "478077                          2.0  \n",
      "478089                          1.0  \n",
      "478096                          1.0  \n",
      "478097                          1.0  \n",
      "478099                          1.0  \n",
      "478100                          2.0  \n",
      "478102                          1.0  \n",
      "478104                          2.0  \n",
      "478112                          1.0  \n",
      "478129                          1.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户点击某个相同品牌商品的次数，同时对训练集和测试集进行处理\n",
    "def getHistorySameBrandCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_brand_id', 'date', 'instance_id']], test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_brand_id_str'] = temp_df['item_brand_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_brand_id'] = temp_df['user_id_str'] + temp_df['item_brand_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_brand_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['user_item_brand_id'].shift(1)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['last_user_item_brand_id']==tempDf['user_item_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_brand_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_brand_id','date','show']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            historyShowList.append(np.sum(list(historyShowTemp.values())))\n",
    "            historyShowTemp[dt] = show\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:show}\n",
    "    tempDf['history_sameBrand_count'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_item_brand_id', 'date']], tempDf[['user_item_brand_id', 'date', 'history_sameBrand_count']], on = ['user_item_brand_id', 'date'], how = 'left')\n",
    "    train_df['history_sameBrand_count'] = temp['history_sameBrand_count'][:len(train_df['user_id'])]\n",
    "    test_df['history_sameBrand_count'] = temp['history_sameBrand_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getHistorySameBrandCount(train_df, test_df)\n",
    "print(train_df[['date', 'history_sameBrand_count', 'lastOneHour_sameBrand_count']][train_df.lastOneHour_sameBrand_count > 0].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      date  history_sameShop_count  lastOneHour_sameShop_count\n",
      "477919 2018-09-24 02:17:00                       1                         1.0\n",
      "477967 2018-09-24 17:04:13                       1                         1.0\n",
      "477974 2018-09-24 21:43:14                       1                         1.0\n",
      "477976 2018-09-24 10:09:56                       1                         1.0\n",
      "478055 2018-09-24 21:37:25                       1                         1.0\n",
      "478099 2018-09-24 23:23:22                       4                         1.0\n",
      "478100 2018-09-24 22:11:40                       2                         2.0\n",
      "478102 2018-09-24 21:55:55                       1                         1.0\n",
      "478104 2018-09-24 22:23:31                       3                         2.0\n",
      "478129 2018-09-24 14:25:29                       1                         1.0\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户点击某个相同店铺商品的次数，同时对训练集和测试集进行处理\n",
    "def getHistorySameShopCount(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'shop_id', 'date', 'instance_id']], test_df[['user_id', 'shop_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['shop_id_str'] = temp_df['shop_id'].map(lambda x: str(x))\n",
    "    temp_df['user_shop_id'] = temp_df['user_id_str'] + temp_df['shop_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_shop_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_shop_id'] = tempDf['user_shop_id'].shift(1)\n",
    "    tempDf['last_user_shop_id'] = tempDf['last_user_shop_id']==tempDf['user_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_shop_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_shop_id','date','show']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            historyShowList.append(np.sum(list(historyShowTemp.values())))\n",
    "            historyShowTemp[dt] = show\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:show}\n",
    "    tempDf['history_sameShop_count'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_shop_id', 'date']], tempDf[['user_shop_id', 'date', 'history_sameShop_count']], on = ['user_shop_id', 'date'], how = 'left')\n",
    "    train_df['history_sameShop_count'] = temp['history_sameShop_count'][:len(train_df['user_id'])]\n",
    "    test_df['history_sameShop_count'] = temp['history_sameShop_count'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getHistorySameShopCount(train_df, test_df)\n",
    "print(train_df[['date', 'history_sameShop_count', 'lastOneHour_sameShop_count']][train_df.lastOneHour_sameShop_count > 0].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  is_history_sameItem  is_trade\n",
      "0 2018-09-18 10:09:04                    0         0\n",
      "1 2018-09-18 12:00:32                    0         0\n",
      "2 2018-09-18 03:04:12                    0         0\n",
      "3 2018-09-18 06:17:50                    0         0\n",
      "4 2018-09-18 19:48:40                    0         0\n",
      "5 2018-09-18 23:00:55                    0         0\n",
      "6 2018-09-18 22:18:37                    0         0\n",
      "7 2018-09-18 16:58:40                    0         0\n",
      "8 2018-09-18 02:27:51                    0         0\n",
      "9 2018-09-18 23:43:10                    0         0\n",
      "188\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否购买过相同商品，同时对训练集和测试集进行处理\n",
    "def getIsHistorySameItem(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['is_trade'] = 0\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'is_trade', 'instance_id']], test_df_copy[['user_id', 'item_id', 'date', 'is_trade', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'is_trade', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item', 'date' ,'is_trade'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item'] = tempDf['user_item'].shift(1)\n",
    "    tempDf['last_user_item'] = tempDf['last_user_item']==tempDf['user_item']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, is_trade in tempDf[['last_user_item','date','is_trade']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                if is_trade == 1:\n",
    "                    historyShowTemp[dt] = is_trade\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            if is_trade == 1:\n",
    "                historyShowTemp = {dt:is_trade}\n",
    "            else:\n",
    "                historyShowTemp = {}\n",
    "    tempDf['is_history_sameItem'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_item', 'date', 'is_trade']], tempDf[['user_item', 'date', 'is_trade', 'is_history_sameItem']], on = ['user_item', 'date' ,'is_trade'], how = 'left')\n",
    "#     check_df = pd.pivot_table(temp_df, index=['user_item'], values=['instance_id'], aggfunc=len)\n",
    "#     check_df.columns = ['show']\n",
    "#     check_df.reset_index(inplace=True)\n",
    "#     print(check_df[['user_item']][check_df.show > 10].head(10))\n",
    "#     print(temp[['user_item', 'date', 'is_history_sameItem', 'is_trade']][temp.is_history_sameItem != 0].head(30))\n",
    "#     print(temp[['user_item', 'date', 'is_history_sameItem', 'is_trade']][temp.user_item == '2414798119892047935410526681843914464'].head(10))\n",
    "    train_df['is_history_sameItem'] = temp['is_history_sameItem'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_sameItem'] = temp['is_history_sameItem'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistorySameItem(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_sameItem', 'is_trade']].head(10))\n",
    "print(len(train_df[['date', 'is_history_sameItem', 'is_trade']][train_df.is_history_sameItem == 1]))\n",
    "print(len(train_df[['date', 'is_history_sameItem', 'is_trade']][((train_df.is_history_sameItem == 1) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    date  is_history_sameFirstCategory  is_trade\n",
      "303  2018-09-18 21:01:22                             1         0\n",
      "511  2018-09-18 13:51:00                             1         0\n",
      "556  2018-09-18 23:43:22                             1         0\n",
      "612  2018-09-18 23:37:40                             1         0\n",
      "762  2018-09-18 20:36:35                             1         0\n",
      "924  2018-09-18 21:19:48                             1         0\n",
      "1003 2018-09-18 18:40:38                             1         0\n",
      "1012 2018-09-18 12:55:38                             1         0\n",
      "1298 2018-09-18 14:36:22                             1         0\n",
      "1627 2018-09-18 21:18:30                             1         0\n",
      "6001\n",
      "5798\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否购买过根类目的商品，同时对训练集和测试集进行处理\n",
    "def getIsHistorySameFirstCategory(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['is_trade'] = 0\n",
    "    df = pd.concat([train_df[['user_id', 'real_first_category', 'date', 'is_trade', 'instance_id']], test_df_copy[['user_id', 'real_first_category', 'date', 'is_trade', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_first_category', 'date', 'is_trade', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_first_category_str'] = temp_df['real_first_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_first_category'] = temp_df['user_id_str'] + temp_df['real_first_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category', 'date' ,'is_trade'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, is_trade in tempDf[['last_user_real_first_category','date','is_trade']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                if is_trade == 1:\n",
    "                    historyShowTemp[dt] = is_trade\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            if is_trade == 1:\n",
    "                historyShowTemp = {dt:is_trade}\n",
    "            else:\n",
    "                historyShowTemp = {}\n",
    "    tempDf['is_history_sameFirstCategory'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_real_first_category', 'date', 'is_trade']], tempDf[['user_real_first_category', 'date', 'is_trade', 'is_history_sameFirstCategory']], on = ['user_real_first_category', 'date' ,'is_trade'], how = 'left')\n",
    "#     check_df = pd.pivot_table(temp_df, index=['user_item'], values=['instance_id'], aggfunc=len)\n",
    "#     check_df.columns = ['show']\n",
    "#     check_df.reset_index(inplace=True)\n",
    "#     print(check_df[['user_item']][check_df.show > 10].head(10))\n",
    "#     print(temp[['user_item', 'date', 'is_history_sameItem', 'is_trade']][temp.is_history_sameItem != 0].head(30))\n",
    "#     print(temp[['user_item', 'date', 'is_history_sameItem', 'is_trade']][temp.user_item == '2414798119892047935410526681843914464'].head(10))\n",
    "    train_df['is_history_sameFirstCategory'] = temp['is_history_sameFirstCategory'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_sameFirstCategory'] = temp['is_history_sameFirstCategory'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistorySameFirstCategory(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_sameFirstCategory', 'is_trade']][train_df.is_history_sameFirstCategory == 1].head(10))\n",
    "print(len(train_df[['date']][train_df.is_history_sameFirstCategory == 1]))\n",
    "print(len(train_df[['date']][((train_df.is_history_sameFirstCategory == 1) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    date  is_history_sameLastCategory  is_trade\n",
      "303  2018-09-18 21:01:22                            1         0\n",
      "511  2018-09-18 13:51:00                            1         0\n",
      "556  2018-09-18 23:43:22                            1         0\n",
      "612  2018-09-18 23:37:40                            1         0\n",
      "762  2018-09-18 20:36:35                            1         0\n",
      "924  2018-09-18 21:19:48                            1         0\n",
      "1003 2018-09-18 18:40:38                            1         0\n",
      "1012 2018-09-18 12:55:38                            1         0\n",
      "1298 2018-09-18 14:36:22                            1         0\n",
      "1627 2018-09-18 21:18:30                            1         0\n",
      "5955\n",
      "5754\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否购买过叶子类目的商品，同时对训练集和测试集进行处理\n",
    "def getIsHistorySameLastCategory(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['is_trade'] = 0\n",
    "    df = pd.concat([train_df[['user_id', 'real_last_category', 'date', 'is_trade', 'instance_id']], test_df_copy[['user_id', 'real_last_category', 'date', 'is_trade', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_last_category', 'date', 'is_trade', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_last_category_str'] = temp_df['real_last_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_last_category'] = temp_df['user_id_str'] + temp_df['real_last_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date' ,'is_trade'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, is_trade in tempDf[['last_user_real_last_category','date','is_trade']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                if is_trade == 1:\n",
    "                    historyShowTemp[dt] = is_trade\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            if is_trade == 1:\n",
    "                historyShowTemp = {dt:is_trade}\n",
    "            else:\n",
    "                historyShowTemp = {}\n",
    "    tempDf['is_history_sameLastCategory'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_real_last_category', 'date', 'is_trade']], tempDf[['user_real_last_category', 'date', 'is_trade', 'is_history_sameLastCategory']], on = ['user_real_last_category', 'date' ,'is_trade'], how = 'left')\n",
    "    train_df['is_history_sameLastCategory'] = temp['is_history_sameLastCategory'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_sameLastCategory'] = temp['is_history_sameLastCategory'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistorySameLastCategory(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_sameLastCategory', 'is_trade']][train_df.is_history_sameLastCategory == 1].head(10))\n",
    "print(len(train_df[['date']][train_df.is_history_sameLastCategory == 1]))\n",
    "print(len(train_df[['date']][((train_df.is_history_sameLastCategory == 1) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    date  is_history_sameBrand  is_trade\n",
      "303  2018-09-18 21:01:22                     1         0\n",
      "1012 2018-09-18 12:55:38                     1         0\n",
      "1298 2018-09-18 14:36:22                     1         0\n",
      "2486 2018-09-18 12:08:58                     1         0\n",
      "2512 2018-09-18 10:03:50                     1         0\n",
      "2515 2018-09-18 08:14:21                     1         1\n",
      "2596 2018-09-18 10:39:04                     1         0\n",
      "2813 2018-09-18 08:01:12                     1         0\n",
      "3193 2018-09-18 12:08:03                     1         0\n",
      "3309 2018-09-18 12:06:21                     1         1\n",
      "608\n",
      "574\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否购买过相同品牌的商品，同时对训练集和测试集进行处理\n",
    "def getIsHistorySameBrand(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['is_trade'] = 0\n",
    "    df = pd.concat([train_df[['user_id', 'item_brand_id', 'date', 'is_trade', 'instance_id']], test_df_copy[['user_id', 'item_brand_id', 'date', 'is_trade', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_brand_id', 'date', 'is_trade', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_brand_id_str'] = temp_df['item_brand_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_brand_id'] = temp_df['user_id_str'] + temp_df['item_brand_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_brand_id', 'date' ,'is_trade'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['user_item_brand_id'].shift(1)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['last_user_item_brand_id']==tempDf['user_item_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_brand_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, is_trade in tempDf[['last_user_item_brand_id','date','is_trade']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                if is_trade == 1:\n",
    "                    historyShowTemp[dt] = is_trade\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            if is_trade == 1:\n",
    "                historyShowTemp = {dt:is_trade}\n",
    "            else:\n",
    "                historyShowTemp = {}\n",
    "    tempDf['is_history_sameBrand'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_item_brand_id', 'date', 'is_trade']], tempDf[['user_item_brand_id', 'date', 'is_trade', 'is_history_sameBrand']], on = ['user_item_brand_id', 'date' ,'is_trade'], how = 'left')\n",
    "    train_df['is_history_sameBrand'] = temp['is_history_sameBrand'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_sameBrand'] = temp['is_history_sameBrand'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistorySameBrand(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_sameBrand', 'is_trade']][train_df.is_history_sameBrand == 1].head(10))\n",
    "print(len(train_df[['date']][train_df.is_history_sameBrand == 1]))\n",
    "print(len(train_df[['date']][((train_df.is_history_sameBrand == 1) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    date  is_history_sameShop  is_trade\n",
      "303  2018-09-18 21:01:22                    1         0\n",
      "1298 2018-09-18 14:36:22                    1         0\n",
      "2512 2018-09-18 10:03:50                    1         0\n",
      "2515 2018-09-18 08:14:21                    1         1\n",
      "2596 2018-09-18 10:39:04                    1         0\n",
      "2813 2018-09-18 08:01:12                    1         0\n",
      "3309 2018-09-18 12:06:21                    1         1\n",
      "3916 2018-09-18 20:52:47                    1         0\n",
      "4655 2018-09-18 13:10:51                    1         0\n",
      "4923 2018-09-18 21:56:11                    1         0\n",
      "308\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否购买过相同店铺的商品，同时对训练集和测试集进行处理\n",
    "def getIsHistorySameShop(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['is_trade'] = 0\n",
    "    df = pd.concat([train_df[['user_id', 'shop_id', 'date', 'is_trade', 'instance_id']], test_df_copy[['user_id', 'shop_id', 'date', 'is_trade', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'shop_id', 'date', 'is_trade', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['shop_id_str'] = temp_df['shop_id'].map(lambda x: str(x))\n",
    "    temp_df['user_shop_id'] = temp_df['user_id_str'] + temp_df['shop_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_shop_id', 'date' ,'is_trade'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_shop_id'] = tempDf['user_shop_id'].shift(1)\n",
    "    tempDf['last_user_shop_id'] = tempDf['last_user_shop_id']==tempDf['user_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_shop_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt, is_trade in tempDf[['last_user_shop_id','date','is_trade']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                if is_trade == 1:\n",
    "                    historyShowTemp[dt] = is_trade\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            if is_trade == 1:\n",
    "                historyShowTemp = {dt:is_trade}\n",
    "            else:\n",
    "                historyShowTemp = {}\n",
    "    tempDf['is_history_sameShop'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_shop_id', 'date', 'is_trade']], tempDf[['user_shop_id', 'date', 'is_trade', 'is_history_sameShop']], on = ['user_shop_id', 'date' ,'is_trade'], how = 'left')\n",
    "    train_df['is_history_sameShop'] = temp['is_history_sameShop'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_sameShop'] = temp['is_history_sameShop'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistorySameShop(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_sameShop', 'is_trade']][train_df.is_history_sameShop == 1].head(10))\n",
    "print(len(train_df[['date']][train_df.is_history_sameShop == 1]))\n",
    "print(len(train_df[['date']][((train_df.is_history_sameShop == 1) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  is_history_firstClickItem  is_trade\n",
      "0 2018-09-18 10:09:04                          1         0\n",
      "1 2018-09-18 12:00:32                          1         0\n",
      "2 2018-09-18 03:04:12                          1         0\n",
      "3 2018-09-18 06:17:50                          1         0\n",
      "4 2018-09-18 19:48:40                          1         0\n",
      "5 2018-09-18 23:00:55                          1         0\n",
      "6 2018-09-18 22:18:37                          1         0\n",
      "7 2018-09-18 16:58:40                          1         0\n",
      "8 2018-09-18 02:27:51                          1         0\n",
      "9 2018-09-18 23:43:10                          1         0\n",
      "7698\n",
      "436581\n",
      "1323\n",
      "32536\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户是否第一次点击该商品，同时对训练集和测试集进行处理\n",
    "def getIsHistoryFirstClickItem(train_df, test_df):\n",
    "    test_df_copy = test_df.copy()\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df_copy[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_id'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_item_id','date']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k > dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(0)\n",
    "            else:\n",
    "                historyShowList.append(1)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(1)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['is_history_firstClickItem'] = historyShowList\n",
    "    temp = pd.merge(temp_df[['user_item_id', 'date']], tempDf[['user_item_id', 'date', 'is_history_firstClickItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df['is_history_firstClickItem'] = temp['is_history_firstClickItem'][:len(train_df['user_id'])]\n",
    "    test_df['is_history_firstClickItem'] = temp['is_history_firstClickItem'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsHistoryFirstClickItem(train_df, test_df)\n",
    "print(train_df[['date', 'is_history_firstClickItem', 'is_trade']][train_df.is_history_firstClickItem == 1].head(10))\n",
    "print(len(train_df[((train_df.is_history_firstClickItem == 1) & (train_df.is_trade == 1))]))\n",
    "print(len(train_df[((train_df.is_history_firstClickItem == 1) & (train_df.is_trade == 0))]))\n",
    "print(len(train_df[((train_df.is_history_firstClickItem == 0) & (train_df.is_trade == 1))]))\n",
    "print(len(train_df[((train_df.is_history_firstClickItem == 0) & (train_df.is_trade == 0))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478138\n",
      "61259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 539370 entries, (10000468422575080321207563772024247788, 2018-09-20 09:44:00) to (9999524220176225161121649958974113109, 2018-09-23 21:35:50)\n",
      "Data columns (total 1 columns):\n",
      "instance_id    539370 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 14.5+ MB\n",
      "None\n",
      "478138\n",
      "61259\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面是否有点击相同商品，同时对训练集和测试集进行处理\n",
    "def getIsClickSameItemLater(train_df, test_df):\n",
    "    train_df_copy = train_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    print(len(train_df_copy))\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    print(len(test_df_copy))\n",
    "    train_df_copy['user_id_str'] = train_df_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_copy['item_id_str'] = train_df_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_copy['user_item_id'] = train_df_copy['user_id_str'] + train_df_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_copy, test_df_copy])\n",
    "#     temp_df = temp_df.sort_values(by='date', ascending=False)\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    print(tempDf.info())\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_item_id', 'date'], ascending=False)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "#     print(tempDf.head(30))\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_item_id','date']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k < dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['is_later_clickSameItem'] = historyShowList\n",
    "#     temp = pd.merge(temp_df[['user_item_id', 'date', 'user_id', 'item_id']], tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df_copy = train_df_copy.merge(tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], how='left', on=['user_item_id', 'date'])\n",
    "    print(len(train_df_copy))\n",
    "    train_df['is_later_clickSameItem'] = train_df_copy['is_later_clickSameItem']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how='left')\n",
    "    print(len(test_df_copy))\n",
    "    test_df['is_later_clickSameItem'] = test_df_copy['is_later_clickSameItem']\n",
    "    #     print(train_df[['date', 'is_later_clickSameItem', 'user_item_id']][train_df.user_item_id == '9996063195993229603233038791884113820'].head(5))\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getIsClickSameItemLater(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478138\n",
      "61259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 498674 entries, (10000468422575080329, 2018-09-20 09:44:00) to (9999524220176225169, 2018-09-23 21:35:50)\n",
      "Data columns (total 1 columns):\n",
      "instance_id    498674 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 11.7+ MB\n",
      "None\n",
      "478138\n",
      "61259\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面是否有点击相同叶子类目商品，同时对训练集和测试集进行处理\n",
    "def getIsClickSameLastCategoryLater(train_df, test_df):\n",
    "    train_df_copy = train_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    print(len(train_df_copy))\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    print(len(test_df_copy))\n",
    "    train_df_copy['user_id_str'] = train_df_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_copy['real_last_category_str'] = train_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_copy['user_real_last_category'] = train_df_copy['user_id_str'] + train_df_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_copy, test_df_copy])\n",
    "#     temp_df = temp_df.sort_values(by='date', ascending=False)\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    print(tempDf.info())\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_real_last_category', 'date'], ascending=False)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "#     print(tempDf.head(30))\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_real_last_category','date']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k < dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(1)\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['is_later_clickSameLastCategory'] = historyShowList\n",
    "#     temp = pd.merge(temp_df[['user_item_id', 'date', 'user_id', 'item_id']], tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df_copy = train_df_copy.merge(tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], how='left', on=['user_real_last_category', 'date'])\n",
    "    print(len(train_df_copy))\n",
    "    train_df['is_later_clickSameLastCategory'] = train_df_copy['is_later_clickSameLastCategory']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    print(len(test_df_copy))\n",
    "    test_df['is_later_clickSameLastCategory'] = test_df_copy['is_later_clickSameLastCategory']\n",
    "    return train_df, test_df\n",
    "    \n",
    "\n",
    "train_df, test_df = getIsClickSameLastCategoryLater(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478138\n",
      "61259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 498674 entries, (10000468422575080329, 2018-09-20 09:44:00) to (9999524220176225169, 2018-09-23 21:35:50)\n",
      "Data columns (total 1 columns):\n",
      "instance_id    498674 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 11.7+ MB\n",
      "None\n",
      "478138\n",
      "61259\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同叶子类目商品的个数，同时对训练集和测试集进行处理\n",
    "def getClickSameLastCategoryLaterNumber(train_df, test_df):\n",
    "    train_df_copy = train_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    print(len(train_df_copy))\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    print(len(test_df_copy))\n",
    "    train_df_copy['user_id_str'] = train_df_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_copy['real_last_category_str'] = train_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_copy['user_real_last_category'] = train_df_copy['user_id_str'] + train_df_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_copy, test_df_copy])\n",
    "#     temp_df = temp_df.sort_values(by='date', ascending=False)\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    print(tempDf.info())\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_real_last_category', 'date'], ascending=False)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "#     print(tempDf.head(30))\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_real_last_category','date']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k < dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(len(historyShowTemp))\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['later_clickSameLastCategory_count'] = historyShowList\n",
    "#     temp = pd.merge(temp_df[['user_item_id', 'date', 'user_id', 'item_id']], tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df_copy = train_df_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    print(len(train_df_copy))\n",
    "    train_df['later_clickSameLastCategory_count'] = train_df_copy['later_clickSameLastCategory_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    print(len(test_df_copy))\n",
    "    test_df['later_clickSameLastCategory_count'] = test_df_copy['later_clickSameLastCategory_count']\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getClickSameLastCategoryLaterNumber(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478138\n",
      "61259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 539370 entries, (10000468422575080321207563772024247788, 2018-09-20 09:44:00) to (9999524220176225161121649958974113109, 2018-09-23 21:35:50)\n",
      "Data columns (total 1 columns):\n",
      "instance_id    539370 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 14.5+ MB\n",
      "None\n",
      "478138\n",
      "61259\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同商品的个数，同时对训练集和测试集进行处理\n",
    "def getClickSameItemLaterNumber(train_df, test_df):\n",
    "    train_df_copy = train_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    print(len(train_df_copy))\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    print(len(test_df_copy))\n",
    "    train_df_copy['user_id_str'] = train_df_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_copy['item_id_str'] = train_df_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_copy['user_item_id'] = train_df_copy['user_id_str'] + train_df_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_copy, test_df_copy])\n",
    "#     temp_df = temp_df.sort_values(by='date', ascending=False)\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    print(tempDf.info())\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_item_id', 'date'], ascending=False)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "#     print(tempDf.head(30))\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_item_id','date']].values:\n",
    "        if same:\n",
    "            [historyShowTemp.pop(k) for k in list(historyShowTemp) if k < dt]\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(len(historyShowTemp))\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['later_clickSameItem_count'] = historyShowList\n",
    "#     temp = pd.merge(temp_df[['user_item_id', 'date', 'user_id', 'item_id']], tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df_copy = train_df_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    print(len(train_df_copy))\n",
    "    train_df['later_clickSameItem_count'] = train_df_copy['later_clickSameItem_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], on = ['user_item_id', 'date'], how='left')\n",
    "    print(len(test_df_copy))\n",
    "    test_df['later_clickSameItem_count'] = test_df_copy['later_clickSameItem_count']\n",
    "    #     print(train_df[['date', 'is_later_clickSameItem', 'user_item_id']][train_df.user_item_id == '9996063195993229603233038791884113820'].head(5))\n",
    "    return train_df, test_df\n",
    "    \n",
    "\n",
    "train_df, test_df = getClickSameItemLaterNumber(train_df, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   shop_review_positive_rate  shop_review_positive_rate_ave  \\\n",
      "0                   1.000000                       0.991042   \n",
      "1                   1.000000                       0.991042   \n",
      "2                   1.000000                       0.991042   \n",
      "3                   1.000000                       0.991042   \n",
      "4                   1.000000                       0.991042   \n",
      "5                   1.000000                       0.991042   \n",
      "6                   0.985427                       0.995915   \n",
      "7                   0.985427                       0.995915   \n",
      "8                   0.985427                       0.996590   \n",
      "9                   0.985427                       0.995915   \n",
      "\n",
      "   isHigh_shop_review_positive_rate  \n",
      "0                               1.0  \n",
      "1                               1.0  \n",
      "2                               1.0  \n",
      "3                               1.0  \n",
      "4                               1.0  \n",
      "5                               1.0  \n",
      "6                               0.0  \n",
      "7                               0.0  \n",
      "8                               0.0  \n",
      "9                               0.0  \n",
      "   real_first_category  shop_review_positive_rate  \\\n",
      "0  8277336076276184272                   0.985244   \n",
      "1  5755694407684602296                   0.989068   \n",
      "2  5755694407684602296                   0.989068   \n",
      "3  5755694407684602296                   0.989068   \n",
      "4  5755694407684602296                   0.989068   \n",
      "5  5755694407684602296                   0.989068   \n",
      "6  4879721024980945592                   1.000000   \n",
      "7  2011981573061447208                   1.000000   \n",
      "8  2011981573061447208                   1.000000   \n",
      "9  2011981573061447208                   1.000000   \n",
      "\n",
      "   shop_review_positive_rate_ave  isHigh_shop_review_positive_rate  \n",
      "0                       0.995915                                 0  \n",
      "1                       0.996590                                 0  \n",
      "2                       0.996590                                 0  \n",
      "3                       0.996590                                 0  \n",
      "4                       0.996590                                 0  \n",
      "5                       0.996590                                 0  \n",
      "6                       0.990844                                 1  \n",
      "7                       0.992751                                 1  \n",
      "8                       0.992751                                 1  \n",
      "9                       0.992751                                 1  \n"
     ]
    }
   ],
   "source": [
    "#构造跟店铺信息相关的特征，评分是否高于平均水平，平均水平根据是否是同一个第一类目来判定\n",
    "def getIsHighFeture(train_df, test_df, colName):\n",
    "    \n",
    "    train_df[colName] = train_df[colName].map(lambda x: -1 if math.isnan(x) else x)\n",
    "    train_df['real_first_category'] = train_df.item_category_list.map(lambda x: x.split(';')[1])\n",
    "    notmiss_train_df = train_df[train_df[colName] != -1]\n",
    "    train_df_pivot_table = pd.pivot_table(notmiss_train_df[['real_first_category', 'shop_review_positive_rate']], index=['real_first_category'], values=['shop_review_positive_rate'], aggfunc=np.mean)\n",
    "    train_df_pivot_table.columns = [colName + '_ave']\n",
    "    train_df_pivot_table.reset_index(inplace=True)\n",
    "\n",
    "    notmiss_train_df = pd.merge(notmiss_train_df, train_df_pivot_table, on=['real_first_category'], how='left')\n",
    "    notmiss_train_df[colName + '_diff'] = notmiss_train_df[colName] - notmiss_train_df[colName + '_ave']\n",
    "    notmiss_train_df['isHigh_' + colName] = notmiss_train_df[colName + '_diff'].map(lambda x: 1 if x >= 0 else 0)\n",
    "\n",
    "    train_df['isHigh_' + colName] = 2\n",
    "    train_df['isHigh_' + colName][train_df[colName] != -1] = notmiss_train_df['isHigh_' + colName]\n",
    "    train_df[colName + '_ave'] = -1\n",
    "    train_df[colName + '_ave'][train_df[colName] != -1] = notmiss_train_df[colName + '_ave']\n",
    "    train_df[colName + '_diff'] = -1\n",
    "    train_df[colName + '_diff'][train_df[colName] != -1] = notmiss_train_df[colName + '_diff']\n",
    "\n",
    "    test_df[colName] = test_df[colName].map(lambda x: -1 if math.isnan(x) else x)\n",
    "    test_df['real_first_category'] = test_df.item_category_list.map(lambda x: x.split(';')[1])\n",
    "    notmiss_test_df = test_df[test_df[colName] != -1]\n",
    "    notmiss_test_df = pd.merge(notmiss_test_df, train_df_pivot_table, on=['real_first_category'], how='left')\n",
    "    notmiss_test_df[colName + '_ave'] = notmiss_test_df[colName + '_ave'].map(lambda x: -1 if x == np.nan else x)\n",
    "    test_df[colName + '_ave'] = -1\n",
    "    test_df[colName + '_ave'][test_df[colName] != -1] = notmiss_test_df[colName + '_ave']\n",
    "    test_df[colName + '_diff'] = -1\n",
    "    test_df[colName + '_diff'][test_df[colName + '_ave'] != -1] = test_df[colName][test_df[colName + '_ave'] != -1] - test_df[colName + '_ave'][test_df[colName + '_ave'] != -1]\n",
    "    test_df['isHigh_' + colName] = 2\n",
    "    test_df['isHigh_' + colName][test_df[colName + '_diff'] >= 0] = 1\n",
    "    test_df['isHigh_' + colName][test_df[colName + '_diff'] < 0] = 0\n",
    "    return train_df, test_df\n",
    "\n",
    "#添加特征\n",
    "train_df, test_df = getIsHighFeture(train_df, test_df, 'shop_review_positive_rate')\n",
    "train_df, test_df = getIsHighFeture(train_df, test_df, 'shop_score_service')\n",
    "train_df, test_df = getIsHighFeture(train_df, test_df, 'shop_score_delivery')\n",
    "train_df, test_df = getIsHighFeture(train_df, test_df, 'shop_score_description')\n",
    "\n",
    "print(train_df[['shop_review_positive_rate', 'shop_review_positive_rate_ave', 'isHigh_shop_review_positive_rate']].head(10))\n",
    "print(test_df[['real_first_category', 'shop_review_positive_rate', 'shop_review_positive_rate_ave', 'isHigh_shop_review_positive_rate']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               user_id              item_id                date  \\\n",
      "0  4505772604969228686  3412720377098676069 2018-09-18 10:09:04   \n",
      "1  2692638157208937547  3412720377098676069 2018-09-18 12:00:32   \n",
      "2  5247924392014515924  3412720377098676069 2018-09-18 03:04:12   \n",
      "3  2681414445369714628  3412720377098676069 2018-09-18 06:17:50   \n",
      "4  2729475788342039013  3412720377098676069 2018-09-18 19:48:40   \n",
      "5  4512655448325954611  3412720377098676069 2018-09-18 23:00:55   \n",
      "6  8811056487516803043   285660928590172217 2018-09-18 22:18:37   \n",
      "7  6507704883896466138   285660928590172217 2018-09-18 16:58:40   \n",
      "8  6203308008480593423  5202355029344881809 2018-09-18 02:27:51   \n",
      "9  6041712044514783312   285660928590172217 2018-09-18 23:43:10   \n",
      "\n",
      "   userItem_lastClickDeltaTime  \n",
      "0                   99999999.0  \n",
      "1                   99999999.0  \n",
      "2                   99999999.0  \n",
      "3                   99999999.0  \n",
      "4                   99999999.0  \n",
      "5                   99999999.0  \n",
      "6                   99999999.0  \n",
      "7                   99999999.0  \n",
      "8                   99999999.0  \n",
      "9                   99999999.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同商品的时间，同时对训练集和测试集进行处理\n",
    "def getUserItemLastClickDeltaTime(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_id', 'date', 'instance_id']], test_df[['user_id', 'item_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_id'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_item_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userItem_lastClickDeltaTime'] = historyShowList\n",
    "#     print(tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']].head(10))\n",
    "    temp = pd.merge(temp_df[['user_item_id', 'date']], tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']], on = ['user_item_id', 'date'], how = 'left')\n",
    "    train_df['userItem_lastClickDeltaTime'] = temp['userItem_lastClickDeltaTime'][:len(train_df['user_id'])]\n",
    "    test_df['userItem_lastClickDeltaTime'] = temp['userItem_lastClickDeltaTime'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getUserItemLastClickDeltaTime(train_df, test_df)\n",
    "print(train_df[['user_id', 'item_id', 'date', 'userItem_lastClickDeltaTime']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_item_brand_id                date  \\\n",
      "0  10000468422575080322479301133483350869 2018-09-20 09:44:00   \n",
      "1  10000531910868977561850538188661123614 2018-09-22 17:53:17   \n",
      "2  10000531910868977561869485793196349073 2018-09-22 09:52:49   \n",
      "3  10000531910868977561869485793196349073 2018-09-22 17:49:03   \n",
      "4  10000773166726440687838285046767229711 2018-09-23 16:44:11   \n",
      "5  10001070043842559681114275315610038623 2018-09-25 21:58:26   \n",
      "6  10001070043842559686400031259989360861 2018-09-25 21:56:32   \n",
      "7  10001437354507214243953456177407100048 2018-09-23 09:37:24   \n",
      "8  10001513848033675592348486371677245014 2018-09-22 21:49:53   \n",
      "9  10001513848033675594191021222338422219 2018-09-22 21:46:59   \n",
      "\n",
      "   userBrand_lastClickDeltaTime  \n",
      "0                    99999999.0  \n",
      "1                    99999999.0  \n",
      "2                    99999999.0  \n",
      "3                       28574.0  \n",
      "4                    99999999.0  \n",
      "5                    99999999.0  \n",
      "6                    99999999.0  \n",
      "7                    99999999.0  \n",
      "8                    99999999.0  \n",
      "9                    99999999.0  \n",
      "               user_id        item_brand_id                date  \\\n",
      "0  4505772604969228686  1975590437749032870 2018-09-18 10:09:04   \n",
      "1  2692638157208937547  1975590437749032870 2018-09-18 12:00:32   \n",
      "2  5247924392014515924  1975590437749032870 2018-09-18 03:04:12   \n",
      "3  2681414445369714628  1975590437749032870 2018-09-18 06:17:50   \n",
      "4  2729475788342039013  1975590437749032870 2018-09-18 19:48:40   \n",
      "5  4512655448325954611  1975590437749032870 2018-09-18 23:00:55   \n",
      "6  8811056487516803043  9057103201734987852 2018-09-18 22:18:37   \n",
      "7  6507704883896466138  9057103201734987852 2018-09-18 16:58:40   \n",
      "8  6203308008480593423  5520678735822176314 2018-09-18 02:27:51   \n",
      "9  6041712044514783312  9057103201734987852 2018-09-18 23:43:10   \n",
      "\n",
      "   userBrand_lastClickDeltaTime  \n",
      "0                    99999999.0  \n",
      "1                    99999999.0  \n",
      "2                    99999999.0  \n",
      "3                    99999999.0  \n",
      "4                    99999999.0  \n",
      "5                    99999999.0  \n",
      "6                    99999999.0  \n",
      "7                    99999999.0  \n",
      "8                    99999999.0  \n",
      "9                    99999999.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同品牌商品的时间，同时对训练集和测试集进行处理\n",
    "def getUserBrandLastClickDeltaTime(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'item_brand_id', 'date', 'instance_id']], test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_brand_id_str'] = temp_df['item_brand_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_brand_id'] = temp_df['user_id_str'] + temp_df['item_brand_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_brand_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['user_item_brand_id'].shift(1)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['last_user_item_brand_id']==tempDf['user_item_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_brand_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_item_brand_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userBrand_lastClickDeltaTime'] = historyShowList\n",
    "    print(tempDf[['user_item_brand_id', 'date', 'userBrand_lastClickDeltaTime']].head(10))\n",
    "    temp = pd.merge(temp_df[['user_item_brand_id', 'date']], tempDf[['user_item_brand_id', 'date', 'userBrand_lastClickDeltaTime']], on = ['user_item_brand_id', 'date'], how = 'left')\n",
    "    train_df['userBrand_lastClickDeltaTime'] = temp['userBrand_lastClickDeltaTime'][:len(train_df['user_id'])]\n",
    "    test_df['userBrand_lastClickDeltaTime'] = temp['userBrand_lastClickDeltaTime'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getUserBrandLastClickDeltaTime(train_df, test_df)\n",
    "print(train_df[['user_id', 'item_brand_id', 'date', 'userBrand_lastClickDeltaTime']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             user_shop_id                date  \\\n",
      "0  10000468422575080324571715481267183187 2018-09-20 09:44:00   \n",
      "1  10000531910868977563526941526328534645 2018-09-22 09:52:49   \n",
      "2  10000531910868977563526941526328534645 2018-09-22 17:49:03   \n",
      "3  10000531910868977567681669516894696027 2018-09-22 17:53:17   \n",
      "4  10000773166726440685239284608305401977 2018-09-23 16:44:11   \n",
      "5  10001070043842559681091499661419284880 2018-09-25 21:58:26   \n",
      "6  10001070043842559688884404577107716547 2018-09-25 21:56:32   \n",
      "7  10001437354507214244142178404332280874 2018-09-23 09:37:24   \n",
      "8   1000151384803367559500378403670609059 2018-09-22 21:50:40   \n",
      "9  10001513848033675596635220515139352173 2018-09-22 21:46:59   \n",
      "\n",
      "   userShop_lastClickDeltaTime  \n",
      "0                   99999999.0  \n",
      "1                   99999999.0  \n",
      "2                      28574.0  \n",
      "3                   99999999.0  \n",
      "4                   99999999.0  \n",
      "5                   99999999.0  \n",
      "6                   99999999.0  \n",
      "7                   99999999.0  \n",
      "8                   99999999.0  \n",
      "9                   99999999.0  \n",
      "               user_id              shop_id                date  \\\n",
      "0  4505772604969228686  6765930309048922341 2018-09-18 10:09:04   \n",
      "1  2692638157208937547  6765930309048922341 2018-09-18 12:00:32   \n",
      "2  5247924392014515924  6765930309048922341 2018-09-18 03:04:12   \n",
      "3  2681414445369714628  6765930309048922341 2018-09-18 06:17:50   \n",
      "4  2729475788342039013  6765930309048922341 2018-09-18 19:48:40   \n",
      "5  4512655448325954611  6765930309048922341 2018-09-18 23:00:55   \n",
      "6  8811056487516803043  4885989684392199728 2018-09-18 22:18:37   \n",
      "7  6507704883896466138  4885989684392199728 2018-09-18 16:58:40   \n",
      "8  6203308008480593423  4885989684392199728 2018-09-18 02:27:51   \n",
      "9  6041712044514783312  4885989684392199728 2018-09-18 23:43:10   \n",
      "\n",
      "   userShop_lastClickDeltaTime  \n",
      "0                   99999999.0  \n",
      "1                   99999999.0  \n",
      "2                   99999999.0  \n",
      "3                   99999999.0  \n",
      "4                   99999999.0  \n",
      "5                   99999999.0  \n",
      "6                   99999999.0  \n",
      "7                   99999999.0  \n",
      "8                   99999999.0  \n",
      "9                   99999999.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同店铺的时间，同时对训练集和测试集进行处理\n",
    "def getUserShopLastClickDeltaTime(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'shop_id', 'date', 'instance_id']], test_df[['user_id', 'shop_id', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['shop_id_str'] = temp_df['shop_id'].map(lambda x: str(x))\n",
    "    temp_df['user_shop_id'] = temp_df['user_id_str'] + temp_df['shop_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_shop_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_shop_id'] = tempDf['user_shop_id'].shift(1)\n",
    "    tempDf['last_user_shop_id'] = tempDf['last_user_shop_id']==tempDf['user_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_shop_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_shop_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userShop_lastClickDeltaTime'] = historyShowList\n",
    "    print(tempDf[['user_shop_id', 'date', 'userShop_lastClickDeltaTime']].head(10))\n",
    "    temp = pd.merge(temp_df[['user_shop_id', 'date']], tempDf[['user_shop_id', 'date', 'userShop_lastClickDeltaTime']], on = ['user_shop_id', 'date'], how = 'left')\n",
    "    train_df['userShop_lastClickDeltaTime'] = temp['userShop_lastClickDeltaTime'][:len(train_df['user_id'])]\n",
    "    test_df['userShop_lastClickDeltaTime'] = temp['userShop_lastClickDeltaTime'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getUserShopLastClickDeltaTime(train_df, test_df)\n",
    "print(train_df[['user_id', 'shop_id', 'date', 'userShop_lastClickDeltaTime']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_real_first_category                date  \\\n",
      "0  10000468422575080325755694407684602296 2018-09-20 09:44:00   \n",
      "1  10000531910868977565755694407684602296 2018-09-22 09:52:49   \n",
      "2  10000531910868977565755694407684602296 2018-09-22 17:49:03   \n",
      "3  10000531910868977565755694407684602296 2018-09-22 17:53:17   \n",
      "4  10000773166726440688277336076276184272 2018-09-23 16:44:11   \n",
      "5  10001070043842559688277336076276184272 2018-09-25 21:56:32   \n",
      "6  10001070043842559688277336076276184272 2018-09-25 21:58:26   \n",
      "7  10001437354507214248277336076276184272 2018-09-23 09:37:24   \n",
      "8   1000151384803367559509660095530134768 2018-09-22 21:46:59   \n",
      "9   1000151384803367559509660095530134768 2018-09-22 21:49:53   \n",
      "\n",
      "   userFirstCategory_lastClickDeltaTime  \n",
      "0                            99999999.0  \n",
      "1                            99999999.0  \n",
      "2                               28574.0  \n",
      "3                                 254.0  \n",
      "4                            99999999.0  \n",
      "5                            99999999.0  \n",
      "6                                 114.0  \n",
      "7                            99999999.0  \n",
      "8                            99999999.0  \n",
      "9                                 174.0  \n",
      "               user_id  real_first_category                date  \\\n",
      "0  4505772604969228686  5799347067982556520 2018-09-18 10:09:04   \n",
      "1  2692638157208937547  5799347067982556520 2018-09-18 12:00:32   \n",
      "2  5247924392014515924  5799347067982556520 2018-09-18 03:04:12   \n",
      "3  2681414445369714628  5799347067982556520 2018-09-18 06:17:50   \n",
      "4  2729475788342039013  5799347067982556520 2018-09-18 19:48:40   \n",
      "5  4512655448325954611  5799347067982556520 2018-09-18 23:00:55   \n",
      "6  8811056487516803043  8277336076276184272 2018-09-18 22:18:37   \n",
      "7  6507704883896466138  8277336076276184272 2018-09-18 16:58:40   \n",
      "8  6203308008480593423  5755694407684602296 2018-09-18 02:27:51   \n",
      "9  6041712044514783312  8277336076276184272 2018-09-18 23:43:10   \n",
      "\n",
      "   userFirstCategory_lastClickDeltaTime  \n",
      "0                            99999999.0  \n",
      "1                                  65.0  \n",
      "2                            99999999.0  \n",
      "3                            99999999.0  \n",
      "4                            99999999.0  \n",
      "5                                 763.0  \n",
      "6                                2550.0  \n",
      "7                            99999999.0  \n",
      "8                            99999999.0  \n",
      "9                                  24.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同根类目的时间，同时对训练集和测试集进行处理\n",
    "def getUserFirstCategoryLastClickDeltaTime(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_first_category', 'date', 'instance_id']], test_df[['user_id', 'real_first_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_first_category_str'] = temp_df['real_first_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_first_category'] = temp_df['user_id_str'] + temp_df['real_first_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_real_first_category', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userFirstCategory_lastClickDeltaTime'] = historyShowList\n",
    "    print(tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']].head(10))\n",
    "    temp = pd.merge(temp_df[['user_real_first_category', 'date']], tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']], on = ['user_real_first_category', 'date'], how = 'left')\n",
    "    train_df['userFirstCategory_lastClickDeltaTime'] = temp['userFirstCategory_lastClickDeltaTime'][:len(train_df['user_id'])]\n",
    "    test_df['userFirstCategory_lastClickDeltaTime'] = temp['userFirstCategory_lastClickDeltaTime'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getUserFirstCategoryLastClickDeltaTime(train_df, test_df)\n",
    "print(train_df[['user_id', 'real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_real_last_category                date  \\\n",
      "0    10000468422575080329 2018-09-20 09:44:00   \n",
      "1    10000531910868977569 2018-09-22 09:52:49   \n",
      "2    10000531910868977569 2018-09-22 17:49:03   \n",
      "3    10000531910868977569 2018-09-22 17:53:17   \n",
      "4    10000773166726440689 2018-09-23 16:44:11   \n",
      "5    10001070043842559689 2018-09-25 21:56:32   \n",
      "6    10001070043842559689 2018-09-25 21:58:26   \n",
      "7    10001437354507214249 2018-09-23 09:37:24   \n",
      "8    10001513848033675599 2018-09-22 21:46:59   \n",
      "9    10001513848033675599 2018-09-22 21:49:53   \n",
      "\n",
      "   userLastCategory_lastClickDeltaTime  \n",
      "0                           99999999.0  \n",
      "1                           99999999.0  \n",
      "2                              28574.0  \n",
      "3                                254.0  \n",
      "4                           99999999.0  \n",
      "5                           99999999.0  \n",
      "6                                114.0  \n",
      "7                           99999999.0  \n",
      "8                           99999999.0  \n",
      "9                                174.0  \n",
      "               user_id real_last_category                date  \\\n",
      "0  4505772604969228686                  9 2018-09-18 10:09:04   \n",
      "1  2692638157208937547                  9 2018-09-18 12:00:32   \n",
      "2  5247924392014515924                  9 2018-09-18 03:04:12   \n",
      "3  2681414445369714628                  9 2018-09-18 06:17:50   \n",
      "4  2729475788342039013                  9 2018-09-18 19:48:40   \n",
      "5  4512655448325954611                  9 2018-09-18 23:00:55   \n",
      "6  8811056487516803043                  9 2018-09-18 22:18:37   \n",
      "7  6507704883896466138                  9 2018-09-18 16:58:40   \n",
      "8  6203308008480593423                  9 2018-09-18 02:27:51   \n",
      "9  6041712044514783312                  9 2018-09-18 23:43:10   \n",
      "\n",
      "   userLastCategory_lastClickDeltaTime  \n",
      "0                           99999999.0  \n",
      "1                                 65.0  \n",
      "2                           99999999.0  \n",
      "3                           99999999.0  \n",
      "4                           99999999.0  \n",
      "5                                763.0  \n",
      "6                               2550.0  \n",
      "7                           99999999.0  \n",
      "8                           99999999.0  \n",
      "9                                 24.0  \n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同叶子类目的时间，同时对训练集和测试集进行处理\n",
    "def getUserLastCategoryLastClickDeltaTime(train_df, test_df):\n",
    "    df = pd.concat([train_df[['user_id', 'real_last_category', 'date', 'instance_id']], test_df[['user_id', 'real_last_category', 'date', 'instance_id']]])\n",
    "    temp_df = df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['real_last_category_str'] = temp_df['real_last_category'].map(lambda x: str(x))\n",
    "    temp_df['user_real_last_category'] = temp_df['user_id_str'] + temp_df['real_last_category_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_real_last_category', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userLastCategory_lastClickDeltaTime'] = historyShowList\n",
    "    print(tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']].head(10))\n",
    "    temp = pd.merge(temp_df[['user_real_last_category', 'date']], tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']], on = ['user_real_last_category', 'date'], how = 'left')\n",
    "    train_df['userLastCategory_lastClickDeltaTime'] = temp['userLastCategory_lastClickDeltaTime'][:len(train_df['user_id'])]\n",
    "    test_df['userLastCategory_lastClickDeltaTime'] = temp['userLastCategory_lastClickDeltaTime'][len(train_df['user_id']):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getUserLastCategoryLastClickDeltaTime(train_df, test_df)\n",
    "print(train_df[['user_id', 'real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               user_id              item_id  shop_item_classNumber  \\\n",
      "0  4505772604969228686  3412720377098676069                    3.0   \n",
      "1  2692638157208937547  3412720377098676069                    3.0   \n",
      "2  5247924392014515924  3412720377098676069                    3.0   \n",
      "3  2681414445369714628  3412720377098676069                    3.0   \n",
      "4  2729475788342039013  3412720377098676069                    3.0   \n",
      "5  4512655448325954611  3412720377098676069                    3.0   \n",
      "6  8811056487516803043   285660928590172217                    3.0   \n",
      "7  6507704883896466138   285660928590172217                    3.0   \n",
      "8  6203308008480593423  5202355029344881809                    3.0   \n",
      "9  6041712044514783312   285660928590172217                    3.0   \n",
      "\n",
      "   brand_item_classNumber  city_item_classNumber  shop_user_classNumber  \\\n",
      "0                    65.0                    3.0                  119.0   \n",
      "1                    65.0                    3.0                  119.0   \n",
      "2                    65.0                    3.0                  119.0   \n",
      "3                    65.0                    3.0                  119.0   \n",
      "4                    65.0                    3.0                  119.0   \n",
      "5                    65.0                    3.0                  119.0   \n",
      "6                    65.0                    3.0                  119.0   \n",
      "7                    65.0                    3.0                  119.0   \n",
      "8                    65.0                    3.0                  119.0   \n",
      "9                    65.0                    3.0                  119.0   \n",
      "\n",
      "   brand_user_classNumber  city_user_classNumber  \n",
      "0                   492.0                   34.0  \n",
      "1                   492.0                   34.0  \n",
      "2                   492.0                   34.0  \n",
      "3                   492.0                   34.0  \n",
      "4                   492.0                   34.0  \n",
      "5                   492.0                   34.0  \n",
      "6                   492.0                   34.0  \n",
      "7                   492.0                   34.0  \n",
      "8                   492.0                   34.0  \n",
      "9                   492.0                  271.0  \n"
     ]
    }
   ],
   "source": [
    "# 定义获取某种店铺，品牌，城市对应商品种类，用户数的函数\n",
    "def getCorrespondNumber(train_df, test_df, colName1, colName2, newColName):\n",
    "    df = pd.concat([train_df[[colName1, colName2, 'instance_id']], test_df[[colName1, colName2, 'instance_id']]])\n",
    "    temp_df = df[[colName1, colName2, 'instance_id']]\n",
    "    tempDf = temp_df.sort_values(by=colName1, ascending=False)\n",
    "    tempDf['last_' + colName1] = tempDf[colName1].shift(1)\n",
    "    tempDf['same'] = tempDf['last_' + colName1]==tempDf[colName1]\n",
    "    \n",
    "    colName1List = []\n",
    "    countList = []\n",
    "    colName2Set = set()\n",
    "    for same, col2, last_col1 in tempDf[['same', colName2, 'last_' + colName1]].values:\n",
    "        if same:\n",
    "            colName2Set.add(col2)\n",
    "        else:\n",
    "            colName1List.append(last_col1)\n",
    "            countList.append(len(colName2Set))\n",
    "            colName2Set = {col2}\n",
    "    #处理最后一行数据\n",
    "    last_col1 = tempDf.iloc[-1][colName1]\n",
    "    last_count = len(colName2Set)\n",
    "    colName1List.append(last_col1)\n",
    "    countList.append(last_count)\n",
    "    #将结果组合到tempDf中\n",
    "    result_df = {colName1: colName1List, newColName: countList}\n",
    "    result_df = DataFrame(result_df)\n",
    "    result_df = result_df[1:]\n",
    "    tempDf = pd.merge(tempDf[[colName1, colName2]], result_df[[colName1, newColName]], on=[colName1])\n",
    "#     print(tempDf[[colName1, colName2, newColName]].head(10))\n",
    "    temp = pd.merge(temp_df[[colName1, colName2]], tempDf[[colName1, colName2, newColName]], on = [colName1, colName2])\n",
    "    \n",
    "    train_df[newColName] = temp[newColName][:len(train_df[colName1])]\n",
    "    test_df[newColName] = temp[newColName][len(train_df[colName1]):]\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'shop_id', 'item_id', 'shop_item_classNumber')\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'item_brand_id', 'item_id', 'brand_item_classNumber')\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'item_city_id', 'item_id', 'city_item_classNumber')\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'shop_id', 'user_id', 'shop_user_classNumber')\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'item_brand_id', 'user_id', 'brand_user_classNumber')\n",
    "train_df, test_df = getCorrespondNumber(train_df, test_df, 'item_city_id', 'user_id', 'city_user_classNumber')\n",
    "print(train_df[['user_id', 'item_id', 'shop_item_classNumber', 'brand_item_classNumber', 'city_item_classNumber',\n",
    "               'shop_user_classNumber', 'brand_user_classNumber', 'city_user_classNumber']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_drop_fea = ['shop_review_positive_rate_ave', 'shop_score_service_ave', 'shop_score_delivery_ave', 'shop_score_description_ave']\n",
    "test_drop_fea = ['shop_review_positive_rate_ave', 'shop_score_service_ave', 'shop_score_delivery_ave', 'shop_score_description_ave']\n",
    "def dropFeture(drop_fea, df):\n",
    "    for fea in drop_fea:\n",
    "        df = df.drop(fea, 1)\n",
    "    return df\n",
    "train_df = dropFeture(train_drop_fea, train_df)\n",
    "test_df = dropFeture(test_drop_fea, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instance_id' 'item_id' 'item_category_list' 'item_property_list'\n",
      " 'item_brand_id' 'item_city_id' 'item_price_level' 'item_sales_level'\n",
      " 'item_collected_level' 'item_pv_level' 'user_id' 'user_gender_id'\n",
      " 'user_age_level' 'user_occupation_id' 'user_star_level' 'context_id'\n",
      " 'context_timestamp' 'context_page_id' 'predict_category_property'\n",
      " 'shop_id' 'shop_review_num_level' 'shop_review_positive_rate'\n",
      " 'shop_star_level' 'shop_score_service' 'shop_score_delivery'\n",
      " 'shop_score_description' 'is_trade' 'date' 'weekday' 'day' 'hour'\n",
      " 'context_page_id_1' 'context_page_id_2' 'context_page_id_3'\n",
      " 'context_page_id_4' 'item_price_level_0' 'item_price_level_1'\n",
      " 'item_pv_level_low' 'shop_review_num_level_lowHigh'\n",
      " 'shop_star_level_lowHigh' 'shop_star_level_middle' 'shop_star_level_loss'\n",
      " 'day_hour' 'predict_category_list' 'predict_category_set'\n",
      " 'real_item_category_list' 'predict_property_list'\n",
      " 'match_category_proportion' 'match_property_proportion'\n",
      " 'predict_category_number' 'predict_property_number' 'isFirstCategoryIn'\n",
      " 'isLastCategoryIn' 'category_number' 'property_number'\n",
      " 'is_highProportion_brand' 'is_highSale_brand' 'item_sales_price'\n",
      " 'item_sales_collected' 'item_sales_pv' 'item_price_collected'\n",
      " 'item_price_pv' 'item_collected_pv' 'user_gender_age'\n",
      " 'user_gender_occupation' 'user_gender_star' 'user_age_occupation'\n",
      " 'user_age_star' 'user_occupation_star' 'shop_review_star'\n",
      " 'lastOneHour_sameItem_count' 'real_first_category' 'real_last_category'\n",
      " 'lastOneHour_sameFirstCategory_count' 'lastOneHour_sameLastCategory_count'\n",
      " 'lastOneHour_sameBrand_count' 'lastOneHour_sameShop_count'\n",
      " 'isLastOneHour_firstClickItem' 'lastOneDay_sameItem_count'\n",
      " 'lastOneDay_sameFirstCategory_count' 'lastOneDay_sameLastCategory_count'\n",
      " 'lastOneDay_sameBrand_count' 'lastOneDay_sameShop_count'\n",
      " 'history_sameItem_count' 'history_sameFirstCategory_count'\n",
      " 'history_sameLastCategory_count' 'history_sameBrand_count'\n",
      " 'history_sameShop_count' 'is_history_sameItem'\n",
      " 'is_history_sameFirstCategory' 'is_history_sameLastCategory'\n",
      " 'is_history_sameBrand' 'is_history_sameShop' 'is_history_firstClickItem'\n",
      " 'is_later_clickSameItem' 'is_later_clickSameLastCategory'\n",
      " 'later_clickSameLastCategory_count' 'later_clickSameItem_count'\n",
      " 'isHigh_shop_review_positive_rate' 'shop_review_positive_rate_diff'\n",
      " 'isHigh_shop_score_service' 'shop_score_service_diff'\n",
      " 'isHigh_shop_score_delivery' 'shop_score_delivery_diff'\n",
      " 'isHigh_shop_score_description' 'shop_score_description_diff'\n",
      " 'userItem_lastClickDeltaTime' 'userBrand_lastClickDeltaTime'\n",
      " 'userShop_lastClickDeltaTime' 'userFirstCategory_lastClickDeltaTime'\n",
      " 'userLastCategory_lastClickDeltaTime' 'shop_item_classNumber'\n",
      " 'brand_item_classNumber' 'city_item_classNumber' 'shop_user_classNumber'\n",
      " 'brand_user_classNumber' 'city_user_classNumber']\n",
      "['instance_id' 'item_id' 'item_category_list' 'item_property_list'\n",
      " 'item_brand_id' 'item_city_id' 'item_price_level' 'item_sales_level'\n",
      " 'item_collected_level' 'item_pv_level' 'user_id' 'user_gender_id'\n",
      " 'user_age_level' 'user_occupation_id' 'user_star_level' 'context_id'\n",
      " 'context_timestamp' 'context_page_id' 'predict_category_property'\n",
      " 'shop_id' 'shop_review_num_level' 'shop_review_positive_rate'\n",
      " 'shop_star_level' 'shop_score_service' 'shop_score_delivery'\n",
      " 'shop_score_description' 'date' 'weekday' 'day' 'hour' 'day_hour'\n",
      " 'context_page_id_1' 'context_page_id_2' 'context_page_id_3'\n",
      " 'context_page_id_4' 'item_price_level_0' 'item_price_level_1'\n",
      " 'item_pv_level_low' 'shop_review_num_level_lowHigh'\n",
      " 'shop_star_level_lowHigh' 'shop_star_level_middle' 'shop_star_level_loss'\n",
      " 'predict_category_list' 'predict_category_set' 'real_item_category_list'\n",
      " 'predict_property_list' 'match_category_proportion'\n",
      " 'match_property_proportion' 'predict_category_number'\n",
      " 'predict_property_number' 'isFirstCategoryIn' 'isLastCategoryIn'\n",
      " 'real_first_category' 'real_last_category' 'is_highProportion_brand'\n",
      " 'is_highSale_brand' 'category_number' 'property_number' 'item_sales_price'\n",
      " 'item_sales_collected' 'item_sales_pv' 'item_price_collected'\n",
      " 'item_price_pv' 'item_collected_pv' 'user_gender_age'\n",
      " 'user_gender_occupation' 'user_gender_star' 'user_age_occupation'\n",
      " 'user_age_star' 'user_occupation_star' 'shop_review_star'\n",
      " 'lastOneHour_sameItem_count' 'lastOneHour_sameFirstCategory_count'\n",
      " 'lastOneHour_sameLastCategory_count' 'lastOneHour_sameBrand_count'\n",
      " 'lastOneHour_sameShop_count' 'isLastOneHour_firstClickItem'\n",
      " 'lastOneDay_sameItem_count' 'lastOneDay_sameFirstCategory_count'\n",
      " 'lastOneDay_sameLastCategory_count' 'lastOneDay_sameBrand_count'\n",
      " 'lastOneDay_sameShop_count' 'history_sameItem_count'\n",
      " 'history_sameFirstCategory_count' 'history_sameLastCategory_count'\n",
      " 'history_sameBrand_count' 'history_sameShop_count' 'is_history_sameItem'\n",
      " 'is_history_sameFirstCategory' 'is_history_sameLastCategory'\n",
      " 'is_history_sameBrand' 'is_history_sameShop' 'is_history_firstClickItem'\n",
      " 'is_later_clickSameItem' 'is_later_clickSameLastCategory'\n",
      " 'later_clickSameLastCategory_count' 'later_clickSameItem_count'\n",
      " 'shop_review_positive_rate_diff' 'isHigh_shop_review_positive_rate'\n",
      " 'shop_score_service_diff' 'isHigh_shop_score_service'\n",
      " 'shop_score_delivery_diff' 'isHigh_shop_score_delivery'\n",
      " 'shop_score_description_diff' 'isHigh_shop_score_description'\n",
      " 'userItem_lastClickDeltaTime' 'userBrand_lastClickDeltaTime'\n",
      " 'userShop_lastClickDeltaTime' 'userFirstCategory_lastClickDeltaTime'\n",
      " 'userLastCategory_lastClickDeltaTime' 'shop_item_classNumber'\n",
      " 'brand_item_classNumber' 'city_item_classNumber' 'shop_user_classNumber'\n",
      " 'brand_user_classNumber' 'city_user_classNumber']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.values)\n",
    "print(test_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #添加one-hot编码并保留原字段\n",
    "# def addOneHot(df, colName):\n",
    "#     colDum = pd.get_dummies(df[colName], prefix=colName)\n",
    "#     df = pd.concat([df, colDum], axis=1)\n",
    "#     return df\n",
    "\n",
    "# #将相关字段进行one-hot编码\n",
    "# def oneHotData(train_df, test_df, colSet):\n",
    "#     for colName in colSet:\n",
    "#         train_df = addOneHot(train_df, colName)\n",
    "#         test_df = addOneHot(test_df, colName)\n",
    "#     return train_df, test_df\n",
    "\n",
    "# oneHotColSet = ['item_sales_level', 'item_collected_level', 'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level']\n",
    "# train_df, test_df = oneHotData(train_df, test_df, oneHotColSet)\n",
    "\n",
    "# print(train_df.head(10))\n",
    "# print(test_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "116\n",
      "42888\n",
      "42888\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df_b.columns.values))\n",
    "print(len(test_df.columns.values))\n",
    "\n",
    "test_df = pd.merge(test_df_b[['instance_id']], test_df, on=['instance_id'])\n",
    "\n",
    "print(len(test_df_b))\n",
    "print(len(test_df))\n",
    "print(len(test_df.columns.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instance_id' 'item_id' 'item_category_list' 'item_property_list'\n",
      " 'item_brand_id' 'item_city_id' 'item_price_level' 'item_sales_level'\n",
      " 'item_collected_level' 'item_pv_level' 'user_id' 'user_gender_id'\n",
      " 'user_age_level' 'user_occupation_id' 'user_star_level' 'context_id'\n",
      " 'context_timestamp' 'context_page_id' 'predict_category_property'\n",
      " 'shop_id' 'shop_review_num_level' 'shop_review_positive_rate'\n",
      " 'shop_star_level' 'shop_score_service' 'shop_score_delivery'\n",
      " 'shop_score_description' 'date' 'weekday' 'day' 'hour' 'day_hour'\n",
      " 'context_page_id_1' 'context_page_id_2' 'context_page_id_3'\n",
      " 'context_page_id_4' 'item_price_level_0' 'item_price_level_1'\n",
      " 'item_pv_level_low' 'shop_review_num_level_lowHigh'\n",
      " 'shop_star_level_lowHigh' 'shop_star_level_middle' 'shop_star_level_loss'\n",
      " 'predict_category_list' 'predict_category_set' 'real_item_category_list'\n",
      " 'predict_property_list' 'match_category_proportion'\n",
      " 'match_property_proportion' 'predict_category_number'\n",
      " 'predict_property_number' 'isFirstCategoryIn' 'isLastCategoryIn'\n",
      " 'real_first_category' 'real_last_category' 'is_highProportion_brand'\n",
      " 'is_highSale_brand' 'category_number' 'property_number' 'item_sales_price'\n",
      " 'item_sales_collected' 'item_sales_pv' 'item_price_collected'\n",
      " 'item_price_pv' 'item_collected_pv' 'user_gender_age'\n",
      " 'user_gender_occupation' 'user_gender_star' 'user_age_occupation'\n",
      " 'user_age_star' 'user_occupation_star' 'shop_review_star'\n",
      " 'lastOneHour_sameItem_count' 'lastOneHour_sameFirstCategory_count'\n",
      " 'lastOneHour_sameLastCategory_count' 'lastOneHour_sameBrand_count'\n",
      " 'lastOneHour_sameShop_count' 'isLastOneHour_firstClickItem'\n",
      " 'lastOneDay_sameItem_count' 'lastOneDay_sameFirstCategory_count'\n",
      " 'lastOneDay_sameLastCategory_count' 'lastOneDay_sameBrand_count'\n",
      " 'lastOneDay_sameShop_count' 'history_sameItem_count'\n",
      " 'history_sameFirstCategory_count' 'history_sameLastCategory_count'\n",
      " 'history_sameBrand_count' 'history_sameShop_count' 'is_history_sameItem'\n",
      " 'is_history_sameFirstCategory' 'is_history_sameLastCategory'\n",
      " 'is_history_sameBrand' 'is_history_sameShop' 'is_history_firstClickItem'\n",
      " 'is_later_clickSameItem' 'is_later_clickSameLastCategory'\n",
      " 'later_clickSameLastCategory_count' 'later_clickSameItem_count'\n",
      " 'shop_review_positive_rate_diff' 'isHigh_shop_review_positive_rate'\n",
      " 'shop_score_service_diff' 'isHigh_shop_score_service'\n",
      " 'shop_score_delivery_diff' 'isHigh_shop_score_delivery'\n",
      " 'shop_score_description_diff' 'isHigh_shop_score_description'\n",
      " 'userItem_lastClickDeltaTime' 'userBrand_lastClickDeltaTime'\n",
      " 'userShop_lastClickDeltaTime' 'userFirstCategory_lastClickDeltaTime'\n",
      " 'userLastCategory_lastClickDeltaTime' 'shop_item_classNumber'\n",
      " 'brand_item_classNumber' 'city_item_classNumber' 'shop_user_classNumber'\n",
      " 'brand_user_classNumber' 'city_user_classNumber']\n",
      "['instance_id' 'item_id' 'item_category_list' 'item_property_list'\n",
      " 'item_brand_id' 'item_city_id' 'item_price_level' 'item_sales_level'\n",
      " 'item_collected_level' 'item_pv_level' 'user_id' 'user_gender_id'\n",
      " 'user_age_level' 'user_occupation_id' 'user_star_level' 'context_id'\n",
      " 'context_timestamp' 'context_page_id' 'predict_category_property'\n",
      " 'shop_id' 'shop_review_num_level' 'shop_review_positive_rate'\n",
      " 'shop_star_level' 'shop_score_service' 'shop_score_delivery'\n",
      " 'shop_score_description']\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns.values)\n",
    "print(test_df_b.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导出训练集预处理结果\n",
    "def exportResult(df, fileName):\n",
    "    df.to_csv('./%s.csv' % fileName, header=True, index=False)\n",
    "    \n",
    "exportResult(train_df, 'chusai_train_df')\n",
    "exportResult(test_df, 'chusai_test_df')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42888\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
