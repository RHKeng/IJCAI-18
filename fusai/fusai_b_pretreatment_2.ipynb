{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import csv\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from datetime import *\n",
    "import matplotlib.pylab as pylab\n",
    "from pylab import *\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "from sklearn.preprocessing import *\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import matplotlib.dates\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "import matplotlib.pylab as plt\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~开始导入数据~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~导入数据完毕~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print('~~~~~~~~~~~~~~开始导入数据~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "train_df_3 = pd.read_csv('/usr/competition/alimama/data/fusai/fusai_b_train_df_3_sample.csv')\n",
    "train_df_2 = pd.read_csv('/usr/competition/alimama/data/fusai/fusai_b_train_df_2_sample.csv')\n",
    "train_df_1 = pd.read_csv('/usr/competition/alimama/data/fusai/fusai_b_train_df_1_sample.csv')\n",
    "\n",
    "print('~~~~~~~~~~~~~~导入数据完毕~~~~~~~~~~~~~~~~~~~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 拆分多维度拼接的字段\n",
    "def splitMultiFea(df):\n",
    "    tempDf = df.drop_duplicates(subset=['item_id'])[['item_id','item_category_list','item_property_list']]\n",
    "    tempDf['item_category_list_str'] = tempDf['item_category_list'].values\n",
    "    tempDf['item_property_list_str'] = tempDf['item_property_list'].values\n",
    "    tempDf['item_category_list'] = tempDf[tempDf.item_category_list.notnull()]['item_category_list'].map(lambda x: x.split(';'))\n",
    "    tempDf['item_category0'] = tempDf[tempDf.item_category_list.notnull()]['item_category_list'].map(lambda x: x[0])\n",
    "    tempDf['item_category1'] = tempDf[tempDf.item_category_list.notnull()]['item_category_list'].map(lambda x: x[1] if len(x)>1 else np.nan)\n",
    "    tempDf['item_category2'] = tempDf[tempDf.item_category_list.notnull()]['item_category_list'].map(lambda x: x[2] if len(x)>2 else np.nan)\n",
    "    tempDf['item_property_list'] = tempDf[tempDf.item_property_list.notnull()]['item_property_list'].map(lambda x: x.split(';'))\n",
    "    df = df.drop(['item_category_list','item_property_list'], axis=1).merge(tempDf, how='left', on='item_id')\n",
    "    df['item_prop_num'] = df['item_property_list'].dropna().map(lambda x: len(x))\n",
    "    df['predict_category_property_str'] = df['predict_category_property'].values\n",
    "    df['predict_category_property'] = df[df.predict_category_property.notnull()]['predict_category_property'].map(\n",
    "        lambda x: {kv.split(':')[0]:((kv.split(':')[1].split(',') if kv.split(':')[1]!='-1' else []) if len(kv.split(':')) >= 2 else []) for kv in x.split(';')})\n",
    "    return df\n",
    "\n",
    "# 添加广告商品与查询词的相关性特征\n",
    "def addContextFea(df):\n",
    "    df['predict_category'] = df['predict_category_property'].dropna().map(lambda x: list(x.keys()))\n",
    "    df['predict_cate_num'] = df['predict_category'].dropna().map(lambda x: len(x))\n",
    "    idx = df[df.predict_category_property.notnull()].index\n",
    "    df.loc[idx,'cate_intersect_num'] = list(map(lambda x: len(np.intersect1d(x[0],x[1])), df.loc[idx, ['item_category_list','predict_category']].values))\n",
    "    df['predict_property'] = [set() for i in range(len(df))]\n",
    "    idx = df[(df.item_category2.notnull())&(df.predict_category_property.notnull())].index\n",
    "    df.loc[idx,'predict_property'] = list(map(lambda x: x[2]|set(x[1][x[0]]) if (x[0] in x[1].keys()) else x[2], df.loc[idx,['item_category2','predict_category_property','predict_property']].values))\n",
    "    idx = df[(df.item_category1.notnull())&(df.predict_category_property.notnull())].index\n",
    "    df.loc[idx,'predict_property'] = list(map(lambda x: x[2]|set(x[1][x[0]]) if (x[0] in x[1].keys()) else x[2], df.loc[idx,['item_category1','predict_category_property','predict_property']].values))\n",
    "    df['predict_property'] = df['predict_property'].map(lambda x: np.nan if len(x)==0 else list(x))\n",
    "    df['predict_prop_num'] = df[df.predict_property.notnull()]['predict_property'].map(lambda x: len(x))\n",
    "    idx = df[(df.predict_property.notnull())&(df.item_property_list.notnull())].index\n",
    "    df.loc[idx, 'prop_intersect_num'] = list(map(lambda x: len(np.intersect1d(x[0],x[1])), df.loc[idx, ['item_property_list','predict_property']].values))\n",
    "    df.loc[idx,'prop_union_num'] = list(map(lambda x: len(np.union1d(x[0],x[1])), df.loc[idx, ['item_property_list','predict_property']].values))\n",
    "    df['prop_jaccard'] = df['prop_intersect_num'] / df['prop_union_num']\n",
    "    df['prop_predict_ratio'] = df['prop_intersect_num'] / df['predict_prop_num']\n",
    "    df['prop_item_ratio'] = df['prop_intersect_num'] / df['item_prop_num']\n",
    "    df.fillna({k:-1 for k in ['predict_prop_num','prop_intersect_num','prop_union_num','prop_jaccard','prop_predict_ratio','prop_item_ratio']}, inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df_3 = splitMultiFea(train_df_3)\n",
    "train_df_2 = splitMultiFea(train_df_2)\n",
    "train_df_1 = splitMultiFea(train_df_1)\n",
    "\n",
    "train_df_3 = addContextFea(train_df_3)\n",
    "train_df_2 = addContextFea(train_df_2)\n",
    "train_df_1 = addContextFea(train_df_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addSet(setList):\n",
    "    allSet = []\n",
    "    for member in setList:\n",
    "        allSet = allSet + member\n",
    "    allSet = set(allSet)\n",
    "    return allSet\n",
    "\n",
    "#处理跟商品类目和属性相关的特征\n",
    "def getCategoryFuture(df):\n",
    "    df['predict_category_list'] = df['predict_category_property'].map(lambda x: [] if x == np.nan else list(kv.split(':')[0] for kv in str(x).split(';')))\n",
    "    df['predict_category_set'] = df['predict_category_list'].map(lambda x: set(x))\n",
    "    df['real_item_category_list'] = df['item_category_list'].map(lambda x: set(x))\n",
    "\n",
    "    df['predict_property_list'] = df['predict_category_property'].map(lambda x: [] if x == np.nan else ((kv.split(':')[1].split(',') if kv.split(':')[1]!='-1' else []) if len(kv.split(':')) >= 2 else [] for kv in str(x).split(';')))\n",
    "    df['predict_property_list'] = df['predict_property_list'].map(lambda x: addSet(x))\n",
    "    df['item_property_list'] = df['item_property_list'].map(lambda x: set(x))\n",
    "    return df\n",
    "\n",
    "def getMatchProportion(df):\n",
    "    match_category_proportion = []\n",
    "    match_property_proportion = []\n",
    "    for x,y,m,n in df[['real_item_category_list', 'predict_category_set', 'item_property_list', 'predict_property_list']].values:\n",
    "        match_category = x & y\n",
    "        match_property = m & n\n",
    "        if len(y) > 0:\n",
    "            category_proportion = len(match_category) / len(y)\n",
    "            match_category_proportion.append(category_proportion)\n",
    "        else:\n",
    "            match_category_proportion.append(0)\n",
    "        if len(n) > 0:\n",
    "            property_proportion = len(match_property) / len(n)\n",
    "            match_property_proportion.append(property_proportion)\n",
    "        else:\n",
    "            match_property_proportion.append(0)\n",
    "    df['match_category_proportion'] = match_category_proportion\n",
    "    df['match_property_proportion'] = match_property_proportion\n",
    "    return df\n",
    "\n",
    "#构造跟预测数目相关的特征\n",
    "def getPredictNumber(df):\n",
    "    df['predict_category_number'] = df['predict_category_set'].map(lambda x: len(x))\n",
    "    df['predict_property_number'] = df['predict_property_list'].map(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "#构造跟类目预测精确性相关的特征\n",
    "def getPredictAccuracy(df):\n",
    "    isFirstCategoryIn = []\n",
    "    isLastCategoryIn = []\n",
    "    for x,y in df[['real_item_category_list', 'predict_category_list']].values:\n",
    "        if y[0] in x:\n",
    "            isFirstCategoryIn.append(1)\n",
    "        else:\n",
    "            isFirstCategoryIn.append(0)\n",
    "        if y[len(y)-1] in x:\n",
    "            isLastCategoryIn.append(1)\n",
    "        else:\n",
    "            isLastCategoryIn.append(0)\n",
    "    df['isFirstCategoryIn'] = isFirstCategoryIn\n",
    "    df['isLastCategoryIn'] = isLastCategoryIn\n",
    "    return df\n",
    "\n",
    "#添加商品属性个数以及类目个数特征\n",
    "def getCPNumber(df):\n",
    "    df['category_number'] = df['item_category_list'].map(lambda x: len(x))\n",
    "    df['property_number'] = df['item_property_list'].map(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "train_df_3 = getCategoryFuture(train_df_3)\n",
    "train_df_2 = getCategoryFuture(train_df_2)\n",
    "train_df_1 = getCategoryFuture(train_df_1)\n",
    "\n",
    "train_df_3 = getMatchProportion(train_df_3)\n",
    "train_df_2 = getMatchProportion(train_df_2)\n",
    "train_df_1 = getMatchProportion(train_df_1)\n",
    "\n",
    "train_df_3 = getPredictNumber(train_df_3)\n",
    "train_df_2 = getPredictNumber(train_df_2)\n",
    "train_df_1 = getPredictNumber(train_df_1)\n",
    "\n",
    "train_df_3 = getPredictAccuracy(train_df_3)\n",
    "train_df_2 = getPredictAccuracy(train_df_2)\n",
    "train_df_1 = getPredictAccuracy(train_df_1)\n",
    "\n",
    "train_df_3 = getCPNumber(train_df_3)\n",
    "train_df_2 = getCPNumber(train_df_2)\n",
    "train_df_1 = getCPNumber(train_df_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入测试集进行数据处理\n",
    "test_df = pd.read_csv('/usr/competition/alimama/data/fusai/fusai_b_test_df_sample.csv')\n",
    "test_df['date'] = test_df.context_timestamp.map(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "test_df['weekday'] = test_df['date'].map(lambda x: x.weekday())\n",
    "test_df['day'] = test_df['date'].map(lambda x: x.day)\n",
    "test_df['hour'] = test_df['date'].map(lambda x: x.hour)\n",
    "test_df = splitMultiFea(test_df)\n",
    "test_df = addContextFea(test_df)\n",
    "test_df = getCategoryFuture(test_df)\n",
    "test_df = getMatchProportion(test_df)\n",
    "test_df = getPredictNumber(test_df)\n",
    "test_df = getPredictAccuracy(test_df)\n",
    "test_df = getCPNumber(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构造跟商品实际的根类目和叶子类目特征\n",
    "train_df_1['real_first_category'] = train_df_1['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[0])\n",
    "train_df_1['real_last_category'] = train_df_1['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[len(x) -1])\n",
    "train_df_2['real_first_category'] = train_df_2['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[0])\n",
    "train_df_2['real_last_category'] = train_df_2['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[len(x) -1])\n",
    "train_df_3['real_first_category'] = train_df_3['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[0])\n",
    "train_df_3['real_last_category'] = train_df_3['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[len(x) -1])\n",
    "test_df['real_first_category'] = test_df['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[0])\n",
    "test_df['real_last_category'] = test_df['item_category_list'].map(lambda x: np.nan if len(x) < 1 else x[len(x) -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instance_id' 'item_id' 'item_brand_id' 'item_city_id' 'item_price_level'\n",
      " 'item_sales_level' 'item_collected_level' 'item_pv_level' 'user_id'\n",
      " 'user_gender_id' 'user_age_level' 'user_occupation_id' 'user_star_level'\n",
      " 'context_id' 'context_timestamp' 'context_page_id'\n",
      " 'predict_category_property' 'shop_id' 'shop_review_num_level'\n",
      " 'shop_review_positive_rate' 'shop_star_level' 'shop_score_service'\n",
      " 'shop_score_delivery' 'shop_score_description' 'is_trade' 'date' 'weekday'\n",
      " 'day' 'hour' 'item_category_list' 'item_property_list'\n",
      " 'item_category_list_str' 'item_property_list_str' 'item_category0'\n",
      " 'item_category1' 'item_category2' 'item_prop_num'\n",
      " 'predict_category_property_str' 'predict_category' 'predict_cate_num'\n",
      " 'cate_intersect_num' 'predict_property' 'predict_prop_num'\n",
      " 'prop_intersect_num' 'prop_union_num' 'prop_jaccard' 'prop_predict_ratio'\n",
      " 'prop_item_ratio' 'predict_category_list' 'predict_category_set'\n",
      " 'real_item_category_list' 'predict_property_list'\n",
      " 'match_category_proportion' 'match_property_proportion'\n",
      " 'predict_category_number' 'predict_property_number' 'isFirstCategoryIn'\n",
      " 'isLastCategoryIn' 'category_number' 'property_number'\n",
      " 'real_first_category' 'real_last_category']\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(train_df_3.columns.values)\n",
    "print(len(train_df_3.columns.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['item_category_list' 'item_property_list' 'item_category_list_str'\n 'item_property_list_str' 'item_category0' 'item_category1'\n 'item_category2' 'item_prop_num' 'predict_category_property_str'\n 'predict_category' 'predict_cate_num' 'cate_intersect_num'\n 'predict_property' 'predict_prop_num' 'prop_intersect_num'\n 'prop_union_num' 'predict_category_list' 'predict_category_set'\n 'real_item_category_list' 'predict_property_list'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8411b7080545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m'prop_intersect_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prop_union_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_category_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_category_set'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             'real_item_category_list', 'predict_property_list']\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_df_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_df_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_df_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['item_category_list' 'item_property_list' 'item_category_list_str'\n 'item_property_list_str' 'item_category0' 'item_category1'\n 'item_category2' 'item_prop_num' 'predict_category_property_str'\n 'predict_category' 'predict_cate_num' 'cate_intersect_num'\n 'predict_property' 'predict_prop_num' 'prop_intersect_num'\n 'prop_union_num' 'predict_category_list' 'predict_category_set'\n 'real_item_category_list' 'predict_property_list'] not contained in axis"
     ]
    }
   ],
   "source": [
    "#删除某些不必要的列\n",
    "drop_fea = ['item_category_list', 'item_property_list', \n",
    "            'item_category_list_str', 'item_property_list_str', 'item_category0', \n",
    "            'item_category1', 'item_category2', 'item_prop_num',\n",
    "            'predict_category_property_str', 'predict_category', 'predict_cate_num',\n",
    "            'cate_intersect_num', 'predict_property', 'predict_prop_num',\n",
    "            'prop_intersect_num', 'prop_union_num', 'predict_category_list', 'predict_category_set',\n",
    "            'real_item_category_list', 'predict_property_list']\n",
    "train_df_1.drop(drop_fea, axis=1, inplace=True)\n",
    "train_df_2.drop(drop_fea, axis=1, inplace=True)\n",
    "train_df_3.drop(drop_fea, axis=1, inplace=True)\n",
    "test_df.drop(drop_fea, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instance_id' 'item_id' 'item_brand_id' 'item_city_id' 'item_price_level'\n",
      " 'item_sales_level' 'item_collected_level' 'item_pv_level' 'user_id'\n",
      " 'user_gender_id' 'user_age_level' 'user_occupation_id' 'user_star_level'\n",
      " 'context_id' 'context_timestamp' 'context_page_id'\n",
      " 'predict_category_property' 'shop_id' 'shop_review_num_level'\n",
      " 'shop_review_positive_rate' 'shop_star_level' 'shop_score_service'\n",
      " 'shop_score_delivery' 'shop_score_description' 'is_trade' 'date' 'weekday'\n",
      " 'day' 'hour' 'prop_jaccard' 'prop_predict_ratio' 'prop_item_ratio'\n",
      " 'match_category_proportion' 'match_property_proportion'\n",
      " 'predict_category_number' 'predict_property_number' 'isFirstCategoryIn'\n",
      " 'isLastCategoryIn' 'category_number' 'property_number'\n",
      " 'real_first_category' 'real_last_category']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(train_df_1.columns.values)\n",
    "print(len(train_df_3.columns.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origion_rate_mean :  0.013086259688778887\n",
      "origion_rate_var :  0.003236829406100776\n",
      "alpha :  0.03912815971526574\n",
      "beta :  2.9508904281641324\n",
      "origion_rate_mean :  0.013128726741275971\n",
      "origion_rate_var :  0.0035945894362571255\n",
      "alpha :  0.03419254764073707\n",
      "beta :  2.5702144382429464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origion_rate_mean :  0.009856723155881956\n",
      "origion_rate_var :  0.00357251595321706\n",
      "alpha :  0.017070339669942695\n",
      "beta :  1.7147769893032816\n",
      "~~~~~~~~~~~~~~历史数据统计完毕~~~~~~~~~~~~~~~~~~~\n",
      "                instance_id  all_item_brand_id_click_number\n",
      "0       8940337983247977520                        0.012114\n",
      "1       4858474345954405241                        0.004865\n",
      "2       5053378222821165852                        0.000173\n",
      "3       8890718968941765524                        0.043056\n",
      "4        579096116755484782                        0.008292\n",
      "5       1749254003519401220                        0.004611\n",
      "6       5019544380774408770                        0.000022\n",
      "7       2094542978124861709                        0.005235\n",
      "8       4337024072645272631                        0.000123\n",
      "9       3647726773891282224                        0.004232\n",
      "10      8776086985778794477                        0.001956\n",
      "11      5455246581601763171                        0.042974\n",
      "12       198903881603399236                        0.000022\n",
      "13      3662243202389412863                        0.007380\n",
      "14      1695026739462118892                        0.005169\n",
      "15      5185658664518610005                        0.002244\n",
      "16      3481465019974461511                        1.000000\n",
      "17      6063220447099082368                        0.002416\n",
      "18      7889779653405672856                        0.158821\n",
      "19      2174478865324284862                        0.007454\n",
      "20      1955608325390102624                        0.000197\n",
      "21      8267872048185016836                        1.000000\n",
      "22      3471131558600866193                        0.008210\n",
      "23       510734980697086570                        1.000000\n",
      "24      3180861892816138763                        0.037714\n",
      "25      4059895318278936068                        0.000616\n",
      "26      3437955331741137198                        0.001857\n",
      "27      6333149279512056590                        0.000879\n",
      "28      7536236823926654317                        1.000000\n",
      "29      1180881060925713160                        1.000000\n",
      "...                     ...                             ...\n",
      "621990  2333692835726861254                        0.002613\n",
      "621991  8888695580103859165                        0.001561\n",
      "621992  1016993317018046390                        0.004849\n",
      "621993  7206679418345922167                        0.000099\n",
      "621994  3389457948942495156                        0.000436\n",
      "621995  7309500246665018971                        0.001479\n",
      "621996  2647036417183066958                        0.003690\n",
      "621997  3237146718259501254                        0.004808\n",
      "621998  1845707117620079386                        0.042974\n",
      "621999  1544377112019620375                        0.004101\n",
      "622000  6764820507268211276                        1.000000\n",
      "622001   882275264156044514                        1.000000\n",
      "622002  8174248314546778694                        0.015237\n",
      "622003  7356863617988245705                        0.000205\n",
      "622004  1735007774091550243                        1.000000\n",
      "622005  3886867563878798806                        0.003846\n",
      "622006  8650968787284630579                        0.001898\n",
      "622007  4386392447095492618                        0.006304\n",
      "622008  3777706376225568310                        0.001849\n",
      "622009  8661300163874040606                        0.000173\n",
      "622010  6634898544374680327                        0.002802\n",
      "622011  9170354486251741714                        1.000000\n",
      "622012  6435609390985615493                        1.000000\n",
      "622013  5404920149812442259                        0.013774\n",
      "622014  4594337744137433627                        0.000022\n",
      "622015  3823768088782503064                        1.000000\n",
      "622016  3327463832134769821                        0.000156\n",
      "622017  4649639820203665967                        0.020620\n",
      "622018  3351056805568387989                        0.032997\n",
      "622019  1803197603855129684                        0.002655\n",
      "\n",
      "[622020 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def getBayesSmoothParam(origion_rate):\n",
    "    origion_rate_mean = origion_rate.mean()\n",
    "    origion_rate_var = origion_rate.var()\n",
    "    alpha = origion_rate_mean / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "    beta = (1 - origion_rate_mean) / origion_rate_var * (origion_rate_mean * (1 - origion_rate_mean) - origion_rate_var)\n",
    "    print('origion_rate_mean : ', origion_rate_mean)\n",
    "    print('origion_rate_var : ', origion_rate_var)\n",
    "    print('alpha : ', alpha)\n",
    "    print('beta : ', beta)\n",
    "    return alpha, beta\n",
    "\n",
    "# 缩放字段至0-1\n",
    "def scalerFea(df, cols):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[cols] = scaler.fit_transform(df[[cols]].values)\n",
    "    return df,scaler\n",
    "\n",
    "def getHistoryInfoByCol(train_df_normal, train_df_1, train_df_2, train_df_3, test_df, colName):\n",
    "    train_df_pivot_table_all = pd.pivot_table(train_df_normal[['instance_id', colName]], index=[colName], values=['instance_id'], aggfunc=len)\n",
    "    train_df_pivot_table_all.reset_index(inplace=True)\n",
    "    train_df_pivot_table_all.rename(columns={'instance_id' : 'all_' + colName + '_click_number'}, inplace=True)\n",
    "#     print(train_df_pivot_table_all.head(10))\n",
    "\n",
    "    train_df_pivot_table_buy = pd.pivot_table(train_df_normal[['instance_id', colName]][train_df_normal.is_trade == 1], index=[colName], values=['instance_id'], aggfunc=len)\n",
    "    train_df_pivot_table_buy.reset_index(inplace=True)\n",
    "    train_df_pivot_table_buy.rename(columns={'instance_id' : 'all_' + colName + '_buy_number'}, inplace=True)\n",
    "#     print(train_df_pivot_table_buy.head(10))\n",
    "\n",
    "    train_df_pivot_table = pd.merge(train_df_pivot_table_all, train_df_pivot_table_buy, on=[colName], how='left')\n",
    "    train_df_pivot_table['all_' + colName + '_buy_number'] = train_df_pivot_table['all_' + colName + '_buy_number'].fillna(0)\n",
    "    train_df_pivot_table['all_' + colName + '_buy_number'][train_df_pivot_table[colName] == -1] = train_df_pivot_table['all_' + colName + '_buy_number'][train_df_pivot_table[colName] == -1] / len(train_df_pivot_table)\n",
    "    train_df_pivot_table['all_' + colName + '_click_number'][train_df_pivot_table[colName] == -1] = train_df_pivot_table['all_' + colName + '_click_number'][train_df_pivot_table[colName] == -1] / len(train_df_pivot_table)\n",
    "#     print(train_df_pivot_table['all_' + colName + '_click_number'][train_df_pivot_table.item_brand_id == -1])\n",
    "    train_df_pivot_table['history_' + colName + '_rate'] = train_df_pivot_table['all_' + colName + '_buy_number'] / train_df_pivot_table['all_' + colName + '_click_number']\n",
    "    alpha, beta = getBayesSmoothParam(train_df_pivot_table['history_' + colName + '_rate'])\n",
    "    train_df_pivot_table['history_' + colName + '_smooth_rate'] = (train_df_pivot_table['all_' + colName + '_buy_number'] + alpha) / (train_df_pivot_table['all_' + colName + '_click_number'] + alpha + beta)\n",
    "\n",
    "    train_df_pivot_table, all_buy_number_scaler = scalerFea(train_df_pivot_table, 'all_' + colName + '_buy_number')\n",
    "    train_df_pivot_table, all_click_number_scaler = scalerFea(train_df_pivot_table, 'all_' + colName + '_click_number')\n",
    "#     print(train_df_pivot_table.head(10))\n",
    "#     print(train_df_pivot_table.columns.values)\n",
    "\n",
    "    train_df_1 = pd.merge(train_df_1, train_df_pivot_table, on=[colName], how='left')\n",
    "    train_df_2 = pd.merge(train_df_2, train_df_pivot_table, on=[colName], how='left')\n",
    "    train_df_3 = pd.merge(train_df_3, train_df_pivot_table, on=[colName], how='left')\n",
    "    train_df_3['all_' + colName + '_click_number'] = train_df_3['all_' + colName + '_click_number'].fillna(0)\n",
    "    train_df_3['all_' + colName + '_buy_number'] = train_df_3['all_' + colName + '_buy_number'].fillna(0)\n",
    "    train_df_3['history_' + colName + '_smooth_rate'] = train_df_3['history_' + colName + '_smooth_rate'].fillna((alpha / (alpha + beta)))\n",
    "\n",
    "    test_df = pd.merge(test_df, train_df_pivot_table, on=[colName], how='left')\n",
    "    test_df['all_' + colName + '_click_number'] = test_df['all_' + colName + '_click_number'].fillna(0)\n",
    "    test_df['all_' + colName + '_buy_number'] = test_df['all_' + colName + '_buy_number'].fillna(0)\n",
    "    test_df['history_' + colName + '_smooth_rate'] = test_df['history_' + colName + '_smooth_rate'].fillna((alpha / (alpha + beta)))\n",
    "\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_normal = pd.concat([train_df_1, train_df_2])\n",
    "train_df_1, train_df_2, train_df_3, test_df = getHistoryInfoByCol(train_df_normal, train_df_1, train_df_2, train_df_3, test_df, 'item_brand_id')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getHistoryInfoByCol(train_df_normal, train_df_1, train_df_2, train_df_3, test_df, 'shop_id')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getHistoryInfoByCol(train_df_normal, train_df_1, train_df_2, train_df_3, test_df, 'item_id')\n",
    "\n",
    "print('~~~~~~~~~~~~~~历史数据统计完毕~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print(train_df_1[['instance_id', 'all_item_brand_id_click_number']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "train_df_1['date'] = pd.to_datetime(train_df_1['date'])\n",
    "train_df_2['date'] = pd.to_datetime(train_df_2['date'])\n",
    "train_df_3['date'] = pd.to_datetime(train_df_3['date'])\n",
    "\n",
    "# 统计过去一个小时某用户点击某个相同商品的次数\n",
    "def getOneHourSameItemCount(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item'] = tempDf['last_user_item']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameItem_count'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'lastOneHour_sameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['lastOneHour_sameItem_count'] = train_df_1_copy['lastOneHour_sameItem_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'lastOneHour_sameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['lastOneHour_sameItem_count'] = train_df_2_copy['lastOneHour_sameItem_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'lastOneHour_sameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['lastOneHour_sameItem_count'] = train_df_3_copy['lastOneHour_sameItem_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'lastOneHour_sameItem_count']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['lastOneHour_sameItem_count'] = test_df_copy['lastOneHour_sameItem_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getOneHourSameItemCount(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种根类目商品的次数\n",
    "def getOneHourSameFirstCategoryCount(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_first_category_str'] = train_df_1_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_first_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_first_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_first_category_str'] = train_df_2_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_first_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_first_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_first_category_str'] = train_df_3_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_first_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_first_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_first_category_str'] = test_df_copy['real_first_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_first_category'] = test_df_copy['user_id_str'] + test_df_copy['real_first_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_first_category','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameFirstCategory_count'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_first_category', 'date', 'lastOneHour_sameFirstCategory_count']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_1['lastOneHour_sameFirstCategory_count'] = train_df_1_copy['lastOneHour_sameFirstCategory_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_first_category', 'date', 'lastOneHour_sameFirstCategory_count']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_2['lastOneHour_sameFirstCategory_count'] = train_df_2_copy['lastOneHour_sameFirstCategory_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_first_category', 'date', 'lastOneHour_sameFirstCategory_count']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_3['lastOneHour_sameFirstCategory_count'] = train_df_3_copy['lastOneHour_sameFirstCategory_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_first_category', 'date', 'lastOneHour_sameFirstCategory_count']], on = ['user_real_first_category', 'date'], how='left')\n",
    "    test_df['lastOneHour_sameFirstCategory_count'] = test_df_copy['lastOneHour_sameFirstCategory_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getOneHourSameFirstCategoryCount(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种叶子类目商品的次数\n",
    "def getOneHourSameLastCategoryCount(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_last_category_str'] = train_df_1_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_last_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_last_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_last_category_str'] = train_df_2_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_last_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_last_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_last_category_str'] = train_df_3_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_last_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_last_category_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['real_last_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_real_last_category','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameLastCategory_count'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_last_category', 'date', 'lastOneHour_sameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_1['lastOneHour_sameLastCategory_count'] = train_df_1_copy['lastOneHour_sameLastCategory_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_last_category', 'date', 'lastOneHour_sameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_2['lastOneHour_sameLastCategory_count'] = train_df_2_copy['lastOneHour_sameLastCategory_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_last_category', 'date', 'lastOneHour_sameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_3['lastOneHour_sameLastCategory_count'] = train_df_3_copy['lastOneHour_sameLastCategory_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'lastOneHour_sameLastCategory_count']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    test_df['lastOneHour_sameLastCategory_count'] = test_df_copy['lastOneHour_sameLastCategory_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getOneHourSameLastCategoryCount(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种品牌商品的次数\n",
    "def getOneHourSameBrandCount(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['brand_id_str'] = train_df_1_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_brand_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['brand_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['brand_id_str'] = train_df_2_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_brand_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['brand_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['brand_id_str'] = train_df_3_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_brand_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['brand_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['brand_id_str'] = test_df_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_brand_id'] = test_df_copy['user_id_str'] + test_df_copy['brand_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_brand_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_brand_id'] = tempDf['user_brand_id'].shift(1)\n",
    "    tempDf['last_user_brand_id'] = tempDf['last_user_brand_id']==tempDf['user_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_brand_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_brand_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameBrand_count'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_brand_id', 'date', 'lastOneHour_sameBrand_count']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_1['lastOneHour_sameBrand_count'] = train_df_1_copy['lastOneHour_sameBrand_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_brand_id', 'date', 'lastOneHour_sameBrand_count']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_2['lastOneHour_sameBrand_count'] = train_df_2_copy['lastOneHour_sameBrand_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_brand_id', 'date', 'lastOneHour_sameBrand_count']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_3['lastOneHour_sameBrand_count'] = train_df_3_copy['lastOneHour_sameBrand_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_brand_id', 'date', 'lastOneHour_sameBrand_count']], on = ['user_brand_id', 'date'], how='left')\n",
    "    test_df['lastOneHour_sameBrand_count'] = test_df_copy['lastOneHour_sameBrand_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getOneHourSameBrandCount(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计过去一个小时某用户点击同种店铺商品的次数\n",
    "def getOneHourSameShopCount(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_shop_id_str'] = train_df_1_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_shop_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_shop_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_shop_id_str'] = train_df_2_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_shop_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_shop_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_shop_id_str'] = train_df_3_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_shop_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_shop_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_shop_id_str'] = test_df_copy['shop_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_shop_id'] = test_df_copy['user_id_str'] + test_df_copy['item_shop_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_shop_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['user_item_shop_id'].shift(1)\n",
    "    tempDf['last_user_item_shop_id'] = tempDf['last_user_item_shop_id']==tempDf['user_item_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_shop_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_shop_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            hourShowList.append(np.sum(list(hourShowTemp.values())))\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(0)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['lastOneHour_sameShop_count'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_shop_id', 'date', 'lastOneHour_sameShop_count']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_1['lastOneHour_sameShop_count'] = train_df_1_copy['lastOneHour_sameShop_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_shop_id', 'date', 'lastOneHour_sameShop_count']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_2['lastOneHour_sameShop_count'] = train_df_2_copy['lastOneHour_sameShop_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_shop_id', 'date', 'lastOneHour_sameShop_count']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_3['lastOneHour_sameShop_count'] = train_df_3_copy['lastOneHour_sameShop_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_shop_id', 'date', 'lastOneHour_sameShop_count']], on = ['user_item_shop_id', 'date'], how='left')\n",
    "    test_df['lastOneHour_sameShop_count'] = test_df_copy['lastOneHour_sameShop_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getOneHourSameShopCount(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 获取是否是该用户在这1个小时内第一次点击这个商品的特征\n",
    "def getIsOneHourFirstClickItem(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id','date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['date'] - tempDf['last_show_time']\n",
    "    tempDf['ui_last_show_timedelta'] = tempDf['ui_last_show_timedelta'].dt.seconds\n",
    "    tempDf['ui_last_show_timedelta'].fillna(999999, inplace=True)\n",
    "    hourShowList = []\n",
    "    hourShowTemp = {}\n",
    "    for same, dt, show in tempDf[['last_user_item_id','date','show']].values:\n",
    "        if same:\n",
    "            [hourShowTemp.pop(k) for k in list(hourShowTemp) if k<dt-timedelta(hours=1)]\n",
    "            if len(hourShowTemp) > 0:\n",
    "                hourShowList.append(0)\n",
    "            else:\n",
    "                hourShowList.append(1)\n",
    "            hourShowTemp[dt] = show\n",
    "        else:\n",
    "            hourShowList.append(1)\n",
    "            hourShowTemp = {dt:show}\n",
    "    tempDf['isLastOneHour_firstClickItem'] = hourShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'isLastOneHour_firstClickItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['isLastOneHour_firstClickItem'] = train_df_1_copy['isLastOneHour_firstClickItem']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'isLastOneHour_firstClickItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['isLastOneHour_firstClickItem'] = train_df_2_copy['isLastOneHour_firstClickItem']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'isLastOneHour_firstClickItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['isLastOneHour_firstClickItem'] = train_df_3_copy['isLastOneHour_firstClickItem']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'isLastOneHour_firstClickItem']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['isLastOneHour_firstClickItem'] = test_df_copy['isLastOneHour_firstClickItem']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getIsOneHourFirstClickItem(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同商品的时间\n",
    "def getUserItemLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    temp_df['user_id_str'] = temp_df['user_id'].map(lambda x: str(x))\n",
    "    temp_df['item_id_str'] = temp_df['item_id'].map(lambda x: str(x))\n",
    "    temp_df['user_item_id'] = temp_df['user_id_str'] + temp_df['item_id_str']\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_item_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userItem_lastClickDeltaTime'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['userItem_lastClickDeltaTime'] = train_df_1_copy['userItem_lastClickDeltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['userItem_lastClickDeltaTime'] = train_df_2_copy['userItem_lastClickDeltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['userItem_lastClickDeltaTime'] = train_df_3_copy['userItem_lastClickDeltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'userItem_lastClickDeltaTime']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['userItem_lastClickDeltaTime'] = test_df_copy['userItem_lastClickDeltaTime']\n",
    "    print(len(train_df_1))\n",
    "\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserItemLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同品牌商品的时间\n",
    "def getUserBrandLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_brand_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['brand_id_str'] = train_df_1_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_brand_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['brand_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['brand_id_str'] = train_df_2_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_brand_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['brand_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['brand_id_str'] = train_df_3_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_brand_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['brand_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['brand_id_str'] = test_df_copy['item_brand_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_brand_id'] = test_df_copy['user_id_str'] + test_df_copy['brand_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_brand_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['user_brand_id'].shift(1)\n",
    "    tempDf['last_user_item_brand_id'] = tempDf['last_user_item_brand_id']==tempDf['user_brand_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_brand_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_item_brand_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userBrand_lastClickDeltaTime'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_brand_id', 'date', 'userBrand_lastClickDeltaTime']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_1['userBrand_lastClickDeltaTime'] = train_df_1_copy['userBrand_lastClickDeltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_brand_id', 'date', 'userBrand_lastClickDeltaTime']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_2['userBrand_lastClickDeltaTime'] = train_df_2_copy['userBrand_lastClickDeltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_brand_id', 'date', 'userBrand_lastClickDeltaTime']], how='left', on=['user_brand_id', 'date'])\n",
    "    train_df_3['userBrand_lastClickDeltaTime'] = train_df_3_copy['userBrand_lastClickDeltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_brand_id', 'date', 'userBrand_lastClickDeltaTime']], on = ['user_brand_id', 'date'], how='left')\n",
    "    test_df['userBrand_lastClickDeltaTime'] = test_df_copy['userBrand_lastClickDeltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserBrandLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同店铺的时间\n",
    "def getUserShopLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'shop_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_shop_id_str'] = train_df_1_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_shop_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_shop_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_shop_id_str'] = train_df_2_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_shop_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_shop_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_shop_id_str'] = train_df_3_copy['shop_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_shop_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_shop_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_shop_id_str'] = test_df_copy['shop_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_shop_id'] = test_df_copy['user_id_str'] + test_df_copy['item_shop_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_shop_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_shop_id'] = tempDf['user_item_shop_id'].shift(1)\n",
    "    tempDf['last_user_shop_id'] = tempDf['last_user_shop_id']==tempDf['user_item_shop_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_shop_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_shop_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userShop_lastClickDeltaTime'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_shop_id', 'date', 'userShop_lastClickDeltaTime']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_1['userShop_lastClickDeltaTime'] = train_df_1_copy['userShop_lastClickDeltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_shop_id', 'date', 'userShop_lastClickDeltaTime']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_2['userShop_lastClickDeltaTime'] = train_df_2_copy['userShop_lastClickDeltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_shop_id', 'date', 'userShop_lastClickDeltaTime']], how='left', on=['user_item_shop_id', 'date'])\n",
    "    train_df_3['userShop_lastClickDeltaTime'] = train_df_3_copy['userShop_lastClickDeltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_shop_id', 'date', 'userShop_lastClickDeltaTime']], on = ['user_item_shop_id', 'date'], how='left')\n",
    "    test_df['userShop_lastClickDeltaTime'] = test_df_copy['userShop_lastClickDeltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserShopLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同根类目的时间\n",
    "def getUserFirstCategoryLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_first_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_first_category_str'] = train_df_1_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_first_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_first_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_first_category_str'] = train_df_2_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_first_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_first_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_first_category_str'] = train_df_3_copy['real_first_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_first_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_first_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_first_category_str'] = test_df_copy['real_first_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_first_category'] = test_df_copy['user_id_str'] + test_df_copy['real_first_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_first_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['user_real_first_category'].shift(1)\n",
    "    tempDf['last_user_real_first_category'] = tempDf['last_user_real_first_category']==tempDf['user_real_first_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_first_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_real_first_category', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userFirstCategory_lastClickDeltaTime'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_1['userFirstCategory_lastClickDeltaTime'] = train_df_1_copy['userFirstCategory_lastClickDeltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_2['userFirstCategory_lastClickDeltaTime'] = train_df_2_copy['userFirstCategory_lastClickDeltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']], how='left', on=['user_real_first_category', 'date'])\n",
    "    train_df_3['userFirstCategory_lastClickDeltaTime'] = train_df_3_copy['userFirstCategory_lastClickDeltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_first_category', 'date', 'userFirstCategory_lastClickDeltaTime']], on = ['user_real_first_category', 'date'], how='left')\n",
    "    test_df['userFirstCategory_lastClickDeltaTime'] = test_df_copy['userFirstCategory_lastClickDeltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserFirstCategoryLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计某用户距离上次点击相同叶子类目的时间\n",
    "def getUserLastCategoryLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_last_category_str'] = train_df_1_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_last_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_last_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_last_category_str'] = train_df_2_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_last_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_last_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_last_category_str'] = train_df_3_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_last_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_last_category_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['real_last_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_real_last_category', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['userLastCategory_lastClickDeltaTime'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_1['userLastCategory_lastClickDeltaTime'] = train_df_1_copy['userLastCategory_lastClickDeltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_2['userLastCategory_lastClickDeltaTime'] = train_df_2_copy['userLastCategory_lastClickDeltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_3['userLastCategory_lastClickDeltaTime'] = train_df_3_copy['userLastCategory_lastClickDeltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'userLastCategory_lastClickDeltaTime']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    test_df['userLastCategory_lastClickDeltaTime'] = test_df_copy['userLastCategory_lastClickDeltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserLastCategoryLastClickDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     day  hour  all_click_number  all_buy_number      rate\n",
      "144    7     0             17744             894  0.050383\n",
      "145    7     1              9644             421  0.043654\n",
      "146    7     2              4373             202  0.046193\n",
      "147    7     3              2550              98  0.038431\n",
      "148    7     4              1911              94  0.049189\n",
      "149    7     5              2396             108  0.045075\n",
      "150    7     6              5552             227  0.040886\n",
      "151    7     7             10666             466  0.043690\n",
      "152    7     8             12504             575  0.045985\n",
      "153    7     9             13383             667  0.049839\n",
      "154    7    10             14359             658  0.045825\n",
      "155    7    11             12636             533  0.042181\n",
      "155    0.024274\n",
      "Name: rate, dtype: float64\n",
      "<bound method NDFrame.head of     hour      rate  special_rate\n",
      "0     12  0.016176      0.040450\n",
      "1     13  0.015343      0.039617\n",
      "2     14  0.012466      0.036740\n",
      "3     15  0.013358      0.037632\n",
      "4     16  0.012251      0.036525\n",
      "5     17  0.012282      0.036556\n",
      "6     18  0.013743      0.038017\n",
      "7     19  0.012786      0.037060\n",
      "8     20  0.012447      0.036721\n",
      "9     21  0.009947      0.034221\n",
      "10    22  0.008485      0.032759\n",
      "11    23  0.006648      0.030922>\n",
      "0.03643503257735959\n",
      "   day  hour  hour_rate\n",
      "0    7     0   0.050383\n",
      "1    7    10   0.045825\n",
      "2    7     0   0.050383\n",
      "3    7     8   0.045985\n",
      "4    7    10   0.045825\n",
      "5    7     9   0.049839\n",
      "6    7    11   0.042181\n",
      "7    7     7   0.043690\n",
      "8    7     2   0.046193\n",
      "9    7    11   0.042181\n",
      "   day  hour  hour_rate\n",
      "0    7    13   0.039617\n",
      "1    7    14   0.036740\n",
      "2    7    21   0.034221\n",
      "3    7    17   0.036556\n",
      "4    7    15   0.037632\n",
      "5    7    16   0.036525\n",
      "6    7    21   0.034221\n",
      "7    7    16   0.036525\n",
      "8    7    22   0.032759\n",
      "9    7    17   0.036556\n"
     ]
    }
   ],
   "source": [
    "#定义添加每个小时转化率特征，test数据集采用预测方法填充\n",
    "def getHourTradeRate(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    train_df_all = pd.concat([train_df_1, train_df_2, train_df_3])\n",
    "    train_df_hour_pivot_table_all = pd.pivot_table(train_df_all[['day', 'hour', 'instance_id']], index=['day', 'hour'], values=['instance_id'], aggfunc=len)\n",
    "    train_df_hour_pivot_table_all.reset_index(inplace=True)\n",
    "    train_df_hour_pivot_table_all.rename(columns={'instance_id' : 'all_click_number'}, inplace=True)\n",
    "\n",
    "    train_df_hour_pivot_table_buy = pd.pivot_table(train_df_all[['day', 'hour', 'instance_id']][train_df_all.is_trade == 1], index=['day', 'hour'], values=['instance_id'], aggfunc=len)\n",
    "    train_df_hour_pivot_table_buy.reset_index(inplace=True)\n",
    "    train_df_hour_pivot_table_buy.rename(columns={'instance_id' : 'all_buy_number'}, inplace=True)\n",
    "\n",
    "    train_df_hour_pivot_table_all = pd.merge(train_df_hour_pivot_table_all, train_df_hour_pivot_table_buy, on=['day', 'hour'], how='left')\n",
    "    train_df_hour_pivot_table_all['rate'] = train_df_hour_pivot_table_all['all_buy_number'] / train_df_hour_pivot_table_all['all_click_number']\n",
    "\n",
    "    print(train_df_hour_pivot_table_all[train_df_hour_pivot_table_all.day == 7])\n",
    "\n",
    "    hour_11_normal_mean = train_df_hour_pivot_table_all['rate'][train_df_hour_pivot_table_all.hour == 11].mean()\n",
    "    hour_11_diff = train_df_hour_pivot_table_all['rate'][(train_df_hour_pivot_table_all.hour == 11) & (train_df_hour_pivot_table_all.day == 7)] - hour_11_normal_mean\n",
    "    print(hour_11_diff)\n",
    "\n",
    "    hour_nextHalf_normal_mean = pd.pivot_table(train_df_hour_pivot_table_all[['hour', 'rate']][(train_df_hour_pivot_table_all.hour > 11) & ((train_df_hour_pivot_table_all.day == 31) | (train_df_hour_pivot_table_all.day <= 4))], index=['hour'], values=['rate'], aggfunc=mean)\n",
    "    hour_nextHalf_normal_mean.reset_index(inplace=True)\n",
    "    hour_nextHalf_normal_mean['special_rate'] = hour_nextHalf_normal_mean['rate'] + hour_11_diff.values\n",
    "    print(hour_nextHalf_normal_mean.head)\n",
    "    print(hour_nextHalf_normal_mean['special_rate'].mean())\n",
    "\n",
    "    train_df_hour_pivot_table_all.rename(columns={'rate' : 'hour_rate'}, inplace=True)\n",
    "    hour_nextHalf_normal_mean.rename(columns={'special_rate' : 'hour_rate'}, inplace=True)\n",
    "\n",
    "    train_df_1 = pd.merge(train_df_1, train_df_hour_pivot_table_all[['day', 'hour', 'hour_rate']], on=['day', 'hour'], how='left')\n",
    "    train_df_2 = pd.merge(train_df_2, train_df_hour_pivot_table_all[['day', 'hour', 'hour_rate']], on=['day', 'hour'], how='left')\n",
    "    train_df_3 = pd.merge(train_df_3, train_df_hour_pivot_table_all[['day', 'hour', 'hour_rate']], on=['day', 'hour'], how='left')\n",
    "    test_df = pd.merge(test_df, hour_nextHalf_normal_mean[['hour', 'hour_rate']], on=['hour'], how='left')\n",
    "    print(train_df_3[['day', 'hour', 'hour_rate']].head(10))\n",
    "    print(test_df[['day', 'hour', 'hour_rate']].head(10))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getHourTradeRate(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n",
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 定义获取某种店铺，品牌，城市对应商品种类，用户数的函数\n",
    "def getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, colName1, colName2, newColName):\n",
    "\n",
    "    df = pd.concat([train_df_1[[colName1, colName2, 'instance_id']], train_df_2[[colName1, colName2, 'instance_id']], train_df_3[[colName1, colName2, 'instance_id']], test_df[[colName1, colName2, 'instance_id']]])\n",
    "    temp_df = df[[colName1, colName2, 'instance_id']]\n",
    "    tempDf = temp_df.sort_values(by=colName1, ascending=False)\n",
    "    tempDf['last_' + colName1] = tempDf[colName1].shift(1)\n",
    "    tempDf['same'] = tempDf['last_' + colName1]==tempDf[colName1]\n",
    "#     print(tempDf.head(10))\n",
    "    colName1List = []\n",
    "    countList = []\n",
    "    colName2Set = set()\n",
    "    for same, col2, last_col1 in tempDf[['same', colName2, 'last_' + colName1]].values:\n",
    "        if same:\n",
    "            colName2Set.add(col2)\n",
    "        else:\n",
    "            colName1List.append(last_col1)\n",
    "            countList.append(len(colName2Set))\n",
    "            colName2Set = {col2}\n",
    "    #处理最后一行数据\n",
    "    last_col1 = tempDf.iloc[-1][colName1]\n",
    "    last_count = len(colName2Set)\n",
    "    colName1List.append(last_col1)\n",
    "    countList.append(last_count)\n",
    "\n",
    "    #将结果组合到tempDf中\n",
    "    result_df = {colName1: colName1List, newColName: countList}\n",
    "    result_df = DataFrame(result_df)\n",
    "    result_df = result_df[1:]\n",
    "\n",
    "    tempDf = tempDf.drop_duplicates([colName1])\n",
    "    tempDf[newColName] = result_df[newColName].values\n",
    "\n",
    "    print(len(train_df_1))\n",
    "    train_df_1 = pd.merge(train_df_1, tempDf[[colName1, newColName]], on=[colName1], how='left')\n",
    "    print(len(train_df_1))\n",
    "    train_df_2 = pd.merge(train_df_2, tempDf[[colName1, newColName]], on=[colName1], how='left')\n",
    "    train_df_3 = pd.merge(train_df_3, tempDf[[colName1, newColName]], on=[colName1], how='left')\n",
    "    test_df = pd.merge(test_df, tempDf[[colName1, newColName]], on=[colName1], how='left')\n",
    "\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'shop_id', 'item_id', 'shop_item_classNumber')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'item_brand_id', 'item_id', 'brand_item_classNumber')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'item_city_id', 'item_id', 'city_item_classNumber')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'shop_id', 'user_id', 'shop_user_classNumber')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'item_brand_id', 'user_id', 'brand_user_classNumber')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getCorrespondNumber(train_df_1, train_df_2, train_df_3, test_df, 'item_city_id', 'user_id', 'city_user_classNumber')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义获取用户浏览过商品的平均值，众数，中位数，最大值，最小值\n",
    "def getUserItemStatFuture(train_df_1, train_df_2, train_df_3, test_df, colName):\n",
    "    df = pd.concat([train_df_1, train_df_2, train_df_3, test_df])\n",
    "    df_user_item_pivot_table = pd.pivot_table(df, index=['user_id'], values=[colName], aggfunc=[np.mean, np.max, np.min, np.median])\n",
    "    df_user_item_pivot_table.reset_index(inplace=True)\n",
    "    df_user_item_pivot_table.columns = ['user_id', colName + '_mean', colName + '_max', colName + '_min', colName + '_median']\n",
    "\n",
    "    df_mode_pivot_table = pd.pivot_table(df[['user_id', colName, 'instance_id']], index=['user_id', colName], values=['instance_id'], aggfunc=len)\n",
    "    df_mode_pivot_table.reset_index(inplace=True)\n",
    "    df_mode_pivot_table = df_mode_pivot_table.sort_values(by=['user_id', 'instance_id'], ascending=False)\n",
    "    df_mode_pivot_table = df_mode_pivot_table.drop_duplicates(['user_id'])\n",
    "    df_mode_pivot_table.rename(columns={colName:colName + '_mode'}, inplace=True)\n",
    "\n",
    "    train_df_1 = pd.merge(train_df_1, df_user_item_pivot_table, on=['user_id'], how='left')\n",
    "    train_df_1 = pd.merge(train_df_1, df_mode_pivot_table[['user_id', colName + '_mode']], on=['user_id'], how='left')\n",
    "    train_df_2 = pd.merge(train_df_2, df_user_item_pivot_table, on=['user_id'], how='left')\n",
    "    train_df_2 = pd.merge(train_df_2, df_mode_pivot_table[['user_id', colName + '_mode']], on=['user_id'], how='left')\n",
    "    train_df_3 = pd.merge(train_df_3, df_user_item_pivot_table, on=['user_id'], how='left')\n",
    "    train_df_3 = pd.merge(train_df_3, df_mode_pivot_table[['user_id', colName + '_mode']], on=['user_id'], how='left')\n",
    "    test_df = pd.merge(test_df, df_user_item_pivot_table, on=['user_id'], how='left')\n",
    "    test_df = pd.merge(test_df, df_mode_pivot_table[['user_id', colName + '_mode']], on=['user_id'], how='left')\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserItemStatFuture(train_df_1, train_df_2, train_df_3, test_df, 'item_price_level')\n",
    "train_df_1, train_df_2, train_df_3, test_df = getUserItemStatFuture(train_df_1, train_df_2, train_df_3, test_df, 'item_sales_level')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         last_user_item_id                date  is_later_clickSameItem\n",
      "1157354              False 2018-09-05 07:17:07                       0\n",
      "1157353              False 2018-09-04 08:32:28                       0\n",
      "1157352              False 2018-09-06 08:58:40                       0\n",
      "1157351              False 2018-08-31 22:50:39                       0\n",
      "1157350              False 2018-09-01 11:02:01                       0\n",
      "1157349              False 2018-09-05 22:15:12                       0\n",
      "1157348              False 2018-09-07 08:57:01                       0\n",
      "1157347              False 2018-09-03 09:51:51                       0\n",
      "1157346              False 2018-09-07 12:03:01                       0\n",
      "1157345              False 2018-09-05 15:44:28                       0\n",
      "1157344              False 2018-09-01 08:51:15                       0\n",
      "1157343              False 2018-09-01 20:47:46                       0\n",
      "1157342              False 2018-09-03 15:17:26                       0\n",
      "1157341              False 2018-09-03 15:20:38                       0\n",
      "1157340              False 2018-09-06 22:08:20                       0\n",
      "1157339              False 2018-09-02 17:08:44                       0\n",
      "1157338              False 2018-08-31 01:53:59                       0\n",
      "1157337              False 2018-09-07 14:02:44                       0\n",
      "1157336              False 2018-09-02 20:09:56                       0\n",
      "1157335              False 2018-09-05 09:08:48                       0\n",
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面是否有点击相同商品\n",
    "def getIsClickSameItemLater(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_item_id', 'date'], ascending=False)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    for same, dt in tempDf[['last_user_item_id','date']].values:\n",
    "        if same:\n",
    "            historyShowList.append(1)\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "    tempDf['is_later_clickSameItem'] = historyShowList\n",
    "    print(tempDf[['last_user_item_id', 'date', 'is_later_clickSameItem']].head(20))\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['is_later_clickSameItem'] = train_df_1_copy['is_later_clickSameItem']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['is_later_clickSameItem'] = train_df_2_copy['is_later_clickSameItem']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['is_later_clickSameItem'] = train_df_3_copy['is_later_clickSameItem']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'is_later_clickSameItem']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['is_later_clickSameItem'] = test_df_copy['is_later_clickSameItem']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getIsClickSameItemLater(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面是否有点击相同叶子类目商品\n",
    "def getIsClickSameLastCategoryLater(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_last_category_str'] = train_df_1_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_last_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_last_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_last_category_str'] = train_df_2_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_last_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_last_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_last_category_str'] = train_df_3_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_last_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_last_category_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['real_last_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_real_last_category', 'date'], ascending=False)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    for same, dt in tempDf[['last_user_real_last_category','date']].values:\n",
    "        if same:\n",
    "            historyShowList.append(1)\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "    tempDf['is_later_clickSameLastCategory'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_1['is_later_clickSameLastCategory'] = train_df_1_copy['is_later_clickSameLastCategory']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_2['is_later_clickSameLastCategory'] = train_df_2_copy['is_later_clickSameLastCategory']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_3['is_later_clickSameLastCategory'] = train_df_3_copy['is_later_clickSameLastCategory']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'is_later_clickSameLastCategory']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    test_df['is_later_clickSameLastCategory'] = test_df_copy['is_later_clickSameLastCategory']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getIsClickSameLastCategoryLater(train_df_1, train_df_2, train_df_3, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同商品的个数\n",
    "def getClickSameItemLaterNumber(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_item_id', 'date'], ascending=False)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_item_id','date']].values:\n",
    "        if same:\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(len(historyShowTemp))\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['later_clickSameItem_count'] = historyShowList\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['later_clickSameItem_count'] = train_df_1_copy['later_clickSameItem_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['later_clickSameItem_count'] = train_df_2_copy['later_clickSameItem_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['later_clickSameItem_count'] = train_df_3_copy['later_clickSameItem_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'later_clickSameItem_count']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['later_clickSameItem_count'] = test_df_copy['later_clickSameItem_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getClickSameItemLaterNumber(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同叶子类目商品的个数\n",
    "def getClickSameLastCategoryLaterNumber(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_last_category_str'] = train_df_1_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_last_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_last_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_last_category_str'] = train_df_2_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_last_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_last_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_last_category_str'] = train_df_3_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_last_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_last_category_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['real_last_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_real_last_category', 'date'], ascending=False)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    historyShowTemp = {}\n",
    "    for same, dt in tempDf[['last_user_real_last_category','date']].values:\n",
    "        if same:\n",
    "            if len(historyShowTemp) > 0:\n",
    "                historyShowList.append(len(historyShowTemp))\n",
    "                historyShowTemp[dt] = same\n",
    "            else:\n",
    "                historyShowList.append(0)\n",
    "                historyShowTemp[dt] = same\n",
    "        else:\n",
    "            historyShowList.append(0)\n",
    "            historyShowTemp = {dt:same}\n",
    "    tempDf['later_clickSameLastCategory_count'] = historyShowList\n",
    "\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_1['later_clickSameLastCategory_count'] = train_df_1_copy['later_clickSameLastCategory_count']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_2['later_clickSameLastCategory_count'] = train_df_2_copy['later_clickSameLastCategory_count']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_3['later_clickSameLastCategory_count'] = train_df_3_copy['later_clickSameLastCategory_count']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_count']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    test_df['later_clickSameLastCategory_count'] = test_df_copy['later_clickSameLastCategory_count']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getClickSameLastCategoryLaterNumber(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同商品的时间间隔\n",
    "def getClickSameItemLaterDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'item_id', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['item_id_str'] = train_df_1_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_item_id'] = train_df_1_copy['user_id_str'] + train_df_1_copy['item_id_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['item_id_str'] = train_df_2_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_item_id'] = train_df_2_copy['user_id_str'] + train_df_2_copy['item_id_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['item_id_str'] = train_df_3_copy['item_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_item_id'] = train_df_3_copy['user_id_str'] + train_df_3_copy['item_id_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['item_id_str'] = test_df_copy['item_id'].map(lambda x: str(x))\n",
    "    test_df_copy['user_item_id'] = test_df_copy['user_id_str'] + test_df_copy['item_id_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_item_id', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_item_id', 'date'], ascending=False)\n",
    "    tempDf['last_user_item_id'] = tempDf['user_item_id'].shift(1)\n",
    "    tempDf['last_user_item_id'] = tempDf['last_user_item_id']==tempDf['user_item_id']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_item_id, 'last_show_time'] = np.nan\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_item_id', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['later_clickSameItem_deltaTime'] = historyShowList\n",
    "\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_deltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_1['later_clickSameItem_deltaTime'] = train_df_1_copy['later_clickSameItem_deltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_deltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_2['later_clickSameItem_deltaTime'] = train_df_2_copy['later_clickSameItem_deltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_item_id', 'date', 'later_clickSameItem_deltaTime']], how='left', on=['user_item_id', 'date'])\n",
    "    train_df_3['later_clickSameItem_deltaTime'] = train_df_3_copy['later_clickSameItem_deltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_item_id', 'date', 'later_clickSameItem_deltaTime']], on = ['user_item_id', 'date'], how='left')\n",
    "    test_df['later_clickSameItem_deltaTime'] = test_df_copy['later_clickSameItem_deltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getClickSameItemLaterDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622020\n"
     ]
    }
   ],
   "source": [
    "# 统计历史记录中某用户后面点击相同叶子类目商品的时间间隔\n",
    "def getClickSameLastCategoryLaterDeltaTime(train_df_1, train_df_2, train_df_3, test_df):\n",
    "    print(len(train_df_1))\n",
    "    train_df_1_copy = train_df_1[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_2_copy = train_df_2[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_3_copy = train_df_3[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    test_df_copy = test_df[['user_id', 'real_last_category', 'date', 'instance_id']]\n",
    "    train_df_1_copy['user_id_str'] = train_df_1_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_1_copy['real_last_category_str'] = train_df_1_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_1_copy['user_real_last_category'] = train_df_1_copy['user_id_str'] + train_df_1_copy['real_last_category_str']\n",
    "    train_df_2_copy['user_id_str'] = train_df_2_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_2_copy['real_last_category_str'] = train_df_2_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_2_copy['user_real_last_category'] = train_df_2_copy['user_id_str'] + train_df_2_copy['real_last_category_str']\n",
    "    train_df_3_copy['user_id_str'] = train_df_3_copy['user_id'].map(lambda x: str(x))\n",
    "    train_df_3_copy['real_last_category_str'] = train_df_3_copy['real_last_category'].map(lambda x: str(x))\n",
    "    train_df_3_copy['user_real_last_category'] = train_df_3_copy['user_id_str'] + train_df_3_copy['real_last_category_str']\n",
    "    test_df_copy['user_id_str'] = test_df_copy['user_id'].map(lambda x: str(x))\n",
    "    test_df_copy['real_last_category_str'] = test_df_copy['real_last_category'].map(lambda x: str(x))\n",
    "    test_df_copy['user_real_last_category'] = test_df_copy['user_id_str'] + test_df_copy['real_last_category_str']\n",
    "    temp_df = pd.concat([train_df_1_copy, train_df_2_copy, train_df_3_copy, test_df_copy])\n",
    "\n",
    "    tempDf = pd.pivot_table(temp_df, index=['user_real_last_category', 'date'], values=['instance_id'], aggfunc=len)\n",
    "    tempDf.columns = ['show']\n",
    "    tempDf.reset_index(inplace=True)\n",
    "    tempDf = tempDf.sort_values(by=['user_real_last_category', 'date'], ascending=False)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['user_real_last_category'].shift(1)\n",
    "    tempDf['last_user_real_last_category'] = tempDf['last_user_real_last_category']==tempDf['user_real_last_category']\n",
    "    tempDf['last_show_time'] = tempDf['date'].shift(1)\n",
    "    tempDf.loc[~tempDf.last_user_real_last_category, 'last_show_time'] = np.nan\n",
    "\n",
    "    historyShowList = []\n",
    "    deltaTime = 99999999\n",
    "    for same, dt, lastShowTime in tempDf[['last_user_real_last_category', 'date', 'last_show_time']].values:\n",
    "        if same:\n",
    "            deltaTime = (dt - lastShowTime) / np.timedelta64(1, 's')\n",
    "            historyShowList.append(deltaTime)\n",
    "            deltaTime = 99999999\n",
    "        else:\n",
    "            historyShowList.append(deltaTime)\n",
    "    tempDf['later_clickSameLastCategory_deltaTime'] = historyShowList\n",
    "\n",
    "    train_df_1_copy = train_df_1_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_deltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_1['later_clickSameLastCategory_deltaTime'] = train_df_1_copy['later_clickSameLastCategory_deltaTime']\n",
    "    train_df_2_copy = train_df_2_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_deltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_2['later_clickSameLastCategory_deltaTime'] = train_df_2_copy['later_clickSameLastCategory_deltaTime']\n",
    "    train_df_3_copy = train_df_3_copy.merge(tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_deltaTime']], how='left', on=['user_real_last_category', 'date'])\n",
    "    train_df_3['later_clickSameLastCategory_deltaTime'] = train_df_3_copy['later_clickSameLastCategory_deltaTime']\n",
    "    test_df_copy = pd.merge(test_df_copy, tempDf[['user_real_last_category', 'date', 'later_clickSameLastCategory_deltaTime']], on = ['user_real_last_category', 'date'], how='left')\n",
    "    test_df['later_clickSameLastCategory_deltaTime'] = test_df_copy['later_clickSameLastCategory_deltaTime']\n",
    "    print(len(train_df_1))\n",
    "    return train_df_1, train_df_2, train_df_3, test_df\n",
    "\n",
    "train_df_1, train_df_2, train_df_3, test_df = getClickSameLastCategoryLaterDeltaTime(train_df_1, train_df_2, train_df_3, test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origion_rate_mean :  0.014030989941101248\n",
      "origion_rate_var :  0.012976118619169384\n",
      "alpha :  0.000927752497457697\n",
      "beta :  0.06519391827218728\n",
      "origion_rate_mean :  0.015054532085585381\n",
      "origion_rate_var :  0.00492799638531314\n",
      "alpha :  0.030243186444117682\n",
      "beta :  1.9786659096463108\n",
      "origion_rate_mean :  0.012097971377722512\n",
      "origion_rate_var :  0.005571045964682445\n",
      "alpha :  0.013855905552248306\n",
      "beta :  1.1314522721280935\n",
      "origion_rate_mean :  0.015381346774083779\n",
      "origion_rate_var :  0.005934931270559113\n",
      "alpha :  0.02386878255241443\n",
      "beta :  1.5279317784121973\n",
      "origion_rate_mean :  0.02435880595088018\n",
      "origion_rate_var :  0.0031205021759647005\n",
      "alpha :  0.1611555960360722\n",
      "beta :  6.454751454623322\n",
      "origion_rate_mean :  0.014093855829482698\n",
      "origion_rate_var :  0.013014060390419257\n",
      "alpha :  0.0009542696777117409\n",
      "beta :  0.06675393517816029\n",
      "origion_rate_mean :  0.015258331924165595\n",
      "origion_rate_var :  0.004990279278552974\n",
      "alpha :  0.030683846044190884\n",
      "beta :  1.9802729345980574\n",
      "origion_rate_mean :  0.012606475467843927\n",
      "origion_rate_var :  0.00592227402876684\n",
      "alpha :  0.013890063064148207\n",
      "beta :  1.0879296405935794\n",
      "origion_rate_mean :  0.0160762890974675\n",
      "origion_rate_var :  0.0061966521478486955\n",
      "alpha :  0.024960741099799445\n",
      "beta :  1.5276824683167014\n",
      "origion_rate_mean :  0.02516260381859347\n",
      "origion_rate_var :  0.003937676158122827\n",
      "alpha :  0.1315858784554019\n",
      "beta :  5.097836299155995\n",
      "origion_rate_mean :  0.013492268524523522\n",
      "origion_rate_var :  0.012456872579317333\n",
      "alpha :  0.000924284150164941\n",
      "beta :  0.067580441240155\n",
      "origion_rate_mean :  0.01564728099201716\n",
      "origion_rate_var :  0.005421183054518674\n",
      "alpha :  0.028809133850657084\n",
      "beta :  1.8123499701083476\n",
      "origion_rate_mean :  0.012498071729000252\n",
      "origion_rate_var :  0.0059604493527673705\n",
      "alpha :  0.013380778430044165\n",
      "beta :  1.057246652759657\n",
      "origion_rate_mean :  0.01534217734713753\n",
      "origion_rate_var :  0.005636997168553311\n",
      "alpha :  0.025773885018576612\n",
      "beta :  1.6541626999528765\n",
      "origion_rate_mean :  0.019801420926571698\n",
      "origion_rate_var :  0.0014527339967515679\n",
      "alpha :  0.2447564460129898\n",
      "beta :  12.115793179218652\n",
      "origion_rate_mean :  0.007875154591296264\n",
      "origion_rate_var :  0.00738536995410294\n",
      "alpha :  0.0004561352981106529\n",
      "beta :  0.057464670296585904\n",
      "origion_rate_mean :  0.00931294267830801\n",
      "origion_rate_var :  0.0029046475563907497\n",
      "alpha :  0.02026833344859595\n",
      "beta :  2.1560935479367123\n",
      "origion_rate_mean :  0.007772238570179888\n",
      "origion_rate_var :  0.0036376362491809177\n",
      "alpha :  0.008704996999634184\n",
      "beta :  1.1113065570760545\n",
      "origion_rate_mean :  0.010219552222677342\n",
      "origion_rate_var :  0.003988979845255969\n",
      "alpha :  0.015694824208603794\n",
      "beta :  1.5200695484981317\n",
      "origion_rate_mean :  0.013731976482686323\n",
      "origion_rate_var :  0.0008248843369347575\n",
      "alpha :  0.21172724214761604\n",
      "beta :  15.206828303339075\n",
      "origion_rate_mean :  0.007875154591296264\n",
      "origion_rate_var :  0.00738536995410294\n",
      "alpha :  0.0004561352981106529\n",
      "beta :  0.057464670296585904\n",
      "origion_rate_mean :  0.00931294267830801\n",
      "origion_rate_var :  0.0029046475563907497\n",
      "alpha :  0.02026833344859595\n",
      "beta :  2.1560935479367123\n",
      "origion_rate_mean :  0.007772238570179888\n",
      "origion_rate_var :  0.0036376362491809177\n",
      "alpha :  0.008704996999634184\n",
      "beta :  1.1113065570760545\n",
      "origion_rate_mean :  0.010219552222677342\n",
      "origion_rate_var :  0.003988979845255969\n",
      "alpha :  0.015694824208603794\n",
      "beta :  1.5200695484981317\n",
      "origion_rate_mean :  0.013731976482686323\n",
      "origion_rate_var :  0.0008248843369347575\n",
      "alpha :  0.21172724214761604\n",
      "beta :  15.206828303339075\n"
     ]
    }
   ],
   "source": [
    "def getBaseConversionRate(future_df, test_df, colName):\n",
    "    t = future_df[[colName]]\n",
    "    t[colName + '_total_number'] = 1\n",
    "    t = t.groupby(colName).agg('sum').reset_index()\n",
    "\n",
    "    t_buy = future_df[[colName]][future_df.is_trade == 1]\n",
    "    t_buy[colName + '_buy_number'] = 1\n",
    "    t_buy = t_buy.groupby(colName).agg('sum').reset_index()\n",
    "\n",
    "    t = pd.merge(t, t_buy, on=colName, how='left')\n",
    "    t[colName + '_buy_number'] = t[colName + '_buy_number'].map(lambda x: 0 if math.isnan(x) else x)\n",
    "    t['buy_origion_rate'] = t[colName + '_buy_number'] / t[colName + '_total_number']\n",
    "    alpha, beta = getBayesSmoothParam(t['buy_origion_rate'])\n",
    "    t[colName + '_converse_smooth_rate'] = (t[colName + '_buy_number'] + alpha) / (t[colName + '_total_number'] + alpha + beta)\n",
    "#     train_df = pd.merge(train_df, t[[colName, colName + '_converse_smooth_rate']], on=colName, how='left')\n",
    "#     train_df[colName + '_converse_smooth_rate'] = train_df[colName + '_converse_smooth_rate'].map(lambda x: (alpha / (alpha + beta)) if math.isnan(x) else x)\n",
    "\n",
    "    test_df = pd.merge(test_df, t[[colName, colName + '_converse_smooth_rate', colName + '_total_number', colName + '_buy_number']], on=colName, how='left')\n",
    "    test_df[colName + '_converse_smooth_rate'] = test_df[colName + '_converse_smooth_rate'].map(lambda x: (alpha / (alpha + beta)) if math.isnan(x) else x)\n",
    "\n",
    "    test_df[colName + '_total_number'] = test_df[colName + '_total_number'].fillna(0)\n",
    "    test_df, total_number_scaler = scalerFea(test_df, colName + '_total_number')\n",
    "\n",
    "    test_df[colName + '_buy_number'] = test_df[colName + '_buy_number'].fillna(0)\n",
    "    test_df, buy_number_scaler = scalerFea(test_df, colName + '_buy_number')\n",
    "\n",
    "    return test_df\n",
    "\n",
    "#定义对每个窗口进行操作的函数\n",
    "def dealHuaChuangDataset(future_df, dataset):\n",
    "    dataset = getBaseConversionRate(future_df, dataset, 'user_id')\n",
    "    dataset = getBaseConversionRate(future_df, dataset, 'item_brand_id')\n",
    "    dataset = getBaseConversionRate(future_df, dataset, 'item_id')\n",
    "    dataset = getBaseConversionRate(future_df, dataset, 'shop_id')\n",
    "    dataset = getBaseConversionRate(future_df, dataset, 'real_last_category')\n",
    "    return dataset\n",
    "\n",
    "#尝试统计两天前滑窗结果，包括商品，店铺，品牌，叶子类目的转化率，点击次数和购买次数\n",
    "#首先划分数据集\n",
    "future_dataset1 = train_df_1[(train_df_1.day == 31) | (train_df_1.day == 1)]\n",
    "train_df_huachuang_1 = train_df_1[train_df_1.day == 2]\n",
    "future_dataset2 = train_df_1[(train_df_1.day == 1) | (train_df_1.day == 2)]\n",
    "train_df_huachuang_2 = train_df_1[train_df_1.day == 3]\n",
    "future_dataset3 = train_df_1[(train_df_1.day == 2) | (train_df_1.day == 3)]\n",
    "train_df_huachuang_3 = train_df_1[train_df_1.day == 4]\n",
    "future_dataset4 = train_df_2\n",
    "train_df_huachuang_4 = train_df_3\n",
    "\n",
    "train_df_huachuang_1 = dealHuaChuangDataset(future_dataset1, train_df_huachuang_1)\n",
    "train_df_huachuang_2 = dealHuaChuangDataset(future_dataset2, train_df_huachuang_2)\n",
    "train_df_huachuang_3 = dealHuaChuangDataset(future_dataset3, train_df_huachuang_3)\n",
    "train_df_huachuang_4 = dealHuaChuangDataset(future_dataset4, train_df_huachuang_4)\n",
    "test_df = dealHuaChuangDataset(future_dataset4, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "['instance_id' 'item_id' 'item_brand_id' 'item_city_id' 'item_price_level'\n",
      " 'item_sales_level' 'item_collected_level' 'item_pv_level' 'user_id'\n",
      " 'user_gender_id' 'user_age_level' 'user_occupation_id' 'user_star_level'\n",
      " 'context_id' 'context_timestamp' 'context_page_id'\n",
      " 'predict_category_property' 'shop_id' 'shop_review_num_level'\n",
      " 'shop_review_positive_rate' 'shop_star_level' 'shop_score_service'\n",
      " 'shop_score_delivery' 'shop_score_description' 'date' 'weekday' 'day'\n",
      " 'hour' 'prop_jaccard' 'prop_predict_ratio' 'prop_item_ratio'\n",
      " 'match_category_proportion' 'match_property_proportion'\n",
      " 'predict_category_number' 'predict_property_number' 'isFirstCategoryIn'\n",
      " 'isLastCategoryIn' 'category_number' 'property_number'\n",
      " 'real_first_category' 'real_last_category'\n",
      " 'all_item_brand_id_click_number' 'all_item_brand_id_buy_number'\n",
      " 'history_item_brand_id_rate' 'history_item_brand_id_smooth_rate'\n",
      " 'all_shop_id_click_number' 'all_shop_id_buy_number' 'history_shop_id_rate'\n",
      " 'history_shop_id_smooth_rate' 'all_item_id_click_number'\n",
      " 'all_item_id_buy_number' 'history_item_id_rate'\n",
      " 'history_item_id_smooth_rate' 'lastOneHour_sameItem_count'\n",
      " 'lastOneHour_sameFirstCategory_count' 'lastOneHour_sameLastCategory_count'\n",
      " 'lastOneHour_sameBrand_count' 'lastOneHour_sameShop_count'\n",
      " 'isLastOneHour_firstClickItem' 'userItem_lastClickDeltaTime'\n",
      " 'userBrand_lastClickDeltaTime' 'userShop_lastClickDeltaTime'\n",
      " 'userFirstCategory_lastClickDeltaTime'\n",
      " 'userLastCategory_lastClickDeltaTime' 'hour_rate' 'shop_item_classNumber'\n",
      " 'brand_item_classNumber' 'city_item_classNumber' 'shop_user_classNumber'\n",
      " 'brand_user_classNumber' 'city_user_classNumber' 'item_price_level_mean'\n",
      " 'item_price_level_max' 'item_price_level_min' 'item_price_level_median'\n",
      " 'item_price_level_mode' 'item_sales_level_mean' 'item_sales_level_max'\n",
      " 'item_sales_level_min' 'item_sales_level_median' 'item_sales_level_mode'\n",
      " 'is_later_clickSameItem' 'is_later_clickSameLastCategory'\n",
      " 'later_clickSameItem_count' 'later_clickSameLastCategory_count'\n",
      " 'later_clickSameItem_deltaTime' 'later_clickSameLastCategory_deltaTime'\n",
      " 'user_id_converse_smooth_rate' 'user_id_total_number' 'user_id_buy_number'\n",
      " 'item_brand_id_converse_smooth_rate' 'item_brand_id_total_number'\n",
      " 'item_brand_id_buy_number' 'item_id_converse_smooth_rate'\n",
      " 'item_id_total_number' 'item_id_buy_number' 'shop_id_converse_smooth_rate'\n",
      " 'shop_id_total_number' 'shop_id_buy_number'\n",
      " 'real_last_category_converse_smooth_rate'\n",
      " 'real_last_category_total_number' 'real_last_category_buy_number']\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df.columns.values))\n",
    "print(test_df.columns.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将2,3,4号数据抽样15%与7号当天数据结合作为训练接，拟合线上分布\n",
    "train_df_234 = pd.concat([train_df_huachuang_1, train_df_huachuang_2, train_df_huachuang_3])\n",
    "train_df_234 = train_df_234.sample(frac = 0.15, replace = True)\n",
    "\n",
    "train_df = pd.concat([train_df_huachuang_4, train_df_234])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XgbModel:\n",
    "    def __init__(self, feaNames=None, params={}):\n",
    "        self.feaNames = feaNames\n",
    "        self.params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric':'logloss',\n",
    "            'silent': True,\n",
    "            'eta': 0.1,\n",
    "            'max_depth': 4,\n",
    "            'gamma': 0.5,\n",
    "            'subsample': 0.95,\n",
    "            'colsample_bytree': 1,\n",
    "            'min_child_weight': 8,\n",
    "            'max_delta_step': 5,\n",
    "            'lambda': 100,\n",
    "        }\n",
    "        for k,v in params.items():\n",
    "            self.params[k] = v\n",
    "        self.clf = None\n",
    "\n",
    "    def train(self, X, y, train_size=1, test_size=0.1, verbose=True, num_boost_round=1000, early_stopping_rounds=3):\n",
    "        X = X.astype(float)\n",
    "        if train_size==1:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "            X_train, y_train = X, y\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size)\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=self.feaNames)\n",
    "        dval = xgb.DMatrix(X_test, label=y_test, feature_names=self.feaNames)\n",
    "        watchlist = [(dtrain,'train'),(dval,'val')]\n",
    "        clf = xgb.train(\n",
    "            self.params, dtrain,\n",
    "            num_boost_round = num_boost_round,\n",
    "            evals = watchlist,\n",
    "            early_stopping_rounds = early_stopping_rounds,\n",
    "            verbose_eval=verbose\n",
    "        )\n",
    "        self.clf = clf\n",
    "\n",
    "    def trainCV(self, X, y, nFold=3, verbose=True, num_boost_round=1500, early_stopping_rounds=10):\n",
    "        X = X.astype(float)\n",
    "        dtrain = xgb.DMatrix(X, label=y, feature_names=self.feaNames)\n",
    "        cvResult = xgb.cv(\n",
    "            self.params, dtrain,\n",
    "            num_boost_round = num_boost_round,\n",
    "            nfold = nFold,\n",
    "            early_stopping_rounds = early_stopping_rounds,\n",
    "            verbose_eval=verbose\n",
    "        )\n",
    "        clf = xgb.train(\n",
    "            self.params, dtrain,\n",
    "            num_boost_round = cvResult.shape[0],\n",
    "        )\n",
    "        self.clf = clf\n",
    "\n",
    "    def gridSearch(self, X, y, nFold=3, verbose=1, num_boost_round=130):\n",
    "        paramsGrids = {\n",
    "            # 'n_estimators': [50+5*i for i in range(0,30)],\n",
    "            'gamma': [0,0.01,0.05,0.1,0.5,1,5,10,50,100],\n",
    "            # 'max_depth': list(range(3,10)),\n",
    "            'min_child_weight': list(range(0,10)),\n",
    "            'subsample': [1-0.05*i for i in range(0,8)],\n",
    "            'colsample_bytree': [1-0.05*i for i in range(0,10)],\n",
    "            # 'reg_alpha': [0+2*i for i in range(0,10)],\n",
    "            'reg_lambda': [0+50*i for i in range(0,10)],\n",
    "            'max_delta_step': [0+1*i for i in range(0,8)],\n",
    "        }\n",
    "        for k,v in paramsGrids.items():\n",
    "            gsearch = GridSearchCV(\n",
    "                estimator = xgb.XGBClassifier(\n",
    "                    max_depth = self.params['max_depth'],\n",
    "                    gamma = self.params['gamma'],\n",
    "                    learning_rate = self.params['eta'],\n",
    "                    max_delta_step = self.params['max_delta_step'],\n",
    "                    min_child_weight = self.params['min_child_weight'],\n",
    "                    subsample = self.params['subsample'],\n",
    "                    colsample_bytree = self.params['colsample_bytree'],\n",
    "                    silent = self.params['silent'],\n",
    "                    reg_lambda = self.params['lambda'],\n",
    "                    n_estimators = num_boost_round\n",
    "                ),\n",
    "                # param_grid = paramsGrids,\n",
    "                param_grid = {k:v},\n",
    "                scoring = 'neg_log_loss',\n",
    "                cv = nFold,\n",
    "                verbose = verbose,\n",
    "                n_jobs = 4\n",
    "            )\n",
    "            gsearch.fit(X, y)\n",
    "            print(pd.DataFrame(gsearch.cv_results_))\n",
    "            print(gsearch.best_params_)\n",
    "        exit()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.astype(float)\n",
    "        return self.clf.predict(xgb.DMatrix(X, feature_names=self.feaNames))\n",
    "\n",
    "    def getFeaScore(self, show=False):\n",
    "        fscore = self.clf.get_score()\n",
    "        feaNames = fscore.keys()\n",
    "        scoreDf = pd.DataFrame(index=feaNames, columns=['importance'])\n",
    "        for k,v in fscore.items():\n",
    "            scoreDf.loc[k, 'importance'] = v\n",
    "        if show:\n",
    "            print(scoreDf.sort_index(by=['importance'], ascending=False))\n",
    "        return scoreDf\n",
    "\n",
    "# 划分训练集和测试集\n",
    "def trainTestSplit(df, splitDate=pd.to_datetime('2018-09-23'), trainPeriod=3, testPeriod=1):\n",
    "    trainDf = df[(df.context_timestamp<splitDate)&(df.context_timestamp>=splitDate-timedelta(days=trainPeriod))]\n",
    "    testDf = df[(df.context_timestamp>=splitDate)&(df.context_timestamp<splitDate+timedelta(days=testPeriod))]\n",
    "    return (trainDf, testDf)\n",
    "\n",
    "\n",
    "# 统计预测误差\n",
    "def countDeltaY(predictSeries, labelSeries, show=True, title='', subplot=None):\n",
    "    deltaSeries = predictSeries - labelSeries\n",
    "    if subplot!=None:\n",
    "        plt.subplot(subplot[0], subplot[1], subplot[2])\n",
    "    deltaSeries.plot(style='b-')\n",
    "    plt.title(title)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return deltaSeries\n",
    "\n",
    "# 获取stacking下一层数据集\n",
    "def getOof(clf, trainX, trainY, testX, nFold=5, stratify=False):\n",
    "    oofTrain = np.zeros(trainX.shape[0])\n",
    "    oofTest = np.zeros(testX.shape[0])\n",
    "    oofTestSkf = np.zeros((testX.shape[0], nFold))\n",
    "    if stratify:\n",
    "        kf = StratifiedKFold(n_splits=nFold, shuffle=True)\n",
    "    else:\n",
    "        kf = KFold(n_splits=nFold, shuffle=True)\n",
    "    for i, (trainIdx, testIdx) in enumerate(kf.split(trainX, trainY)):\n",
    "        kfTrainX = trainX[trainIdx]\n",
    "        kfTrainY = trainY[trainIdx]\n",
    "        kfTestX = trainX[testIdx]\n",
    "        clf.trainCV(kfTrainX, kfTrainY, verbose=False)\n",
    "        oofTrain[testIdx] = clf.predict(kfTestX)\n",
    "        oofTestSkf[:,i] = clf.predict(testX)\n",
    "    oofTest[:] = oofTestSkf.mean(axis=1)\n",
    "    return oofTrain, oofTest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea = [\n",
    "\n",
    "         'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level',\n",
    "         'item_collected_level', 'item_pv_level', 'user_gender_id',\n",
    "         'user_age_level', 'user_occupation_id', 'user_star_level',\n",
    "         'context_page_id',\n",
    "         'shop_review_num_level', 'shop_review_positive_rate',\n",
    "         'shop_star_level', 'shop_score_service', 'shop_score_delivery',\n",
    "         'shop_score_description',\n",
    "         'prop_jaccard', 'prop_predict_ratio', 'prop_item_ratio',\n",
    "#          'match_category_proportion', 'match_property_proportion', \n",
    "#          'predict_category_number', 'predict_property_number',\n",
    "#          'isLastCategoryIn', 'isFirstCategoryIn',\n",
    "         'category_number', 'property_number',\n",
    "         'all_item_brand_id_click_number',\n",
    "         'all_item_brand_id_buy_number',\n",
    "         'history_item_brand_id_smooth_rate', 'all_shop_id_click_number',\n",
    "         'all_shop_id_buy_number',\n",
    "         'history_shop_id_smooth_rate', 'all_item_id_click_number',\n",
    "         'all_item_id_buy_number',\n",
    "         'history_item_id_smooth_rate', 'lastOneHour_sameItem_count',\n",
    "         'lastOneHour_sameFirstCategory_count', 'lastOneHour_sameLastCategory_count',\n",
    "         'lastOneHour_sameBrand_count', 'lastOneHour_sameShop_count',\n",
    "         'isLastOneHour_firstClickItem',\n",
    "    #      'is_special', 'hour',\n",
    "         'hour_rate',\n",
    "         'userItem_lastClickDeltaTime',\n",
    "         'userBrand_lastClickDeltaTime', 'userShop_lastClickDeltaTime',\n",
    "         'userFirstCategory_lastClickDeltaTime',\n",
    "         'userLastCategory_lastClickDeltaTime',\n",
    "         'user_id_converse_smooth_rate', 'user_id_total_number', 'user_id_buy_number',\n",
    "         'item_brand_id_converse_smooth_rate', 'item_brand_id_total_number',\n",
    "         'item_brand_id_buy_number', 'item_id_converse_smooth_rate',\n",
    "         'item_id_total_number', 'item_id_buy_number', 'shop_id_converse_smooth_rate',\n",
    "         'shop_id_total_number', 'shop_id_buy_number',\n",
    "         'real_last_category_converse_smooth_rate',\n",
    "         'real_last_category_total_number', 'real_last_category_buy_number',\n",
    "         'is_later_clickSameItem', 'is_later_clickSameLastCategory',\n",
    "         'later_clickSameItem_count', 'later_clickSameLastCategory_count',\n",
    "         'later_clickSameItem_deltaTime', 'later_clickSameLastCategory_deltaTime',\n",
    "         'shop_item_classNumber', 'brand_item_classNumber', 'city_item_classNumber',\n",
    "         'shop_user_classNumber', 'brand_user_classNumber', 'city_user_classNumber',\n",
    "#          'item_price_level_mode','item_sales_level_mode', \n",
    "#          'item_price_level_mean', 'item_sales_level_mean', \n",
    "#          'item_price_level_max', 'item_sales_level_max', \n",
    "#          'item_price_level_min', 'item_sales_level_min',  \n",
    "#         'item_sales_level_median', 'item_price_level_median', \n",
    "         ]\n",
    "\n",
    "train_df_7 = train_df[train_df.day == 7]\n",
    "xgbModel = XgbModel(feaNames=fea)\n",
    "modelName = \"xgb_fusai_a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.615224+0.000104327\ttest-logloss:0.615224+7.30677e-05\n",
      "[1]\ttrain-logloss:0.551455+0.000178574\ttest-logloss:0.551455+0.000157051\n",
      "[2]\ttrain-logloss:0.498491+0.000279256\ttest-logloss:0.498492+0.000203649\n",
      "[3]\ttrain-logloss:0.454037+0.000323484\ttest-logloss:0.45404+0.000297533\n",
      "[4]\ttrain-logloss:0.41641+0.000371131\ttest-logloss:0.416423+0.00037828\n",
      "[5]\ttrain-logloss:0.384351+0.00042417\ttest-logloss:0.384378+0.000453768\n",
      "[6]\ttrain-logloss:0.356898+0.000466335\ttest-logloss:0.356927+0.000527633\n",
      "[7]\ttrain-logloss:0.333293+0.000514004\ttest-logloss:0.333342+0.000598367\n",
      "[8]\ttrain-logloss:0.312938+0.000563383\ttest-logloss:0.313004+0.000657637\n",
      "[9]\ttrain-logloss:0.295326+0.000621354\ttest-logloss:0.295414+0.000712402\n",
      "[10]\ttrain-logloss:0.280041+0.000660707\ttest-logloss:0.280152+0.000775454\n",
      "[11]\ttrain-logloss:0.26678+0.000687478\ttest-logloss:0.26693+0.000853381\n",
      "[12]\ttrain-logloss:0.255275+0.000725587\ttest-logloss:0.255442+0.000907854\n",
      "[13]\ttrain-logloss:0.24526+0.000755557\ttest-logloss:0.245464+0.000977829\n",
      "[14]\ttrain-logloss:0.236569+0.000788552\ttest-logloss:0.23682+0.00101739\n",
      "[15]\ttrain-logloss:0.228995+0.000812367\ttest-logloss:0.2293+0.00108961\n",
      "[16]\ttrain-logloss:0.222409+0.000836545\ttest-logloss:0.222764+0.00113917\n",
      "[17]\ttrain-logloss:0.216689+0.000845253\ttest-logloss:0.217091+0.00118446\n",
      "[18]\ttrain-logloss:0.211705+0.000864596\ttest-logloss:0.212166+0.00123802\n",
      "[19]\ttrain-logloss:0.207355+0.000894776\ttest-logloss:0.207876+0.00129624\n",
      "[20]\ttrain-logloss:0.203559+0.000921634\ttest-logloss:0.204169+0.00136499\n",
      "[21]\ttrain-logloss:0.200266+0.000938085\ttest-logloss:0.200971+0.00140548\n",
      "[22]\ttrain-logloss:0.197396+0.000958211\ttest-logloss:0.198168+0.00145667\n",
      "[23]\ttrain-logloss:0.194898+0.000966895\ttest-logloss:0.195745+0.00149146\n",
      "[24]\ttrain-logloss:0.192728+0.00096831\ttest-logloss:0.193647+0.00152431\n",
      "[25]\ttrain-logloss:0.190833+0.000977742\ttest-logloss:0.191831+0.00153911\n",
      "[26]\ttrain-logloss:0.189156+0.000992165\ttest-logloss:0.190212+0.00158244\n",
      "[27]\ttrain-logloss:0.187702+0.00100367\ttest-logloss:0.188828+0.00161687\n",
      "[28]\ttrain-logloss:0.186432+0.00101464\ttest-logloss:0.187629+0.0016494\n",
      "[29]\ttrain-logloss:0.185305+0.00102919\ttest-logloss:0.186563+0.001668\n",
      "[30]\ttrain-logloss:0.184325+0.00102287\ttest-logloss:0.185667+0.00170129\n",
      "[31]\ttrain-logloss:0.183469+0.00104156\ttest-logloss:0.184868+0.00170951\n",
      "[32]\ttrain-logloss:0.182699+0.00103874\ttest-logloss:0.184142+0.00171958\n",
      "[33]\ttrain-logloss:0.182016+0.00102766\ttest-logloss:0.183525+0.00173589\n",
      "[34]\ttrain-logloss:0.18141+0.00101873\ttest-logloss:0.183005+0.00176079\n",
      "[35]\ttrain-logloss:0.180874+0.00101321\ttest-logloss:0.182515+0.00177221\n",
      "[36]\ttrain-logloss:0.180405+0.00101565\ttest-logloss:0.182127+0.00179592\n",
      "[37]\ttrain-logloss:0.17997+0.00100646\ttest-logloss:0.181763+0.00180866\n",
      "[38]\ttrain-logloss:0.179581+0.000995125\ttest-logloss:0.181426+0.00181982\n",
      "[39]\ttrain-logloss:0.179241+0.000986307\ttest-logloss:0.181162+0.00183948\n",
      "[40]\ttrain-logloss:0.178926+0.00097231\ttest-logloss:0.180899+0.00186004\n",
      "[41]\ttrain-logloss:0.178626+0.000964711\ttest-logloss:0.180657+0.00188348\n",
      "[42]\ttrain-logloss:0.178342+0.000951831\ttest-logloss:0.180439+0.00188393\n",
      "[43]\ttrain-logloss:0.178076+0.000943925\ttest-logloss:0.180237+0.00189133\n",
      "[44]\ttrain-logloss:0.177838+0.000939718\ttest-logloss:0.18006+0.00190093\n",
      "[45]\ttrain-logloss:0.177617+0.000933774\ttest-logloss:0.1799+0.00190706\n",
      "[46]\ttrain-logloss:0.177413+0.000926482\ttest-logloss:0.179766+0.00190485\n",
      "[47]\ttrain-logloss:0.177217+0.000923029\ttest-logloss:0.179605+0.00189306\n",
      "[48]\ttrain-logloss:0.177029+0.000906273\ttest-logloss:0.17949+0.00189898\n",
      "[49]\ttrain-logloss:0.176861+0.00090744\ttest-logloss:0.179377+0.00189995\n",
      "[50]\ttrain-logloss:0.176705+0.000899115\ttest-logloss:0.179282+0.00189028\n",
      "[51]\ttrain-logloss:0.176555+0.000888149\ttest-logloss:0.179186+0.00189136\n",
      "[52]\ttrain-logloss:0.176402+0.000875291\ttest-logloss:0.179101+0.00189917\n",
      "[53]\ttrain-logloss:0.176227+0.000878242\ttest-logloss:0.179011+0.00189879\n",
      "[54]\ttrain-logloss:0.176096+0.000878477\ttest-logloss:0.178937+0.00190491\n",
      "[55]\ttrain-logloss:0.17596+0.000887021\ttest-logloss:0.178852+0.00189757\n",
      "[56]\ttrain-logloss:0.175827+0.000870095\ttest-logloss:0.178779+0.00189109\n",
      "[57]\ttrain-logloss:0.17569+0.000871367\ttest-logloss:0.17869+0.0018972\n",
      "[58]\ttrain-logloss:0.175567+0.000868094\ttest-logloss:0.178627+0.00191229\n",
      "[59]\ttrain-logloss:0.175449+0.000865513\ttest-logloss:0.178572+0.00191871\n",
      "[60]\ttrain-logloss:0.17533+0.00085521\ttest-logloss:0.17849+0.00191735\n",
      "[61]\ttrain-logloss:0.175231+0.000857067\ttest-logloss:0.17843+0.001925\n",
      "[62]\ttrain-logloss:0.175129+0.000854312\ttest-logloss:0.178383+0.00190724\n",
      "[63]\ttrain-logloss:0.175025+0.000849524\ttest-logloss:0.178332+0.00190372\n",
      "[64]\ttrain-logloss:0.174912+0.00083011\ttest-logloss:0.178276+0.00189907\n",
      "[65]\ttrain-logloss:0.174803+0.000826141\ttest-logloss:0.178242+0.00190255\n",
      "[66]\ttrain-logloss:0.174716+0.000819085\ttest-logloss:0.178196+0.00188637\n",
      "[67]\ttrain-logloss:0.174625+0.000817739\ttest-logloss:0.178167+0.00188102\n",
      "[68]\ttrain-logloss:0.174521+0.000805009\ttest-logloss:0.178138+0.00186913\n",
      "[69]\ttrain-logloss:0.174444+0.000810458\ttest-logloss:0.178111+0.00187195\n",
      "[70]\ttrain-logloss:0.174352+0.000825704\ttest-logloss:0.178077+0.0018803\n",
      "[71]\ttrain-logloss:0.174248+0.000824206\ttest-logloss:0.17804+0.00189129\n",
      "[72]\ttrain-logloss:0.174183+0.00082534\ttest-logloss:0.17801+0.00189283\n",
      "[73]\ttrain-logloss:0.174097+0.000818541\ttest-logloss:0.177983+0.00188817\n",
      "[74]\ttrain-logloss:0.174011+0.00082122\ttest-logloss:0.177948+0.00189144\n",
      "[75]\ttrain-logloss:0.173933+0.000829715\ttest-logloss:0.177935+0.00187187\n",
      "[76]\ttrain-logloss:0.173858+0.000840723\ttest-logloss:0.177916+0.00187551\n",
      "[77]\ttrain-logloss:0.173775+0.000826165\ttest-logloss:0.177898+0.0018674\n",
      "[78]\ttrain-logloss:0.1737+0.000813521\ttest-logloss:0.177868+0.00186342\n",
      "[79]\ttrain-logloss:0.173624+0.000822368\ttest-logloss:0.177844+0.0018609\n",
      "[80]\ttrain-logloss:0.17355+0.000847851\ttest-logloss:0.177815+0.00185527\n",
      "[81]\ttrain-logloss:0.173486+0.000837803\ttest-logloss:0.177791+0.0018602\n",
      "[82]\ttrain-logloss:0.173409+0.000838156\ttest-logloss:0.177762+0.0018497\n",
      "[83]\ttrain-logloss:0.173354+0.000829303\ttest-logloss:0.17774+0.00185824\n",
      "[84]\ttrain-logloss:0.173283+0.000841483\ttest-logloss:0.177713+0.00185501\n",
      "[85]\ttrain-logloss:0.173227+0.000828843\ttest-logloss:0.177693+0.00184786\n",
      "[86]\ttrain-logloss:0.173135+0.000819545\ttest-logloss:0.177673+0.00185357\n",
      "[87]\ttrain-logloss:0.173059+0.000792618\ttest-logloss:0.177645+0.00184577\n",
      "[88]\ttrain-logloss:0.172979+0.000781139\ttest-logloss:0.177625+0.00183506\n",
      "[89]\ttrain-logloss:0.172907+0.000797309\ttest-logloss:0.177617+0.00181554\n",
      "[90]\ttrain-logloss:0.172831+0.000791433\ttest-logloss:0.177597+0.00179484\n",
      "[91]\ttrain-logloss:0.172753+0.00078931\ttest-logloss:0.177574+0.00179682\n",
      "[92]\ttrain-logloss:0.172686+0.000783625\ttest-logloss:0.177542+0.00180255\n",
      "[93]\ttrain-logloss:0.172622+0.000761275\ttest-logloss:0.177532+0.00178339\n",
      "[94]\ttrain-logloss:0.172565+0.000760775\ttest-logloss:0.177515+0.00177816\n",
      "[95]\ttrain-logloss:0.172504+0.000747534\ttest-logloss:0.1775+0.00177413\n",
      "[96]\ttrain-logloss:0.172457+0.000741609\ttest-logloss:0.177488+0.00177796\n",
      "[97]\ttrain-logloss:0.172402+0.000719309\ttest-logloss:0.177475+0.00178568\n",
      "[98]\ttrain-logloss:0.17234+0.000716917\ttest-logloss:0.177467+0.00179001\n",
      "[99]\ttrain-logloss:0.172278+0.000697736\ttest-logloss:0.177457+0.00177975\n",
      "[100]\ttrain-logloss:0.172201+0.000688612\ttest-logloss:0.177439+0.00177962\n",
      "[101]\ttrain-logloss:0.172133+0.000702537\ttest-logloss:0.177428+0.00177297\n",
      "[102]\ttrain-logloss:0.172067+0.00069694\ttest-logloss:0.177427+0.00177708\n",
      "[103]\ttrain-logloss:0.171985+0.00069413\ttest-logloss:0.177413+0.00177565\n",
      "[104]\ttrain-logloss:0.171931+0.000706083\ttest-logloss:0.177405+0.0017764\n",
      "[105]\ttrain-logloss:0.171859+0.000694896\ttest-logloss:0.177384+0.00177813\n",
      "[106]\ttrain-logloss:0.171786+0.00069292\ttest-logloss:0.17737+0.00178\n",
      "[107]\ttrain-logloss:0.171704+0.000701795\ttest-logloss:0.177346+0.00177794\n",
      "[108]\ttrain-logloss:0.171645+0.000720156\ttest-logloss:0.177351+0.0017765\n",
      "[109]\ttrain-logloss:0.171587+0.000711675\ttest-logloss:0.177341+0.00177175\n",
      "[110]\ttrain-logloss:0.171538+0.00071204\ttest-logloss:0.177337+0.00176623\n",
      "[111]\ttrain-logloss:0.171469+0.000714197\ttest-logloss:0.177325+0.00176736\n",
      "[112]\ttrain-logloss:0.171396+0.000723235\ttest-logloss:0.177315+0.00176068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113]\ttrain-logloss:0.171339+0.000736332\ttest-logloss:0.177317+0.00176373\n",
      "[114]\ttrain-logloss:0.171299+0.000747797\ttest-logloss:0.177308+0.00175508\n",
      "[115]\ttrain-logloss:0.171252+0.000753706\ttest-logloss:0.177291+0.00175076\n",
      "[116]\ttrain-logloss:0.171207+0.000729101\ttest-logloss:0.177286+0.00174179\n",
      "[117]\ttrain-logloss:0.171143+0.000725596\ttest-logloss:0.177272+0.0017411\n",
      "[118]\ttrain-logloss:0.171077+0.000728007\ttest-logloss:0.177273+0.00173987\n",
      "[119]\ttrain-logloss:0.171033+0.000737625\ttest-logloss:0.177266+0.00173403\n",
      "[120]\ttrain-logloss:0.170986+0.000753448\ttest-logloss:0.177253+0.00171939\n",
      "[121]\ttrain-logloss:0.170933+0.00074229\ttest-logloss:0.17725+0.00171458\n",
      "[122]\ttrain-logloss:0.170892+0.00074622\ttest-logloss:0.177234+0.0017076\n",
      "[123]\ttrain-logloss:0.170833+0.00075324\ttest-logloss:0.177228+0.00170559\n",
      "[124]\ttrain-logloss:0.170795+0.000763774\ttest-logloss:0.177218+0.00170901\n",
      "[125]\ttrain-logloss:0.170738+0.000758573\ttest-logloss:0.177207+0.00170741\n",
      "[126]\ttrain-logloss:0.170684+0.00076057\ttest-logloss:0.177206+0.00170241\n",
      "[127]\ttrain-logloss:0.170637+0.000773234\ttest-logloss:0.177208+0.00170384\n",
      "[128]\ttrain-logloss:0.170594+0.000785879\ttest-logloss:0.177207+0.00170187\n",
      "[129]\ttrain-logloss:0.170539+0.000790471\ttest-logloss:0.177203+0.00169727\n",
      "[130]\ttrain-logloss:0.170468+0.000789711\ttest-logloss:0.177208+0.00169497\n",
      "[131]\ttrain-logloss:0.170414+0.000784094\ttest-logloss:0.177203+0.00169915\n",
      "[132]\ttrain-logloss:0.170383+0.000778706\ttest-logloss:0.177205+0.00169527\n",
      "[133]\ttrain-logloss:0.170318+0.000770768\ttest-logloss:0.177197+0.00169777\n",
      "[134]\ttrain-logloss:0.170267+0.000774017\ttest-logloss:0.177201+0.00169149\n",
      "[135]\ttrain-logloss:0.170221+0.000779577\ttest-logloss:0.177209+0.00170039\n",
      "[136]\ttrain-logloss:0.170157+0.000780739\ttest-logloss:0.177204+0.001707\n",
      "[137]\ttrain-logloss:0.170109+0.00077759\ttest-logloss:0.177199+0.00170743\n",
      "[138]\ttrain-logloss:0.170056+0.000772987\ttest-logloss:0.177195+0.00170289\n",
      "[139]\ttrain-logloss:0.170004+0.00077042\ttest-logloss:0.177182+0.00169374\n",
      "[140]\ttrain-logloss:0.169939+0.000771361\ttest-logloss:0.177166+0.00168551\n",
      "[141]\ttrain-logloss:0.169886+0.000787235\ttest-logloss:0.177169+0.00167363\n",
      "[142]\ttrain-logloss:0.169837+0.000768494\ttest-logloss:0.177174+0.00166593\n",
      "[143]\ttrain-logloss:0.169795+0.000768584\ttest-logloss:0.177175+0.00166505\n",
      "[144]\ttrain-logloss:0.169734+0.000760101\ttest-logloss:0.177164+0.00166755\n",
      "[145]\ttrain-logloss:0.169689+0.000757057\ttest-logloss:0.17716+0.00166369\n",
      "[146]\ttrain-logloss:0.169625+0.000747786\ttest-logloss:0.177142+0.00167078\n",
      "[147]\ttrain-logloss:0.169579+0.000750515\ttest-logloss:0.177144+0.00167888\n",
      "[148]\ttrain-logloss:0.169531+0.000739009\ttest-logloss:0.177146+0.00167313\n",
      "[149]\ttrain-logloss:0.169481+0.000753561\ttest-logloss:0.177151+0.00167736\n",
      "[150]\ttrain-logloss:0.169437+0.000750825\ttest-logloss:0.177145+0.0016768\n",
      "[151]\ttrain-logloss:0.169391+0.000731201\ttest-logloss:0.177154+0.00167091\n",
      "[152]\ttrain-logloss:0.169352+0.000723085\ttest-logloss:0.177141+0.00166806\n",
      "[153]\ttrain-logloss:0.169306+0.000738404\ttest-logloss:0.177141+0.00166795\n",
      "[154]\ttrain-logloss:0.169268+0.000738251\ttest-logloss:0.177138+0.00166671\n",
      "[155]\ttrain-logloss:0.16923+0.000739222\ttest-logloss:0.177136+0.0016626\n",
      "[156]\ttrain-logloss:0.169191+0.000749744\ttest-logloss:0.177136+0.00165931\n",
      "[157]\ttrain-logloss:0.169149+0.000750097\ttest-logloss:0.177145+0.00165488\n",
      "[158]\ttrain-logloss:0.169109+0.000743302\ttest-logloss:0.177135+0.00165546\n",
      "[159]\ttrain-logloss:0.169061+0.000739864\ttest-logloss:0.177138+0.00165112\n",
      "[160]\ttrain-logloss:0.169019+0.000733563\ttest-logloss:0.177136+0.00165009\n",
      "[161]\ttrain-logloss:0.16896+0.000743848\ttest-logloss:0.177138+0.00165133\n",
      "[162]\ttrain-logloss:0.168909+0.000753096\ttest-logloss:0.177123+0.00165159\n",
      "[163]\ttrain-logloss:0.168846+0.000755642\ttest-logloss:0.177126+0.00166383\n",
      "[164]\ttrain-logloss:0.168818+0.000755058\ttest-logloss:0.177129+0.00165701\n",
      "[165]\ttrain-logloss:0.168778+0.000767229\ttest-logloss:0.177143+0.00166972\n",
      "[166]\ttrain-logloss:0.168738+0.000772692\ttest-logloss:0.177149+0.00167512\n",
      "[167]\ttrain-logloss:0.168682+0.00075774\ttest-logloss:0.177149+0.00166767\n",
      "[168]\ttrain-logloss:0.16866+0.000757855\ttest-logloss:0.177153+0.00166716\n",
      "[169]\ttrain-logloss:0.168618+0.00077053\ttest-logloss:0.17716+0.00166711\n",
      "[170]\ttrain-logloss:0.168567+0.000753306\ttest-logloss:0.177157+0.0016698\n",
      "[171]\ttrain-logloss:0.16851+0.000752561\ttest-logloss:0.177165+0.00165389\n",
      "                                        importance\n",
      "item_sales_level                               114\n",
      "history_item_brand_id_smooth_rate               67\n",
      "history_item_id_smooth_rate                     66\n",
      "shop_score_delivery                             66\n",
      "user_star_level                                 64\n",
      "real_last_category_converse_smooth_rate         64\n",
      "shop_score_description                          64\n",
      "history_shop_id_smooth_rate                     60\n",
      "all_item_id_click_number                        60\n",
      "property_number                                 52\n",
      "hour_rate                                       51\n",
      "item_brand_id                                   49\n",
      "item_sales_level_median                         48\n",
      "shop_score_service                              44\n",
      "item_id_converse_smooth_rate                    42\n",
      "shop_user_classNumber                           42\n",
      "userFirstCategory_lastClickDeltaTime            42\n",
      "shop_item_classNumber                           41\n",
      "real_last_category_total_number                 41\n",
      "item_city_id                                    40\n",
      "user_age_level                                  39\n",
      "item_brand_id_converse_smooth_rate              37\n",
      "shop_id_converse_smooth_rate                    36\n",
      "prop_jaccard                                    36\n",
      "item_collected_level                            36\n",
      "shop_review_positive_rate                       35\n",
      "context_page_id                                 33\n",
      "all_shop_id_click_number                        32\n",
      "item_price_level_median                         31\n",
      "prop_item_ratio                                 30\n",
      "...                                            ...\n",
      "item_id_total_number                            28\n",
      "real_last_category_buy_number                   27\n",
      "city_user_classNumber                           27\n",
      "later_clickSameLastCategory_deltaTime           27\n",
      "shop_review_num_level                           25\n",
      "item_brand_id_total_number                      24\n",
      "all_item_brand_id_click_number                  23\n",
      "shop_id_total_number                            22\n",
      "userShop_lastClickDeltaTime                     20\n",
      "is_later_clickSameLastCategory                  19\n",
      "user_occupation_id                              19\n",
      "item_pv_level                                   18\n",
      "all_item_brand_id_buy_number                    18\n",
      "userItem_lastClickDeltaTime                     17\n",
      "user_gender_id                                  17\n",
      "brand_user_classNumber                          14\n",
      "brand_item_classNumber                          13\n",
      "shop_star_level                                 12\n",
      "all_shop_id_buy_number                          11\n",
      "item_price_level                                10\n",
      "prop_predict_ratio                               9\n",
      "all_item_id_buy_number                           9\n",
      "userBrand_lastClickDeltaTime                     7\n",
      "shop_id_buy_number                               6\n",
      "userLastCategory_lastClickDeltaTime              6\n",
      "item_id_buy_number                               4\n",
      "item_brand_id_buy_number                         4\n",
      "category_number                                  3\n",
      "user_id_total_number                             3\n",
      "user_id_converse_smooth_rate                     2\n",
      "\n",
      "[61 rows x 1 columns]\n",
      "training time:  0:04:11.348544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:105: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n"
     ]
    }
   ],
   "source": [
    "# 正式模型\n",
    "startTime = datetime.datetime.now()\n",
    "xgbModel.trainCV(train_df_7[fea].values, train_df_7['is_trade'].values)\n",
    "xgbModel.getFeaScore(show=True)\n",
    "print('training time: ', datetime.datetime.now()-startTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting time:  0:04:20.239288\n",
      "预测结果：\n",
      "            instance_id  predicted_score\n",
      "0  7279286161489290771         0.087065\n",
      "1  8639231129442069895         0.074561\n",
      "2  8589809858455174680         0.025012\n",
      "3  4336529059857606193         0.009611\n",
      "4   599240169885361385         0.018930\n",
      "预测均值： 0.04236214980483055\n"
     ]
    }
   ],
   "source": [
    "# 开始预测\n",
    "test_df.loc[:,'predicted_score'] = xgbModel.predict(test_df[fea].values)\n",
    "print('predicting time: ', datetime.datetime.now()-startTime)\n",
    "print(\"预测结果：\\n\",test_df[['instance_id','predicted_score']].head())\n",
    "print('预测均值：', test_df['predicted_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-86f69b5d39d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df_7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predicted_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predicted_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetOof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_trade'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfea\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oof training time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstartTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxgbModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeaScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-14e66647a47b>\u001b[0m in \u001b[0;36mgetOof\u001b[0;34m(clf, trainX, trainY, testX, nFold, stratify)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mkfTrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mkfTestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestIdx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfTrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkfTrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0moofTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfTestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0moofTestSkf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-14e66647a47b>\u001b[0m in \u001b[0;36mtrainCV\u001b[0;34m(self, X, y, nFold, verbose, num_boost_round, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mnfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnFold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m         clf = xgb.train(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/training.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, iteration, feval)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/xgboost-0.7-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m    954\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 生成stacking数据集\n",
    "train_df_7['predicted_score'] = np.nan\n",
    "test_df['predicted_score'] = np.nan\n",
    "train_df_7.loc[:,'predicted_score'], test_df.loc[:,'predicted_score'] = getOof(xgbModel, train_df_7[fea].values, train_df_7['is_trade'].values, test_df[fea].values, stratify=True)\n",
    "print('oof training time: ', datetime.datetime.now()-startTime)\n",
    "xgbModel.getFeaScore(show=True)\n",
    "cost = metrics.log_loss(train_df_7['is_trade'].values, train_df_7['predicted_score'].values)\n",
    "print('train loss: ', cost)\n",
    "print('7th train loss', metrics.log_loss(train_df_7['is_trade'].values, train_df_7['predicted_score'].values))\n",
    "print('7th train predict aver:', train_df_7['predicted_score'].mean())\n",
    "print('test predict: \\n',test_df[['instance_id','predicted_score']].head())\n",
    "print('test predict aver:', test_df['predicted_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导出预测结果\n",
    "def exportResult(df, fileName):\n",
    "    df.to_csv('~/kengkeng/alimama/result/%s.txt' % fileName, sep=' ', header=True, index=False)\n",
    "\n",
    "exportResult(test_df[['instance_id', 'predicted_score']], 'fusai_xgb_5_10_wen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
