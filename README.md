# IJCAI-18 阿里妈妈搜索广告转化预测
A competition about IJCAI-18 阿里妈妈搜索广告转化预测 on the TianChi platform ! Rank 48  
从2018年3月1号开始，[IJCAI-18阿里妈妈搜索广告转化预测大赛](https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.100150.711.6.50d52009HO5leS&raceId=231647)开始了，选手可以进行数据的下载和分析。本次比赛分为初赛和复赛两个阶段，本文主要从复赛角度入手阐述，分为赛题背景，数据分析，特征工程，模型训练和总结五部分。
* 1 **赛题背景**  
本次比赛主要是关于广告CTR（Click-Through-Rate），即广告的点击转化率。搜索广告的转化率，作为衡量广告转化效果的指标，从广告创意、商品品质、商店质量等多个角度综合刻画用户对广告商品的购买意向，即广告商品被用户点击后产生购买行为的概率。举例来说，用户在淘宝搜索栏输入“女装”并点击，相关的女装列表将会展现给用户，用户点击感兴趣的女装进入详情页，通过查看商品介绍、店家信誉、用户评论等信息综合决定是否购买，如果有M个用户进入同一商品详情页，其中N个购买了该商品，那么该商品的转化率为成交总数和点击总数的比值（N/M）。在这个过程中，如果能够将转化率高的商品返回给用户，那么用户看到的商品正好就是想要购买的商品，这样用户将会更快速地找到喜欢的商品，从而提高用户体验；另一方面，广告每被用户点击一次商家都要付出一定的成本，如果广告被点击却没有成交，广告主将白白付出成本，而如果展现给用户且被点击的广告商品都产生了购买，那么商家虽然付出成本但还是能从成交中获得收益。总结来说，准确预估转化率，能够使得广告主匹配到最可能购买自家商品的用户，提升广告主的投入产出比（ROI）；另一方面，也能让用户快速找到购买意愿最强的商品，从而提升在电商平台中的用户体验。
* 2 **数据分析**  
（1）相同于初赛，复赛的正负样本也有比例不均衡的情况，即负样本数量远远大于正样本的数量，但由于要拟合线上的数据分布，并没有进行有针对性的正负样本采样，也没有通过xgb的scale_pos_weight等参数进行正负样本的调整。  
（2）与初赛不同的是，复赛给出的是31号到7号上午的数据作为训练集，7号下午的数据作为线上测试集，其中a榜占30%，b榜占70%，复赛的数据量比初赛大很多，因此需要在集群上跑特征工程，否则内存完全不够。  
![每天数据量](https://upload-images.jianshu.io/upload_images/12207295-79ba06278dc1a220.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  
（3）通过分析可以知道，7号的小时转化率相对于其他日期来说，有明显升高的趋势，而且5号和6号的小时转化率有明显降低的趋势，其他的日期则比较稳定，这个说明了7号就是特殊日期，可以猜测为双11类似的购物狂欢节，然后在7号前由于很多店铺的优惠还没有正式开始，因此很多用户都只是看商品，不会很早地下单，因此5号和6号的小时转化率会相对来说降低，符合我们的预测。接下来附上我们统计的小时转化率图表：  
![小时转化率分析](https://upload-images.jianshu.io/upload_images/12207295-46f73f73cb1a5d18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  
（4）初赛提取到的特征，相对于复赛来说，并不一定适用，因为复赛线上的数据分布跟线下的分布很不一致。此外，用户维度的特征在复赛并没有像初赛那么强，因为很多用户只是出现一次。通过分析，可能店铺，品牌等维度的特征会更强一点，因为某些品牌和店铺会在当天才会有优惠，而在特殊日期前用户都还是会点击查看，购买量会很少，因此通过对特殊日期前的店铺和品牌等维度进行统计，会提高模型精度。  
（5）通过上面小时转化率分析图表可以看到，对于普通日期和特殊日期，小时转化率除了在零点附近的时间会有较大的不同外，后面的趋势基本是保持一致的，只是特殊日期的小时转化率会比普通日期的整体要高。因此，我们需要从学习小时转化率的角度入手，首先根据2号到4号这几天比较平稳的日期的小时转化率和特殊日期前半天的小时转化率来预测线上的小时转化率，然后进行小时预测均值的调整，通过测试，这样可以在一定程度上提高成绩。  
（6）根据小时转化率趋势，我们尝试了将2号到4号抽样一些普通日期的数据，以及跟7号上午的数据进行合并，加入到模型里面训练，这样在一定程度上可以学习到小时转化率。相比与只用7号上午训练，两种方式各有好处，后期融合能取得一定的提升。  
（7）通过分析可以知道，5号和6号的数据，因为7号是特殊日期会产生一定的影响，所以我们的滑动窗口采用了两天的长度进行各个维度的统计。类似与初赛，我们对转化率特征进行了贝叶斯平滑（矩估计法），而对点击量和购买量则进行了归一化处理。  
（8）依据初赛和复赛的分析以及直观感觉，都觉得上下文搜索信息和商品类目属性的匹配程度这一块，以及商品的好评率和描述相符程度等特征都是强特，但是没有提取到很好的特征，这一块还有改进的空间。  
（9）通过测试，发现在线下利用7号上午进行训练，通过cv输出的7号上午的误差可以跟线上误差保持同升降，因此，可以通过这个来线下测试特征的重要性，进行特征选择。  
* 3 **特征工程**  
在上面数据分析中，也阐述了一些对特征的处理方式，主要是对一些特征进行贝叶斯平滑和归一化处理。对于复赛的特征，一部分与初赛不同，主要可以分为基础特征，单维度分析特征，历史统计特征，滑窗统计特征，用户维度统计特征，穿越特征几部分：  
* **基础特征**（上下文，用户，商品，店铺维度的特征）  
广告商品的展示页面编号  
用户性别 / 年龄等级 / 职业编号 / 星际编号  
商品品牌编号 / 城市编号 / 价格等级 / 销量等级 / 被收藏的次数等级 / 被展示次数等级  
店铺的评价数量等级 / 好评率 / 星级编号 / 服务态度评分 / 物流服务评分 / 描述相符评分  
* **单维度分析特征**（针对上下文信息中的根据查询词预测的类目属性列表与商品的类目列表和属性列表，定义了一个匹配程度特征，一开始简单粗暴地定义为两者交集个数 / 预测的个数，复赛的时候添加了针对类目的匹配特征）  
预测类目 / 属性的个数，商品实际的类目 / 属性个数，以及两者的匹配程度  
针对类目的匹配程度特征（'prop_jaccard', 'prop_predict_ratio', 'prop_item_ratio'）  
小时转化率  
*  **历史统计特征**（对特殊日期前的训练样本进行统计）  
品牌/店铺/商品的交易量，点击量，转化率特征，其中，交易量和点击量进行了归一化处理，转化率特征进行了贝叶斯平滑  
店铺/品牌/城市所拥有的用户/商品个数  
*  **滑窗统计特征**  
用户 / 商品 / 品牌 / 店铺 / 叶子类目对应的交易量，点击量，转化率特征，其中，交易量和点击量进行了归一化处理，转化率特征进行了贝叶斯平滑  
*  **用户维度统计特征**  
用户一个小时前点击相同根类目 / 叶子类目 / 商品 / 店铺 / 品牌的个数，以及时间间隔  
用户是否第一次点击该商品  
用户点击商品对应的价格等级 / 销量等级的最小值 / 最大值 / 均值 / 众数 / 中位数  
*  **穿越特征**  
用户后面点击相同商品/叶子类目的个数，时间间隔，以及是否点击  
* 4 **模型训练**  
本次比赛的复赛，我们也尝试了很多模型，包括xgb，lgb，lr，ffm等，由于发现lr和ffm的误差较大，因此在复赛的时候我们放弃了这两个模型，接下来详细介绍最终进行模型融合的模型：  
（1）xgb只用7号上午训练的模型：这个是我们在初赛a榜用的比较多的模型，只把7号上午的数据丢到模型里面训练，由于模型无法自己学到正确的小时转化率，因此这个模型最后预测出来的小时转化率趋势是存在一定问题的。我们根据测试出来的线上的均值，以及前几天比较稳定的小时转化率趋势预测出线上7号下午的小时转化率趋势，根据小时时段进行手动调整均值，这一部分的单模型最终在线上可以到90名左右，误差0.14035  
（2）xgb 7号上午 + 2-4号15%抽样样本训练模型：这个模型，是在初赛的时候也进行过尝试的模型，通过增加2-4号三天15%抽样样本数据让模型学习到一定的小时转化率趋势变化，然而，我们发现，后面预测出来的小时转化率还是存在一定问题，因此也是进行了手动调整均值，考虑到模型差异性，我们后面也是把这个模型融合到最终的结果中。这个单模型在线上的排名是90名左右，误差：0.14030  
（3）lgb 7号上午 + 2-4号15%抽样样本训练模型：这个模型是为了增加模型差异，最后考虑进行训练并添加到模型融合中的，采用的特征跟xgb基本一致  
（4）模型融合：关于模型融合，我们最后采用了5个模型进行**加权融合**，由于我和另一个队友采用的特征不一样，因为我们两个分别训练了两个模型，即加普通日期抽样和只用7号上午进行训练的模型，最后融合的比例是根据线上线下误差估计出来的，比例是：0.4 * yuna只用7号训练xgb模型 + 0.1 * yuna加普通日期xgb模型 + 0.1 * lake加普通日期lgb模型 + 0.2 * keng只用7号训练xgb模型 +　0.2 * keng加普通日期训练xgb模型  
* 5 **总结**  
本次阿里妈妈的比赛，持续时间比较长，有两个月，不过最终还是坚持下来了，虽然成绩还没有达到预期设计的排名，但是也是学到了很多东西，包括数据分析，特征工程和模型训练等，接下来就做一下简单的总结：  
（１）数据分析那一块，在比赛阶段很少画图表等直观的东西进行辅助分析，很多时候只是自己在YY，而特征选择通常是通过误差来判断，后面其实可以试着分析一下特征和标签之间的相关性分析特征的作用。  
（２）在模型训练这一部分，由于之前没有怎么用过xgb，因此，这个还是学到了很多东西，包括xgb模型适合丢不太稀疏的特征进去，模型怎么调参(我是采用了网格搜索和手动调参相结合的方法调参的)，对xgb的很多参数也有了进一步的理解，特别是col_sample（特征抽样），曾经因为这个特征，没有设置为１，导致在加特征的时候，出现了不收敛的情况。  
（３）模型选择方面，这次尝试的模型不多，关于lr和ffm是队友尝试比较多，因此，以后还是需要多加尝试相关的模型。  
（４）关于时间规划，很多时候没有规划好线上到底需要提交什么结果会比较好，没有很好地利用每一次机会。在ｂ榜的时候，我们的线上误差每天都在降，可是其他队伍降的程度比我们还多，所以我们的排名一直没有上去，这是在比赛结束后我们觉得比较可惜的点，其实我们还有挺多想法需要尝试，只不过机会已经没有了，所以规划好提交什么结果，这个对比赛还是很重要的。  
（５）这次复赛的数据量很大，跑一次特征工程都要５个小时以上，在一开始我还提错了一些特征，到时特征工程过了很久才能正常跑出来，这个是比较大的失误，后期的比赛需要好好借鉴，提完特征后，需要查看特征是否是提的没有问题，不然会对模型产生很大不好的影响。
